{"meta":{"title":"郑小飞的个人博客","subtitle":null,"description":null,"author":"郑小飞","url":"https://127.0.0.1/blog","root":"/blog/"},"pages":[{"title":"","date":"2019-05-08T08:46:16.056Z","updated":"2019-05-08T08:46:16.056Z","comments":true,"path":"404/index.html","permalink":"https://127.0.0.1/blog/404/index.html","excerpt":"","text":"&lt;!DOCTYPE html&gt; 404"}],"posts":[{"title":"Hello World","slug":"hello-world","date":"2019-05-08T08:21:10.402Z","updated":"2019-05-08T08:21:10.402Z","comments":true,"path":"2019/05/08/hello-world/","link":"","permalink":"https://127.0.0.1/blog/2019/05/08/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"ESLint错误解析","slug":"ESLint错误解析","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.395Z","comments":true,"path":"2019/05/06/ESLint错误解析/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/ESLint错误解析/","excerpt":"","text":"“no-alert”: 0,//禁止使用alert confirm prompt“no-array-constructor”: 2,//禁止使用数组构造器“no-bitwise”: 0,//禁止使用按位运算符“no-caller”: 1,//禁止使用arguments.caller或arguments.callee“no-catch-shadow”: 2,//禁止catch子句参数与外部作用域变量同名“no-class-assign”: 2,//禁止给类赋值“no-cond-assign”: 2,//禁止在条件表达式中使用赋值语句“no-console”: 2,//禁止使用console“no-const-assign”: 2,//禁止修改const声明的变量“no-constant-condition”: 2,//禁止在条件中使用常量表达式 if(true) if(1)“no-continue”: 0,//禁止使用continue“no-control-regex”: 2,//禁止在正则表达式中使用控制字符“no-debugger”: 2,//禁止使用debugger“no-delete-var”: 2,//不能对var声明的变量使用delete操作符“no-div-regex”: 1,//不能使用看起来像除法的正则表达式/=foo/“no-dupe-keys”: 2,//在创建对象字面量时不允许键重复 {a:1,a:1}“no-dupe-args”: 2,//函数参数不能重复“no-duplicate-case”: 2,//switch中的case标签不能重复“no-else-return”: 2,//如果if语句里面有return,后面不能跟else语句“no-empty”: 2,//块语句中的内容不能为空“no-empty-character-class”: 2,//正则表达式中的[]内容不能为空“no-empty-label”: 2,//禁止使用空label“no-eq-null”: 2,//禁止对null使用==或!=运算符“no-eval”: 1,//禁止使用eval“no-ex-assign”: 2,//禁止给catch语句中的异常参数赋值“no-extend-native”: 2,//禁止扩展native对象“no-extra-bind”: 2,//禁止不必要的函数绑定“no-extra-boolean-cast”: 2,//禁止不必要的bool转换“no-extra-parens”: 2,//禁止非必要的括号“no-extra-semi”: 2,//禁止多余的冒号“no-fallthrough”: 1,//禁止switch穿透“no-floating-decimal”: 2,//禁止省略浮点数中的0 .5 3.“no-func-assign”: 2,//禁止重复的函数声明“no-implicit-coercion”: 1,//禁止隐式转换“no-implied-eval”: 2,//禁止使用隐式eval“no-inline-comments”: 0,//禁止行内备注“no-inner-declarations”: [2, “functions”],//禁止在块语句中使用声明（变量或函数）“no-invalid-regexp”: 2,//禁止无效的正则表达式“no-invalid-this”: 2,//禁止无效的this，只能用在构造器，类，对象字面量“no-irregular-whitespace”: 2,//不能有不规则的空格“no-iterator”: 2,//禁止使用iterator 属性“no-label-var”: 2,//label名不能与var声明的变量名相同“no-labels”: 2,//禁止标签声明“no-lone-blocks”: 2,//禁止不必要的嵌套块“no-lonely-if”: 2,//禁止else语句内只有if语句“no-loop-func”: 1,//禁止在循环中使用函数（如果没有引用外部变量不形成闭包就可以）“no-mixed-requires”: [0, false],//声明时不能混用声明类型“no-mixed-spaces-and-tabs”: [2, false],//禁止混用tab和空格“linebreak-style”: [0, “windows”],//换行风格“no-multi-spaces”: 1,//不能用多余的空格“no-multi-str”: 2,//字符串不能用\\换行“no-multiple-empty-lines”: [1, {“max”: 2}],//空行最多不能超过2行“no-native-reassign”: 2,//不能重写native对象“no-negated-in-lhs”: 2,//in 操作符的左边不能有!“no-nested-ternary”: 0,//禁止使用嵌套的三目运算“no-new”: 1,//禁止在使用new构造一个实例后不赋值“no-new-func”: 1,//禁止使用new Function“no-new-object”: 2,//禁止使用new Object()“no-new-require”: 2,//禁止使用new require“no-new-wrappers”: 2,//禁止使用new创建包装实例，new String new Boolean new Number“no-obj-calls”: 2,//不能调用内置的全局对象，比如Math() JSON()“no-octal”: 2,//禁止使用八进制数字“no-octal-escape”: 2,//禁止使用八进制转义序列“no-param-reassign”: 2,//禁止给参数重新赋值“no-path-concat”: 0,//node中不能使用dirname或filename做路径拼接“no-plusplus”: 0,//禁止使用++，–“no-process-env”: 0,//禁止使用process.env“no-process-exit”: 0,//禁止使用process.exit()“no-proto”: 2,//禁止使用proto属性“no-redeclare”: 2,//禁止重复声明变量“no-regex-spaces”: 2,//禁止在正则表达式字面量中使用多个空格 /foo bar/“no-restricted-modules”: 0,//如果禁用了指定模块，使用就会报错“no-return-assign”: 1,//return 语句中不能有赋值表达式“no-script-url”: 0,//禁止使用javascript:void(0)“no-self-compare”: 2,//不能比较自身“no-sequences”: 0,//禁止使用逗号运算符“no-shadow”: 2,//外部作用域中的变量不能与它所包含的作用域中的变量或参数同名“no-shadow-restricted-names”: 2,//严格模式中规定的限制标识符不能作为声明时的变量名使用“no-spaced-func”: 2,//函数调用时 函数名与()之间不能有空格“no-sparse-arrays”: 2,//禁止稀疏数组， [1,,2]“no-sync”: 0,//nodejs 禁止同步方法“no-ternary”: 0,//禁止使用三目运算符“no-trailing-spaces”: 1,//一行结束后面不要有空格“no-this-before-super”: 0,//在调用super()之前不能使用this或super“no-throw-literal”: 2,//禁止抛出字面量错误 throw “error”;“no-undef”: 1,//不能有未定义的变量“no-undef-init”: 2,//变量初始化时不能直接给它赋值为undefined“no-undefined”: 2,//不能使用undefined“no-unexpected-multiline”: 2,//避免多行表达式“no-underscore-dangle”: 1,//标识符不能以_开头或结尾“no-unneeded-ternary”: 2,//禁止不必要的嵌套 var isYes = answer === 1 ? true : false;“no-unreachable”: 2,//不能有无法执行的代码“no-unused-expressions”: 2,//禁止无用的表达式“no-unused-vars”: [2, {“vars”: “all”, “args”: “after-used”}],//不能有声明后未被使用的变量或参数“no-use-before-define”: 2,//未定义前不能使用“no-useless-call”: 2,//禁止不必要的call和apply“no-void”: 2,//禁用void操作符“no-var”: 0,//禁用var，用let和const代替“no-warning-comments”: [1, { “terms”: [“todo”, “fixme”, “xxx”], “location”: “start” }],//不能有警告备注“no-with”: 2,//禁用with “array-bracket-spacing”: [2, “never”],//是否允许非空数组里面有多余的空格“arrow-parens”: 0,//箭头函数用小括号括起来“arrow-spacing”: 0,//=&gt;的前/后括号“accessor-pairs”: 0,//在对象中使用getter/setter“block-scoped-var”: 0,//块语句中使用var“brace-style”: [1, “1tbs”],//大括号风格“callback-return”: 1,//避免多次调用回调什么的“camelcase”: 2,//强制驼峰法命名“comma-dangle”: [2, “never”],//对象字面量项尾不能有逗号“comma-spacing”: 0,//逗号前后的空格“comma-style”: [2, “last”],//逗号风格，换行时在行首还是行尾“complexity”: [0, 11],//循环复杂度“computed-property-spacing”: [0, “never”],//是否允许计算后的键名什么的“consistent-return”: 0,//return 后面是否允许省略“consistent-this”: [2, “that”],//this别名“constructor-super”: 0,//非派生类不能调用super，派生类必须调用super“curly”: [2, “all”],//必须使用 if(){} 中的{}“default-case”: 2,//switch语句最后必须有default“dot-location”: 0,//对象访问符的位置，换行的时候在行首还是行尾“dot-notation”: [0, { “allowKeywords”: true }],//避免不必要的方括号“eol-last”: 0,//文件以单一的换行符结束“eqeqeq”: 2,//必须使用全等“func-names”: 0,//函数表达式必须有名字“func-style”: [0, “declaration”],//函数风格，规定只能使用函数声明/函数表达式“generator-star-spacing”: 0,//生成器函数*的前后空格“guard-for-in”: 0,//for in循环要用if语句过滤“handle-callback-err”: 0,//nodejs 处理错误“id-length”: 0,//变量名长度“indent”: [2, 4],//缩进风格“init-declarations”: 0,//声明时必须赋初值“key-spacing”: [0, { “beforeColon”: false, “afterColon”: true }],//对象字面量中冒号的前后空格“lines-around-comment”: 0,//行前/行后备注“max-depth”: [0, 4],//嵌套块深度“max-len”: [0, 80, 4],//字符串最大长度“max-nested-callbacks”: [0, 2],//回调嵌套深度“max-params”: [0, 3],//函数最多只能有3个参数“max-statements”: [0, 10],//函数内最多有几个声明“new-cap”: 2,//函数名首行大写必须使用new方式调用，首行小写必须用不带new方式调用“new-parens”: 2,//new时必须加小括号“newline-after-var”: 2,//变量声明后是否需要空一行“object-curly-spacing”: [0, “never”],//大括号内是否允许不必要的空格“object-shorthand”: 0,//强制对象字面量缩写语法“one-var”: 1,//连续声明“operator-assignment”: [0, “always”],//赋值运算符 += -=什么的“operator-linebreak”: [2, “after”],//换行时运算符在行尾还是行首“padded-blocks”: 0,//块语句内行首行尾是否要空行“prefer-const”: 0,//首选const“prefer-spread”: 0,//首选展开运算“prefer-reflect”: 0,//首选Reflect的方法“quotes”: [1, “single”],//引号类型 “” ‘’“quote-props”:[2, “always”],//对象字面量中的属性名是否强制双引号“radix”: 2,//parseInt必须指定第二个参数“id-match”: 0,//命名检测“require-yield”: 0,//生成器函数必须有yield“semi”: [2, “always”],//语句强制分号结尾“semi-spacing”: [0, {“before”: false, “after”: true}],//分号前后空格“sort-vars”: 0,//变量声明时排序“space-after-keywords”: [0, “always”],//关键字后面是否要空一格“space-before-blocks”: [0, “always”],//不以新行开始的块{前面要不要有空格“space-before-function-paren”: [0, “always”],//函数定义时括号前面要不要有空格“space-in-parens”: [0, “never”],//小括号里面要不要有空格“space-infix-ops”: 0,//中缀操作符周围要不要有空格“space-return-throw-case”: 2,//return throw case后面要不要加空格“space-unary-ops”: [0, { “words”: true, “nonwords”: false }],//一元运算符的前/后要不要加空格“spaced-comment”: 0,//注释风格要不要有空格什么的“strict”: 2,//使用严格模式“use-isnan”: 2,//禁止比较时使用NaN，只能用isNaN()“valid-jsdoc”: 0,//jsdoc规则“valid-typeof”: 2,//必须使用合法的typeof的值“vars-on-top”: 2,//var必须放在作用域顶部“wrap-iife”: [2, “inside”],//立即执行函数表达式的小括号风格“wrap-regex”: 0,//正则表达式字面量用小括号包起来“yoda”: [2, “never”]//禁止尤达条件 原作者: http://blog.csdn.net/helpzp2008/article/details/51507428","categories":[],"tags":[{"name":"web前端","slug":"web前端","permalink":"https://127.0.0.1/blog/tags/web前端/"}]},{"title":"Django的基础学习","slug":"Django的基础学习","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.394Z","comments":true,"path":"2019/05/06/Django的基础学习/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/Django的基础学习/","excerpt":"","text":"搭建Django框架1 基本搭建1234561 创建一个文件夹 mkdir mytest2 在文件夹里面创建一个项目 Django-admin startproject mysite3 在里面创建一个应用 python3.6 manage.py startapp myweb 2 执行数据库连接配置123456789101112131415161718192021222324251 编辑init文件,添加Pymysql的数据库 import pymysql pymysql.install_as_MySQLdb() 2 进入setting配置文件,进行修改 INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;mytest&apos;, #写上创建的应用名] DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;mydb&apos;, #写上库名 &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;123456&apos;, &apos;HOST&apos;: &apos;localhost&apos;, &apos;PORT&apos;: &apos;3306&apos;,&#125; #此处添加自己的IP地址 ALLOWED_HOSTS = [&apos;192.168.2.240&apos;] 3 配置路由1234567891011121314151 配置主路由(第一层路径正则筛选) from django.conf.urls import include,url from django.contrib import admin urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(r&apos;^mytest/&apos;, include(&apos;mytest.urls&apos;)), ]2 配置应用路由(第二层路径筛选)(必须要有相对应的视图) from django.conf.urls import url from . import views urlpatterns = [ url(r&apos;^$&apos;, views.index, name=&quot;index&quot;), ] 4 编写相对应的视图123456789101112写相对于应用路由的视图from django.shortcuts import renderfrom django.http import HttpResponsefrom mytest.models import Usersdef index(request): ###命名一定是路由的命名 try: s = Users.objects.get(id=1) return HttpResponse(s) except: return HttpResponse(&quot;没有找到对应的信息！&quot;) 5 测试1python3.6 manage.py sunserver 0:8000 数据库的增删改查1 视图1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192视图的填写from django.shortcuts import renderfrom django.http import HttpResponse,HttpResponseRedirectfrom django.core.urlresolvers import reversefrom django.shortcuts import redirectfrom mytest.models import Usersdef index(request): try: list = Users.objects.filter(id__in=[1,3,5]) s = &apos;,&apos;.join([vo.name for vo in list]) #修改(将id值为5的age值改为30) #ob = Users.objects.get(id=5) #ob.age = 30 #ob.save() #删除(删除id为3的信息) #ob = Users.objects.get(id=3) #ob.delete() return HttpResponse(s) except: return HttpResponse(&quot;没有找到对应的信息！&quot;)# 浏览用户信息 def indexUsers(request): # 执行数据查询，并放置到模板中 list = Users.objects.all() context = &#123;&quot;stulist&quot;:list&#125; return render(request,&quot;mytest/users/index.html&quot;,context)# 加载添加信息表单def addUsers(request): return render(request,&quot;mytest/users/add.html&quot;)# 执行信息添加操作def insertUsers(request): try: ob = Users() ob.name = request.POST[&apos;name&apos;] ob.age = request.POST[&apos;age&apos;] ob.phone = request.POST[&apos;phone&apos;] ob.save() context = &#123;&apos;info&apos;:&apos;添加成功！&apos;&#125; except: context = &#123;&apos;info&apos;:&apos;添加失败！&apos;&#125; return render(request,&quot;mytest/users/info.html&quot;,context)# 执行信息删除操作 def delUsers(request,uid): try: ob = Users.objects.get(id=uid) ob.delete() #重定向到信息浏览页 return HttpResponseRedirect(reverse(&quot;users&quot;)) #同上重定向跳转的简写 return redirect(reverse(&quot;users&quot;)) except: context = &#123;&apos;info&apos;:&apos;删除失败！&apos;&#125; return render(request,&quot;mytest/users/info.html&quot;,context)# 加载信息编辑表单 def editUsers(request,uid): try: ob = Users.objects.get(id=uid) context = &#123;&apos;user&apos;:ob&#125; return render(request,&quot;mytest/users/edit.html&quot;,context) except: context = &#123;&apos;info&apos;:&apos;没有找到要修改的信息！&apos;&#125; return render(request,&quot;mytest/users/info.html&quot;,context)# 执行信息编辑操作def usersupdate(request,uid): try: ob = Users.objects.get(id=uid) ob.username = request.POST[&apos;username&apos;] ob.name = request.POST[&apos;name&apos;] ob.passwd = request.POST[&apos;passwd&apos;] ob.sex = request.POST[&apos;sex&apos;] ob.address = request.POST[&apos;address&apos;] ob.code = request.POST[&apos;code&apos;] ob.phone = request.POST[&apos;phone&apos;] ob.email = request.POST[&apos;email&apos;] ob.state = request.POST[&apos;state&apos;] ob.addtime = time.time() ob.save() context = &#123;&apos;info&apos;:&apos;修改成功&apos;&#125; except: context = &#123;&apos;info&apos;:&apos;修改失败&apos;&#125; return render(request,&apos;myadmin/info.html&apos;,context) 2 html主页123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;title&gt;用户信息管理&lt;/title&gt; &lt;script&gt; //自定义执行信息删除提示判断，参数uu是成功的删除url地址 function doDel(uu)&#123; if(confirm(&quot;确定要删除吗？&quot;))&#123; //网页跳转 window.location=uu; &#125; &#125; &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;center&gt; &#123;% include &apos;mytest/users/menu.html&apos; %&#125; &lt;h3&gt;浏览用户信息&lt;/h3&gt; &lt;table width=&quot;800&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;th&gt;id号&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;th&gt;电话&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &#123;% for stu in stulist %&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123; stu.id &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; stu.name &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; stu.age &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; stu.phone &#125;&#125;&lt;/td&gt; &lt;td&gt; &lt;a href=&quot;&#123;% url &apos;editusers&apos; stu.id %&#125;&quot;&gt;编辑&lt;/a&gt; &lt;a href=&quot;javascript:doDel(&apos;&#123;% url &apos;delusers&apos; stu.id %&#125;&apos;);&quot;&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/table&gt; &lt;/center&gt; &lt;/body&gt;&lt;/html&gt; 添加12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;title&gt;用户信息管理&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;center&gt; &#123;% include &quot;mytest/users/menu.html&quot; %&#125; &lt;h3&gt;添加用户信息&lt;/h3&gt; &lt;form action=&quot;&#123;% url &apos;insertusers&apos; %&#125;&quot; method=&quot;post&quot;&gt; &#123;% csrf_token %&#125; &lt;table width=&quot;280&quot; border=&quot;0&quot;&gt; &lt;tr&gt; &lt;td&gt;姓名：&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;name&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;年龄：&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;age&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;电话：&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;text&quot; name=&quot;phone&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td colspan=&quot;2&quot; align=&quot;center&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;添加&quot;/&gt; &lt;input type=&quot;reset&quot; value=&quot;重置&quot;/&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/form&gt; &lt;/center&gt; &lt;/body&gt;&lt;/html&gt; 修改1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&#123;% extends &quot;myadmin/base.html&quot; %&#125; &#123;%block block_name%&#125;&lt;!-- 主体开始 --&gt; &lt;h1&gt; Edit Your Profile &lt;/h1&gt; &lt;form id=&quot;edit-profile&quot; class=&quot;form-horizontal&quot; action=&quot;&#123;% url &apos;myadmin_usersupdate&apos; user.id %&#125;&quot; enctype=&quot;multipart/form-data&quot; method=&quot;post&quot;&gt; &#123;% csrf_token %&#125; &lt;fieldset&gt; &lt;legend&gt;编辑用户信息&lt;/legend&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;input01&quot;&gt;username&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;input-xlarge&quot; id=&quot;input01&quot; name=&apos;username&apos; value=&apos;&#123;&#123; user.username &#125;&#125;&apos;/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;input01&quot;&gt;name&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &lt;input type=&quot;passwo&quot; class=&quot;input-xlarge&quot; id=&quot;input01&quot; name=&apos;name&apos; value=&apos;&#123;&#123; user.name &#125;&#125;&apos;/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;input01&quot;&gt;passwd&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;input-xlarge&quot; id=&quot;input01&quot; name=&apos;passwd&apos; value=&apos;&#123;&#123; user.passwd &#125;&#125;&apos;/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;input01&quot;&gt;sex&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;input type=&quot;radio&quot; name=&apos;sex&apos; value=&quot;1&quot; /&gt;男 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;input type=&quot;radio&quot; name=&apos;sex&apos; value=&quot;0&quot; /&gt;女 &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;input01&quot;&gt;address&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;input-xlarge&quot; id=&quot;input01&quot; name=&apos;address&apos; value=&apos;&#123;&#123; user.address &#125;&#125;&apos;/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;input01&quot;&gt;code&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;input-xlarge&quot; id=&quot;input01&quot; name=&apos;code&apos; value=&apos;&#123;&#123; user.code &#125;&#125;&apos;/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;input01&quot;&gt;phone&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;input-xlarge&quot; id=&quot;input01&quot; name=&apos;phone&apos; value=&apos;&#123;&#123; user.phone &#125;&#125;&apos;/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;input01&quot;&gt;email&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;input-xlarge&quot; id=&quot;input01&quot; name=&apos;email&apos; value=&apos;&#123;&#123; user.email &#125;&#125;&apos;/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;input01&quot;&gt;state&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;input type=&quot;radio&quot; name=&quot;state&quot; value=&quot;1&quot; /&gt;启用 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;input type=&quot;radio&quot; name=&quot;state&quot; value=&quot;2&quot; /&gt;禁用 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;input type=&quot;radio&quot; name=&quot;state&quot; value=&quot;0&quot; /&gt;后台管理员 &lt;/div&gt; &lt;/div&gt; &lt;!-- &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;fileInput&quot;&gt;Photo&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &lt;input class=&quot;input-file&quot; id=&quot;fileInput&quot; type=&quot;file&quot; /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;control-group&quot;&gt; &lt;label class=&quot;control-label&quot; for=&quot;textarea&quot;&gt;Biography&lt;/label&gt; &lt;div class=&quot;controls&quot;&gt; &lt;textarea class=&quot;input-xlarge&quot; id=&quot;textarea&quot; rows=&quot;4&quot;&gt;Web technology junkie who writes innovative and bestselling technical books. Also enjoys Sunday bicycle rides and all &quot;good&quot; comedy.&lt;/textarea&gt; &lt;/div&gt; &lt;/div&gt; --&gt; &lt;div class=&quot;form-actions&quot;&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;Save&lt;/button&gt; &lt;button class=&quot;btn&quot;&gt;Cancel&lt;/button&gt; &lt;/div&gt; &lt;/fieldset&gt; &lt;/form&gt;&lt;!-- 主体结束 --&gt;&#123;%endblock%&#125; info显示12345menu&lt;h2&gt;用户信息管理&lt;/h2&gt; &lt;a href=&quot;&#123;% url &apos;users&apos; %&#125;&quot;&gt;浏览用户&lt;/a&gt; | &lt;a href=&quot;&#123;% url &apos;addusers&apos; %&#125;&quot;&gt;添加用户&lt;/a&gt; &lt;hr/&gt; 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;title&gt;用户信息管理&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;center&gt; &#123;% include &quot;mytest/users/menu.html&quot; %&#125; &lt;h3&gt;&#123;&#123; info &#125;&#125;&lt;/h3&gt; &lt;/center&gt; &lt;/body&gt;&lt;/html&gt; 静态文件1 注意123456781 修改setting里面的静态设定(在最后) STATIC_URL = &apos;/static/&apos; STATICFILES_DIRS = [ os.path.join(BASE_DIR, &apos;static&apos;), ]2 在每一个页面都使用编码(每个页面前都必须要加) &#123;% load static from staticfiles %&#125; 2 使用方法123456789101112创建一个base.html,base是父,其他为子,所有的公共部分都放在父文件里以便调用&#123;% csrf_token %&#125;1 占位标签 &#123;%block block_name%&#125; 这里可以定义默认值 如果不定义默认值，则表示空字符串 &#123;%endblock%&#125; 在base文件中任意位置可以占位,然后可以在子文件中写上占位标签就可以自己定义那块部分的内容,注意标签名字不能重复 2 继承标签 &#123;% extends &quot;base.html&quot; %&#125;在子文件中写入继承标签就可以继承父类里面的公共信息 提交表单注意12345from 里面需要写 action=&quot;&#123;% url &apos;myadmin_usersinsert&apos; %&#125;&quot; enctype=&quot;multipart/form-data&quot; method=&quot;post&quot; 下面需要加&#123;% csrf_token %&#125; 分页12# stu信息分页实例 url(r&apos;^stu/(?P&lt;pIndex&gt;[0-9]*)/$&apos;, views.stu, name=&apos;stu&apos;), 1234567891011121314#stu学生信息分页实例def stu(request,pIndex): #return HttpResponse(&apos;ok&apos;) list = Stu.objects.filter() #实例化分页对象 p = Paginator(list,5) # 处理当前页号信息 if pIndex==&quot;&quot;: pIndex = &apos;1&apos; pIndex = int(pIndex) # 获取当前页数据 list2 = p.page(pIndex) plist = p.page_range return render(request,&quot;myweb/stu.html&quot;,&#123;&apos;stulist&apos;:list2,&apos;pIndex&apos;:pIndex,&apos;plist&apos;:plist&#125;) 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Web的使用操作&lt;/title&gt; &lt;!-- 最新版本的 Bootstrap 核心 CSS 文件 --&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css&quot; integrity=&quot;sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;center&gt; &lt;h1&gt;信息分页实例&lt;/h1&gt; &lt;a href=&quot;&#123;% url &apos;index&apos; %&#125;&quot;&gt;返回首页&lt;/a&gt; &lt;br/&gt;&lt;br/&gt; &lt;table width=&quot;70%&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;th&gt;学号&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;th&gt;性别&lt;/th&gt; &lt;th&gt;班级&lt;/th&gt; &lt;/tr&gt; &#123;% for stu in stulist %&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123; stu.id &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; stu.name &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; stu.age &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; stu.sex &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; stu.classid &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/table&gt; &lt;br/&gt; &lt;ul class=&quot;pagination&quot;&gt; &#123;%for pindex in plist%&#125; &lt;li&gt;&lt;a href=&#123;% url &apos;stu&apos; pindex %&#125;&gt;&#123;&#123;pindex&#125;&#125;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; &lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 城市的多级联动1234 # 城市级联操作 url(r&apos;^showdistrict$&apos;, views.showdistrict, name=&apos;showdistrict&apos;), url(r&apos;^district/([0-9]+)$&apos;, views.district, name=&apos;district&apos;),] 1234567891011# 加载城市级联信息操作模板def showdistrict(request): return render(request,&quot;myweb/district.html&quot;)# 加载对应的城市信息，并json格式ajax方式响应def district(request,upid): dlist = District.objects.filter(upid=upid) list = [] for ob in dlist: list.append(&#123;&apos;id&apos;:ob.id,&apos;name&apos;:ob.name&#125;) return JsonResponse(&#123;&apos;data&apos;:list&#125;) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&#123;% load static from staticfiles %&#125;&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Web的使用操作&lt;/title&gt; &lt;style&gt; select&#123;margin:10px;&#125; &lt;/style&gt; &lt;!-- &lt;script type=&quot;text/javascript&quot; src=&quot;/static/js/jquery-1.8.3.min.js&quot;&gt;&lt;/script&gt; --&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;&#123;% static &apos;js/jquery-1.8.3.min.js&apos; %&#125;&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; //jQuery入口程序 $(function()&#123; $.ajax(&#123; url: &quot;&#123;% url &apos;district&apos; 0 %&#125;&quot;, type: &apos;get&apos;, data: &#123;&#125;, dataType:&apos;json&apos;, success:function(res)&#123; var data = res.data; for(var i=0;i&lt;data.length;i++)&#123; $(&apos;&lt;option value=&quot;&apos;+data[i].id+&apos;&quot;&gt;&apos;+data[i].name+&apos;&lt;/option&gt;&apos;).appendTo(&apos;select:last&apos;) //$(&apos;select:last&apos;).append(&apos;&lt;option value=&quot;&apos;+data[i].id+&apos;&quot;&gt;&apos;+data[i].name+&apos;&lt;/option&gt;&apos;); &#125; &#125;, error:function()&#123; alert(&quot;ajax加载失败！&quot;); &#125; &#125;); //获取最后一个下拉框并添加选中事件 $(&quot;select&quot;).live(&apos;change&apos;,function()&#123; //获取选中的id号 var id = $(this).val(); $(this).nextAll().remove(); $.ajax(&#123; url: &quot;/district/&quot;+id, type: &apos;get&apos;, data: &#123;&#125;, dataType:&apos;json&apos;, success:function(res)&#123; if(res.data.length&lt;1) return; var data = res.data; var select = $(&quot;&lt;select&gt;&lt;/select&gt;&quot;) for(var i=0;i&lt;data.length;i++)&#123; $(&apos;&lt;option value=&quot;&apos;+data[i].id+&apos;&quot;&gt;&apos;+data[i].name+&apos;&lt;/option&gt;&apos;).appendTo(select) //$(&apos;select:last&apos;).append(&apos;&lt;option value=&quot;&apos;+data[i].id+&apos;&quot;&gt;&apos;+data[i].name+&apos;&lt;/option&gt;&apos;); &#125; $(&quot;select:last&quot;).after(select); &#125; &#125;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Ajax的城市级联信息操作&lt;/h1&gt; &lt;br/&gt; &lt;select&gt; &lt;option&gt;-请选择-&lt;/option&gt; &lt;/select&gt; &lt;/body&gt;&lt;/html&gt; 错误日志1234567891011121314151617看下面前请先确定 1 确保每个代码页都保存了 2 重启一下服务实施 3 看页面下面给的错误的地方,看是不是单词写错了 4 你可以看下面的错误了in.... 缩进错误sock 数据库启动错误 service mysqld restart404 连接成功,地址栏写的不对&quot;Table &apos;myshop.django_session&apos; doesn&apos;t exist&quot;)需要执行数据迁移 $ python manage.py migrateProgrammingError at /myadmin/orders//(1146, &quot;Table &apos;myshop.myadmin_orders&apos; doesn&apos;t exist&quot;)表找不见,后台需要在模板处改名 class Meta: db_table = &quot;myweb_orders&quot; 12345NoReverseMatch at /myadmin/ordersedit/1Reverse for &apos;myadmin_ordersedit&apos; with no arguments not found. 1 pattern(s) tried: [&apos;myadmin/ordersedit/(?P&lt;uid&gt;[0-9]+)$&apos;]在html里面少写了一个参数 &lt;form id=&quot;edit-profile&quot; class=&quot;form-horizontal&quot; action=&quot;&#123;% url &apos;myadmin_ordersupdate&apos; order.id %&#125;&quot; enctype=&quot;multipart/form-data&quot; method=&quot;post&quot;&gt; 判断12345678910111213141516两层判断&lt;td&gt; &#123;% if stu.sex == 1 %&#125; 男 &#123;% else %&#125; 女 &#123;% endif %&#125;&lt;/td&gt;三层判断&#123;% if stu.state == 1 %&#125; 启用 &#123;% elif stu.state == 2 %&#125; 禁用 &#123;% else %&#125; 后台管理员&#123;% endif %&#125; 一些不会的方法12345678910计算总价 数量是shop.m 单价是shop.price 总价 &lt;h5 id=&quot;xiaoji&quot; class=&quot;xj&quot;&gt;&#123;% widthratio shop.price 1 shop.m %&#125;&lt;/h5&gt; 特殊的提交url方式并进行加减 减 &lt;button class=&quot;col-md-2 btn-1 col-xs-2&quot; onclick=&quot;window.location=&apos;&#123;% url &apos;gwcchange&apos; %&#125;?sid=&#123;&#123;shop.id&#125;&#125;&amp;m=&#123;&#123;shop.m|add:-1&#125;&#125;&apos;&quot; &gt;-&lt;/button&gt; 加 &lt;button class=&quot;col-md-2 btn-2 col-xs-2&quot; onclick=&quot;window.location=&apos;&#123;% url &apos;gwcchange&apos; %&#125;?sid=&#123;&#123;shop.id&#125;&#125;&amp;m=&#123;&#123;shop.m|add:1&#125;&#125;&apos;&quot;&gt;+&lt;/button&gt;","categories":[],"tags":[{"name":"web前端","slug":"web前端","permalink":"https://127.0.0.1/blog/tags/web前端/"}]},{"title":"ES查询学习(随时更新)","slug":"ES查询学习(随时更新)","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.395Z","comments":true,"path":"2019/05/06/ES查询学习(随时更新)/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/ES查询学习(随时更新)/","excerpt":"","text":"ES查询学习常用查询match_all 查询所有 match 分词匹配查询, 模糊查询 term 精确查找, 单个字段等值匹配 terms 多个字段等值匹配 基础查询{ &quot;query&quot;: {&quot;match&quot;: {}} # 编写查询条件 &quot;size&quot;: 1 # 返回数量, 默认为10 &quot;from&quot;: 10 # 索引下标, 从第几条开始, 默认为0 &quot;sort&quot;: {&quot;length&quot;: {&quot;order&quot;: &quot;desc&quot;}} # 按length进行降序排序 &quot;_source&quot;: [&quot;id&quot;, &quot;length&quot;] # 返回多个字段 } 布尔查询{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ {&quot;term&quot;: {&apos;id&apos;: 110}}, ### must == and 必须两个都为真才会返回 {&quot;term&quot;: {&apos;id&apos;: 111}} ], &quot;should&quot;: [ {&quot;match&quot;: {&apos;borough&apos;: &quot;黑龙国际&quot;}}, ### should == or 两个有一个为真才会返回 {&quot;match&quot;: {&apos;borough&apos;: &quot;天下国际&quot;}} ], &quot;must_not&quot;: [ {&quot;match&quot;: {&apos;name&apos;: &quot;国美花园&quot;}}, ### must_not == not 全部为假才会返回 {&quot;match&quot;: {&apos;name&apos;: &quot;天坛公园&quot;}}, ] } } } gt 大于 gte 大于等于 lt 小于 lte 小于等于 过滤查询(filter过滤条件){ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: {&quot;match_all&quot;: {}}, &quot;filter&quot;: { &quot;range&quot;: { &quot;price&quot;: { &quot;gte&quot;: 1000, ### 查询price字段在1000到2000之内的所有数据 &quot;lte&quot;: 2000 } } } } } } 相当于 select * from complex where 1000 &lt;= price and price &lt;= 2000 聚合查询(Aggregations){ &quot;aggs&quot;: { &quot;group_by_state&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;borough_name&quot; ### 所有数据按照小区名进行分组, 然后按照分组记录数从大到小排序 } } }, &quot;size&quot;: 0 ### 只返回聚合结果 } 相当于 select borough_name, count(*) from complex group by borough_name order by count(*) desc 聚合查询里面执行求平均操作{ &quot;aggs&quot;: { &quot;group_by_state&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;borough_name&quot; ### 所有数据按照小区名进行分组, 然后按照分组记录数从大到小排序 } }, &quot;aggs&quot;: { &quot;average_balance&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;price&quot; } } } }, &quot;size&quot;: 0 ### 只返回聚合结果 } select borough_name, avg(price) ,count(*) from complex group by borough_name order by count(*) desc","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"Go的并发无法执行的坑","slug":"Go的并发无法执行的坑","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.395Z","comments":true,"path":"2019/05/06/Go的并发无法执行的坑/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/Go的并发无法执行的坑/","excerpt":"","text":"前言Go 语言本身支持并发, 只需要通过 Go来启动goroutine就可以了, 语法格式也很简单, 就直接在调用方法前加上go 关键字就可以了, 例如1go hello(x) 遇到的问题Go 允许使用go 语句开启一个goroutine (线程)去执行这个函数, 很简单, 但是有一个新手需要注意的地方(比如我), 那就是函数运行时间和进程的运行时间, 因为go语句是开启一个新的, 刚创建的goroutine去运行这个函数, 但是本身的主进程还会继续运行, 所以, 如果你只写一个go语句, 后面没有可以运行程序的话就会出现一个尴尬的问题, 主进程直接关闭, 对应goroutine也直接关闭,导致函数没有运行 可以参考一下下面的例子123456789101112131415161718package mainimport ( &quot;fmt&quot; &quot;time&quot;)func hello(aa string) &#123; for a := 0; a &lt; 3; a++ &#123; fmt.Println(aa) time.Sleep(3 * time.Second) &#125;&#125;func main() &#123; go hello(&quot;小飞&quot;) go hello(&quot;飞啊飞&quot;) // time.Sleep(100 * time.Second) 不加这行代码的话就会出现这种情况&#125; 运行良好的结果123456飞啊飞小飞小飞飞啊飞小飞飞啊飞 可以看到顺序不固定, 因为是多个goroutine执行的","categories":[],"tags":[{"name":"GoLang","slug":"GoLang","permalink":"https://127.0.0.1/blog/tags/GoLang/"}]},{"title":"Grpc初体验","slug":"Grpc初体验","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.395Z","comments":true,"path":"2019/05/06/Grpc初体验/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/Grpc初体验/","excerpt":"","text":"Grpc初体验前言因为最近工作涉及到了grpc, 但是不是很了解这个框架, 所以就看了一手 grpc官方文档, 克隆下来代码简单的了解一下 概念定义一个服务， 指定其可以被远程调用的方法及其参数和返回类型。gRPC 默认使用 protocol buffers 作为接口定义语言，来描述服务接口和有效载荷消息结构。允许定义四种服务方法12345671 单项 RPC，即客户端发送一个请求给服务端，从服务端获取一个应答，就像一次普通的函数调用2 服务端流式 RPC，即客户端发送一个请求给服务端，可获取一个数据流用来读取一系列消息。客户端从返回的数据流里一直读取直到没有更多消息为止。3 客户端流式 RPC，即客户端用提供的一个数据流写入并发送一系列消息给服务端。一旦客户端完成消息写入，就等待服务端读取这些消息并返回应答4 双向流式 RPC，即两边都可以分别通过一个读写数据流来发送一系列消息。这两个数据流操作是相互独立的，所以客户端和服务端能按其希望的任意顺序读写， 主要使用gRPC 提供 protocol buffer 编译插件，能够从一个服务定义的 .proto 文件生成客户端和服务端代码。通常 gRPC 用户可以在服务端实现这些API，并从客户端调用它们。 测试服务端测试使用的话就是按照官方文档的教程来的1git clone https://github.com/grpc/grpc.git 拉一手代码然后直接进到demo目录就可以, 我主要看了一下 Python和 Go的, 目录 grpc/examples/python/helloworld, 里面的代码都是生成好的, 可以直接使用, 如果有兴趣的也可以按照教程从头开始 在目录里 greeter_server.py 是服务端, 在里面定义了一个Greeter的类, 包括里面的一个 SayHello 方法(接受参数, 返回响应)12345678910111213141516class Greeter(helloworld_pb2_grpc.GreeterServicer): def SayHello(self, request, context): return helloworld_pb2.HelloReply(message=&apos;Yes, %s!&apos; % request.name)def serve(): server = grpc.server(futures.ThreadPoolExecutor(max_workers=10)) helloworld_pb2_grpc.add_GreeterServicer_to_server(Greeter(), server) server.add_insecure_port(&apos;[::]:50051&apos;) server.start() try: while True: time.sleep(_ONE_DAY_IN_SECONDS) except KeyboardInterrupt: server.stop(0) 可以看到在server里面首先定义了一个最大处理数为10的线程池, 然后将 Greeter 类作为服务添加, 在添加50051作为服务端口, start启动服务 客户端1234567891011def run(): # NOTE(gRPC Python Team): .close() is possible on a channel and should be # used in circumstances in which the with statement does not fit the needs # of the code. a = time.time() with grpc.insecure_channel(&apos;localhost:50051&apos;) as channel: stub = helloworld_pb2_grpc.GreeterStub(channel) response = stub.SayHello(helloworld_pb2.HelloRequest(name=&apos;小飞&apos;)) print(response) print(&quot;time = &quot;, time.time()-a) print(&quot;Greeter client received: &quot; + response.message) 客户端就比较简单了, 通过grpc 连上50051端口携带参数发起请求, 再接受服务端返回的详情就ok proto文件gRPC 默认使用 protocol buffers 作为接口定义语言, 所以需要编写 proto文件定义 gRPC接口, 进行编译生成 helloworld_pb2 和helloworld_pb2_grpc文件, 也就是客户端和服务端之间的通信, 里面会定义接口接收参数和返回参数.","categories":[],"tags":[{"name":"杂记,GoLang,Python","slug":"杂记-GoLang-Python","permalink":"https://127.0.0.1/blog/tags/杂记-GoLang-Python/"}]},{"title":"Mysql的基础学习","slug":"Mysql的基础学习","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.397Z","comments":true,"path":"2019/05/06/Mysql的基础学习/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/Mysql的基础学习/","excerpt":"","text":"MySQL概念1234567891011121314151617数据： data数据库： DB数据库管理系统：DBMS数据库系统：DBSMySQL：数据库 mysql：客户端命令（用来连接服务或发送sql指令）SQL：结构化查询语言 ，其中MySQL支持这个。SQL语言分为4个部分：DDL（定义）、DML（操作）、DQL（查询）、DCL（控制）MySQL-&gt;库-&gt;表-&gt;数据SQL语句中的快捷键\\G 格式化输出（文本式，竖立显示）\\s 查看服务器端信息\\c 结束命令输入操作\\q 退出当前sql命令行模式\\h 查看帮助 授权123456格式：grant 允许操作 on 库名.表名 to 账号@来源 identified by &apos;密码&apos;; --实例：创建zhangsan账号，密码123，授权lamp61库下所有表的增/删/改/查数据,来源地不限 mysql&gt; grant select,insert,update,delete on lamp61.* to zhangsan@&apos;%&apos; identified by &apos;123&apos;; mysql&gt; grant all on *.* to zhangsan@&apos;%&apos; identified by &apos;123&apos;; Query OK, 0 rows affected (0.00 sec) 连接数据库123456789常用 mysql -u 用户名 -p密码 mysql -h 主机名 -u 用户名 -p密码 库名 C:\\&gt;mysql --采用匿名账号和密码登陆本机服务 C:\\&gt;mysql -h localhost -u root -proot --采用root账号和root密码登陆本机服务 C:\\&gt;mysql -u root -p --推荐方式默认登陆本机 Enter password: **** C:\\&gt;mysql -u root -p lamp61 --直接进入lamp61数据库的方式登陆 数据类型和运算符123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051MySQL的数据类型分为四大类：数值类型、字串类型、日期类型、NULL。 5.1 数值类型： *tinyint(1字节) 0~255 -128~127 smallint(2字节) mediumint(3字节) *int(4字节) bigint(8字节) *float(4字节) float(6,2) *double(8字节) decimal(自定义)字串形数值 5.2 字串类型 普通字串 *char 定长字串 char(8) *varchar 可变字串 varchar(8) 二进制类型 tinyblob blob mediumblob longblob 文本类型 tinytext *text 常用于&lt;textarea&gt;&lt;/textarea&gt; mediumtext longtext *enum枚举 set集合 5.3 时间和日期类型： date 年月日 time 时分秒 datetime 年月日时分秒 timestamp 时间戳 year 年 5.4 NULL值 NULL意味着“没有值”或“未知值” 可以测试某个值是否为NULL 不能对NULL值进行算术计算 对NULL值进行算术运算，其结果还是NULL 0或NULL都意味着假，其余值都意味着真 MySQL的运算符： 算术运算符：+ - * / % 比较运算符：= &gt; &lt; &gt;= &lt;= &lt;&gt; != 数据库特有的比较：in，not in, is null,is not null,like, between and 逻辑运算符：and or not 表的字段约束1234567891011!!! 有先后顺序的关系 unsigned 无符号(正数) zerofill 前导零填充 auto_increment 自增 default 默认值 not null 非空 PRIMARY KEY 主键 （非null并不重复） (包括非空,写主见就不用写非空) unique 唯一性 （可以为null但不重复） index 常规索引 建表格式1234567891011121314 create table 表名( 字段名 类型 [字段约束], 字段名 类型 [字段约束], 字段名 类型 [字段约束], ... );create table stu( -&gt; id int unsigned not null auto_increment primary, -&gt; name varchar(8) not null unique, -&gt; age tinyint unsigned, -&gt; sex enum(&apos;m&apos;,&apos;w&apos;) not null default &apos;m&apos;, -&gt; classid char(6) -&gt; ); 数据库的基本操作数据库12345678show databases; 查看当前所有数据库信息create database 库名; 创建数据库create if not exists 库名; 尝试创建数据库,若已存在则不创建drop database 库名; 删除数据库drop database if exists 库名; 尝试删除数据库show create database 库名\\G; 查看数据库的sql语句use 库名; 进入当前数据库select database(); 查看当前所在数据库位置 数据表123456789show tables; 查看当前所有的表create table [if not exists ] 表名(字段1 类型,字段2 类型,...) 创建数据表,指定字段并指定类型 [尝试创建]desc 表名; 查看表结构show create table 表名; 查看表的见表语句show create table 表名\\G 格式化查看建表语句drop table 表名; 删除数据表dd;drop table if exists 表名; 尝试删除表; 表的数据(增删改查 DML)1234567891011121314151617181920212223242526272829303132-- 表的数据操作（增insert 删delete 改update 查select）--======================================== ! uu 是表名-- 标准添加（指定所有表字段，给定所有字段值进行添加）insert into uu(id,name,age) values(1,&apos;zhangsan&apos;,20); -- 标准添加（不同之处是字段顺序）insert into uu(age,id,name) values(22,2,&apos;lisi&apos;);-- 指定部分字段添加值insert into uu(id,name) values(3,&apos;wangwu&apos;);-- 不指定字段信息添加值，注意字段值得顺序和个数要和表结构一致insert into uu values(4,&apos;zhaoliu&apos;,25);-- 批量添加值insert into uu values(5,&apos;u01&apos;,21),(6,&apos;u02&apos;,22),(7,&apos;u03&apos;,23);-- 查看所有字段所有值select * from uu;-- 修改uu表的id值为3的信息，将age改为18update uu set age=18 where id=3; -- 修改id为6的信息，将age改为28，name改为uu04update uu set age=28,name=&apos;uu04&apos; where id=6;-- 删除id值为100的信息delete from uu where id=100;-- 删除id值大于50的所有信息 delete from uu where id&gt;50; 修改表结构12345678910111213141516171819202122232425262728293031323334353637383940414243444546 格式： alter table 表名 action（更改选项）; 更改选项： 1. 添加字段：alter table 表名 add 字段名信息-- 在user表的最后追加一个num字段 设置为int not null mysql&gt; alter table user add num int not null; -- 在user表的email字段后添加一个age字段，设置int not null default 20； mysql&gt; alter table user add age int not null default 20 after email; -- 在user表的最前面添加一个aa字段设置为int类型 mysql&gt; alter table user add aa int first; 2. 删除字段：alter table 表名 drop 被删除的字段名 例如：-- 删除user表的aa字段 mysql&gt; alter table user drop aa; 3. 修改字段：alter table 表名 change[modify] 被修改后的字段信息 (修改记得必须要写属性值) 其中：change可以修改字段名， modify 不修改 -- 修改user表中age字段信息（类型），（使用modify关键字的目的不修改字段名） mysql&gt; alter table user modify age tinyint unsigned not null default 20; -- 修改user表的num字段改为mm字段并添加了默认值（使用change可以改字段名） mysql&gt; alter table user change num mm int not null default 10; 4. 添加和删除索引 -- 为user表中的name字段添加唯一性索引，索引名为uni_name; mysql&gt; alter table user add unique uni_name(name); -- 为user表中的email字段添加普通索引，索引名为index_eamil mysql&gt; alter table user add index index_email(email); -- 将user表中index_email的索引删除 mysql&gt; alter table user drop index index_email; 5. 更改表名称： ALTER TABLE 旧表名 RENAME AS 新表名 6. 更改AUTO_INCREMENT初始值: ALTER TABLE 表名称 AUTO_INCREMENT=1 7. 更改表类型： ALTER TABLE 表名称 ENGINE=&quot;InnoDB&quot; MySQL数据库中的表类型一般常用两种：MyISAM和InnoDB 区别：MyISAM类型的数据文件有三个frm(结构)、MYD（数据）、MYI（索引） MyISAM类型中的表数据增 删 改速度快，不支持事务，没有InnoDB安全。 InnoDB类型的数据文件只有一个 .frm InnoDB类型的表数据增 删 改速度没有MyISAM的快，但支持事务，相对安全。 数据DQL 操作:数据查询1234567891011121314151617181920212223242526272829303132格式： select [字段列表]|* from 表名 [where 搜索条件] [group by 分组字段 [having 子条件]] [order by 排序 asc|desc] [limit 分页参数] 1. where条件查询 1. 查询班级为lamp138期的学生信息 mysql&gt; select * from stu where classid=&apos;lamp138&apos;; 2. 查询lamp138期的男生信息（sex为m） mysql&gt; select * from stu where classid=&apos;lamp138&apos; and sex=&apos;m&apos;; 3. 查询id号值在10以上的学生信息 mysql&gt; select * from stu where id&gt;10; 4. 查询年龄在20至25岁的学生信息 mysql&gt; select * from stu where age&gt;=20 and age&lt;=25; mysql&gt; select * from stu where age between 20 and 25; 5. 查询年龄不在20至25岁的学生信息 mysql&gt; select * from stu where age not between 20 and 25; mysql&gt; select * from stu where age&lt;20 or age&gt;25; 6. 查询id值为1,8,4,10,14的学生信息 select * from stu where id in(1,8,4,10,14); mysql&gt; select * from stu where id=1 or id=8 or id=4 or id=10 or id=14; 7. 查询lamp138和lamp94期的女生信息 mysql&gt; select * from stu where classid in(&apos;lamp138&apos;,&apos;lamp94&apos;) and sex=&apos;w&apos;; mysql&gt; select * from stu where (classid=&apos;lamp138&apos; or classid=&apos;lamp94&apos;) and sex=&apos;w 查询1234567891011121314151617181920212223242526272829303132333435363738 where条件查询--========================================================--1. 查询id为3的学生信息mysql&gt; select * from stu where id=3;--2. 查询性别sex为m的所有信息mysql&gt; select * from stu where sex=&apos;m&apos;;--3. 查询年龄大于25岁的所有学生信息mysql&gt; select * from stu where age&gt;25;--4. 查询学生年龄是22~27岁的所有信息mysql&gt; select * from stu where age&gt;=22 and age&lt;=27;mysql&gt; select * from stu where age between 22 and 27;--5. 查询学生年龄在20~25岁之外的所有信息mysql&gt; select * from stu where age&lt;20 or age&gt;25;mysql&gt; select * from stu where age not between 20 and 25;--6. 查询性别sex为w，并且年龄大于22岁的所有信息mysql&gt; select * from stu where sex=&apos;w&apos; and age&gt;22;--7. 查询classid不为null的所有信息mysql&gt; select * from stu where classid is not null;--8. 查询id值为1,3,5,9,12的学员信息mysql&gt; select * from stu where id in(1,3,5,9,12);--9. 查询name字段值是以zh开头的所有信息mysql&gt; select * from stu where name like &quot;zh%&quot;;mysql&gt; select * from stu where name regexp &quot;^zh&quot;; --正则写法--10.查询姓名name中含有ang子串的所有信息mysql&gt; select * from stu where name like &quot;%ang%&quot;;mysql&gt; select * from stu where name regexp &quot;ang&quot;;-11. 查询姓名是任意四位字符构成的信息。mysql&gt; select * from stu where name like &quot;____&quot;;mysql&gt; select * from stu where name regexp &quot;^[a-z0-9]&#123;4&#125;$&quot;; 统计函数1234567891011121314151617181920MySQL的统计函数（聚合函数）：max() min() count() sum() avg()- 分组 group by 字段名[,字段名] 统计班级classid值为2的男女生各多少人？select sex,count(*) from stu where classid=2 group by sex;- 排序：order by 字段名[,字段名] desc|asc-- asc 默认升序 desc 降序 获取每个班级的平均年龄，并按平均年龄降序， select classid,avg(age) from stu group by classid order by avg(age) desc; select classid,avg(age) anum from stu group by classid order by anum desc; -- limit 关键字 查询部分数据 -- 例如： .... limit m; 查询数据只显示前m条 -- 例如： .... limit m,n; 排除前m条，然后再查询出前n条 统计每个班级的人数，按人数从大到小排序，取前3条。 select classid,count(*) num from stu group by classid order by num desc limit 3;分页公式：.... (页号-1)*页大小, 页大小; 多表查询123456789101112131415161718表之间的关系有：1对1 1对多 多对多1. 嵌套查询， 一个查询的结果是另外sql的条件2. where关联查询 3. join连接查询（左联，右联，内联）-- 查询年龄最大的所有学生信息mysql&gt; select * from stu where age=(select max(age) from stu);+----+---------+------+-----+---------+| id | name | age | sex | classid |+----+---------+------+-----+---------+| 9 | xiaoli | 29 | w | 2 || 14 | zhangle | 29 | m | 5 |+----+---------+------+-----+---------+-- 查询python02期的所有学生信息mysql&gt; select * from stu where classid=(select id from classes where name=&apos;python02&apos;);mysql&gt; select * from stu where classid in(select id from classes where name=&apos;python02&apos;); 123456789101112where关联查询已知：员工personnel表和部门department表，其中员工表中的did字段为部门表id主键关联。 查询所有员工信息，并显示所属部门名称要求：显示字段：员工id 部门 姓名mysql&gt; select p.id,d.name,p.name from personnel p,department d where p.did = d.id; +----+-----------+-----------+ | id | name | name | +----+-----------+-----------+ | 2 | 人事部 | 李玉刚 | | 10 | 人事部 | 阿杜 | | 4 | 市场部 | 刘欢 | 1234567891011121314151617连接join查询左联：left join右联：right join内联：inner join查询新闻信息，并补齐新闻类别信息mysql&gt; select n.id,n.title,t.name from news n,ntype t where n.ntid=t.id;mysql&gt; select n.id,n.title,t.name from news n inner join ntype t on n.ntid=t.id;同上，但采用的是左联查询left joinmysql&gt; select n.id,n.title,t.name from news n left join ntype t on n.ntid=t.id;统计每个新闻类别下的新闻数量，采用where关联统计mysql&gt; select t.name,count(n.id) from ntype t,news n where t.id=n.ntid group by t.id;统计每个新闻类别下的新闻数量，采用左联统计mysql&gt; select t.name,count(n.id) from ntype t left join news n on t.id=n.ntid group by t.id; 1对11234567891011121314151617181920212223242526272829303132333435363738394041424344454647已知如下表所示，商品类别信息表（具有两层类别关系，通过pid表示，0表示一级类别）mysql&gt; select * from type;+----+-----------+------+| id | name | pid |+----+-----------+------+| 1 | 服装 | 0 || 2 | 数码 | 0 || 3 | 男装 | 1 || 4 | 手机 | 2 || 5 | 相机 | 2 || 6 | 电脑 | 2 || 7 | 女装 | 1 || 8 | 童装 | 1 || 9 | 食品 | 0 || 10 | 零食 | 9 || 11 | 特产 | 9 || 12 | 休闲装 | 1 |+----+-----------+------+-- 查询二级类别信息，并关联出他们的父类别名称mysql&gt; select t1.id,t1.name,t2.name from type t1,type t2 where t1.pid!=0 and t1.pid=t2.id;+----+-----------+--------+| id | name | name |+----+-----------+--------+| 3 | 男装 | 服装 || 4 | 手机 | 数码 || 5 | 相机 | 数码 || 6 | 电脑 | 数码 || 7 | 女装 | 服装 || 8 | 童装 | 服装 || 10 | 零食 | 食品 || 11 | 特产 | 食品 || 12 | 休闲装 | 服装 |+----+-----------+--------+9 rows in set (0.01 sec)--统计每个一级类别下都有多少个子类别。mysql&gt; select t1.id,t1.name,count(t2.id) from type t1,type t2 where t1.pid=0 and t1.id=t2.pid group by t1.id;+----+--------+--------------+| id | name | count(t2.id) |+----+--------+--------------+| 1 | 服装 | 4 || 2 | 数码 | 3 || 9 | 食品 | 2 |+----+--------+--------------+3 rows in set (0.00 sec) 数据库的备份和导入1234567891011-- 数据库mydb备份[root@localhost mnt]# mysqldump -u root -p mydb &gt; mydb.sqlpassword：-- 备份 mydb库中的stu表[root@localhost mnt]# mysqldump -u root -p mydb stu &gt; stu.sqlpassword：-- 恢复数据（导入）注：mydb库要存在[root@localhost mnt]# mysql -u root -p mydb &lt; mydb.sql[root@localhost mnt]# mysql -u root -p mydb &lt; stu.sql 数据库日志的备份和导入1234567891011121314151617181920212223242526mysql日志 vim /etc/my.cnf 产看下面这句话56行 开启日志： 在mysql配置文件中开启：log-bin=mysql-bin 查看bin-log日志: mysql&gt;show binary logs; 查看最后一个bin-log日志: mysql&gt;show master status; 此时就会多一个最新的bin-log日志 mysql&gt;flush logs; 查看最后一个bin日志. mysql&gt;show master status; mysql&gt;reset master; 清空所有的bin-log日志 执行查看bin-log日志 备份数据: mysqldump -u 用户名 -p 库名 -l -F 库名&gt; 库名.sql 其中：-F即flush logs，可以重新生成新的日志文件，当然包括log-bin日志 // Linux关闭MySQL的命令 $mysql_dir/bin/mysqladmin -uroot -p shutdown // linux启动MySQL的命令 $mysql_dir/bin/mysqld_safe &amp; MySql的其他操作1231 表复制 2表的索引 3视图4 内置函数 5 事务处理 6 触发器7 日志 8 有关慢查询操作 9 数据库的恢复 1234567891011121. MySQL的表复制 复制表结构 mysql&gt; create table 目标表名 like 原表名; 复制表数据 mysql&gt; insert into 目标表名 select * from 原表名; create table stu2 like stu;复制stu 名为stu2 ; 只复制结构不复制内容insert into stu2 select * from stu limit 5;赋值stu数据前五条添加到 stu2; 12345672. 数据表的索引 创建索引 CREATE INDEX index_name ON table_name (column_list) CREATE UNIQUE INDEX index_name ON table_name (column_list) 删除索引 DROP INDEX index_name ON talbe_name 123456789101112131415163. mysql视图 创建视图: mysql&gt; create view v_t1 as select * from t1 where id&gt;4 and id&lt;11; Query OK, 0 rows affected (0.00 sec) view视图的帮助信息: mysql&gt; ? view ALTER VIEW CREATE VIEW DROP VIEW 查看视图: mysql&gt; show tables; 删除视图v_t1: mysql&gt; drop view v_t1; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657584. MySQL的内置函数 字符串处理函数 --------------------------------------------- *concat(s1,s2,…Sn) 连接s1,s2..Sn为一个字符串 insert(str,x,y,instr)将字符串str从第xx位置开始，y字符串的子字符串替换为字符串str lower(str)将所有的字符串变为小写 upper(str)将所有的字符串变为大写 left(str,x)返回字符串中最左边的x个字符 rigth(str,y)返回字符串中最右边的x个字符 lpad(str,n,pad)用字符串pad对str最左边进行填充，直到长度为n个字符串长度 rpad(str,n,pad)用字符串pad对str最右边进行填充，直到长度为n个字符串长度 trim(str) 去掉左右两边的空格 ltrim(str) 去掉字符串str左侧的空格 rtrim(str) 去掉字符串str右侧的空格 repeat(str,x) 返回字符串str重复x次 replace(str,a,b)将字符串的的a替换成b strcmp(s1,s2) 比较字符串s1和s2 substring(s,x,y)返回字符串指定的长度 *length(str) 返回值为字符串str 的长度 数值函数 ----------------------------------------------------- *abs(x) 返回x的绝对值 ceil(x) 返回大于x的最小整数值 floor(x) 返回小于x的最大整数值 mod(x,y) 返回x/y的取余结果 rand() 返回0~1之间的随机数 *round(x,y)返回参数x的四舍五入的有y位小数的值 truncate(x,y) 返回x截断为y位小数的结果 日期和时间函数 --------------------------------------------------- curdate() 返回当前日期,按照’YYYY-MM-DD’格式 curtime() 返回当前时间,当前时间以&apos;HH:MM:SS&apos; *now() 返回当前日期和时间, *unix_timestamp(date) 返回date时间的unix时间戳 from_unixtime(unix_timestamp[,format]) 返回unix时间的时间 week(date) 返回日期是一年中的第几周 year(date) 返回日期的年份 hour(time) 返回time的小时值 minute(time) 返回日time的分钟值 monthname(date) 返回date的月份 *date_fomat(date,fmt) 返回按字符串fmt格式化日期date值 date_add(date,INTERVAL,expr type) 返回一个日期或者时间值加上一个时间间隔的时间值 *datediff(expr,expr2) 返回起始时间和结束时间的间隔天数 //统计时间戳647583423距离当前时间相差天数（生日天数（不考虑年份）） mysql&gt; select datediff(date_format(from_unixtime(647583423),&quot;2017-%m-%d %h:%i:%s&quot;),now()); 其他常用函数 ------------------------------------------------------ *database() 返回当前数据库名 version() 返回当前服务器版本 user() 返回当前登陆用户名 inet_aton 返回当前IP地址的数字表示 inet_aton(&quot;192.168.80.250&quot;); inet_ntoa(num) 返回当前数字表示的ip inet_ntoa(3232256250); *password(str) 返回当前str的加密版本 *md5(str) 返回字符串str的md5值 123456789101112131415161718195. MySQL的事务处理 关闭自动提交功能（开启手动事务） mysql&gt; set autocommit=0; 从表t1中删除了一条记录 mysql&gt; delete from t1 where id=11; 此时做一个p1还原点: mysql&gt; savepoint p1; 再次从表t1中删除一条记录: mysql&gt; delete from t1 where id=10; 再次做一个p2还原点: mysql&gt; savepoint p2; 此时恢复到p1还原点，当然后面的p2这些还原点自动会失效: mysql&gt; rollback to p1; 退回到最原始的还原点: mysql&gt; rollback; 回滚 开启自动事务提交（关闭手动事务） mysql&gt; set autocommit=1; 123456789101112131415161718192021226. MySQL的触发器 格式：1、触发器的定义： CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt 说明： # trigger_name：触发器名称 # trigger_time:触发时间，可取值：BEFORE或AFTER # trigger_event：触发事件，可取值：INSERT、UPDATE或DELETE。 # tb1_name：指定在哪个表上 # trigger_stmt：触发处理SQL语句。 示例： mysql&gt; delimiter $$ mysql&gt; create trigger del_stu before delete on stu for each row -&gt; begin -&gt; insert into stu_bak values(old.id,old.name,old.sex,old.age,old.addtime); -&gt; end; -&gt; $$ Query OK, 0 rows affected (0.05 sec) mysql&gt; delimiter ; 123456789101112131415161718192021222324252627287. mysql日志 进入 /usr/my.cnf 开启日志： 在mysql配置文件中开启：log-bin=mysql-bin 查看bin-log日志: mysql&gt;show binary logs; 查看最后一个bin-log日志: mysql&gt;show master status; 此时就会多一个最新的bin-log日志 mysql&gt;flush logs; 查看最后一个bin日志. mysql&gt;show master status; mysql&gt;reset master; 清空所有的bin-log日志 执行查看bin-log日志 备份数据: mysqldump -uroot -pwei test -l -F &apos;/tmp/test.sql&apos; 其中：-F即flush logs，可以重新生成新的日志文件，当然包括log-bin日志 // Linux关闭MySQL的命令 $mysql_dir/bin/mysqladmin -uroot -p shutdown // linux启动MySQL的命令 $mysql_dir/bin/mysqld_safe &amp; 1234567898、有关慢查询操作： 开户和设置慢查询时间: vi /etc/my.cnf log_slow_queries=slow.log long_query_time=5 查看设置后是否生效 mysql&gt; show variables like &quot;%quer%&quot;; 慢查询次数: mysql&gt; show global status like &quot;%quer%&quot;; 12345678910119 数据库的恢复 1. 首先恢复最后一次的备份完整数据 [root@localhost mnt]# mysql -u root -p mydemo&lt;mydemo_2017-7-26.sql Enter password: 2. 查看bin-log日志 [root@localhost data]# mysqlbinlog --no-defaults mysql-bin.000009; 查找到恢复的节点 3. 执行bin-log日志文件，恢复最后一块的增量数据。 [root@localhost data]# mysqlbinlog --no-defaults --stop-position=&quot;802&quot; mysql-bin.000009|mysql -u root -p123456 mydemo; Python3 Mysql数据库连接123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167 Python3 MySQL 数据库连接======================================================1. 什么是 PyMySQL？ PyMySQL 是在 Python3.x 版本中用于连接 MySQL 服务器的一个库，Python2中则使用mysqldb。 PyMySQL 遵循 Python 数据库 API v2.0 规范，并包含了 pure-Python MySQL 客户端库。 2. PyMySQL安装 PyMySQL下载地址：https://github.com/PyMySQL/PyMySQL。 2.1 使用pip命令进行安装： $ pip install PyMySQL 2.2 使用 git 命令下载安装包安装(你也可以手动下载)： $ git clone https://github.com/PyMySQL/PyMySQL $ cd PyMySQL/ $ python3 setup.py install 3. 数据库连接 通过如下代码测试数据库连接---------------------------------------------------------------------- #!/usr/bin/python3 import pymysql # 打开数据库连接 db = pymysql.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;123456&quot;,&quot;mydb&quot; ) # 使用 cursor() 方法创建一个游标对象 cursor cursor = db.cursor() # 使用 execute() 方法执行 SQL 查询 cursor.execute(&quot;SELECT VERSION()&quot;) # 使用 fetchone() 方法获取单条数据. data = cursor.fetchone() print (&quot;Database version : %s &quot; % data) # 关闭数据库连接 db.close() 4. 执行数据查询：------------------------------------------------------------------- #!/usr/bin/python3 import pymysql # 打开数据库连接 db = pymysql.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;&quot;,&quot;mydemo&quot; ) # 使用 cursor() 方法创建一个游标对象 cursor cursor = db.cursor() # SQL 查询语句 sql = &quot;select * from stu limit %d&quot; % (3) #sql = &quot;select * from stu&quot; try: # 执行SQL语句 cursor.execute(sql) # 获取所有记录列表 results = cursor.fetchall() for row in results: id = row[0] name = row[1] sex = row[2] age = row[3] classid = row[4] # 打印结果 print (&quot;id=%d,name=%s,sex=%s,age=%d,classid=%s&quot; % (id,name,sex,age,classid)) except: print (&quot;Error: unable to fetch data&quot;) # 关闭数据库连接 db.close() 5. 执行数据添加---------------------------------------------------------------------#!/usr/bin/python3import pymysql# 打开数据库连接db = pymysql.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;&quot;,&quot;mydemo&quot; )# 使用 cursor() 方法创建一个游标对象 cursorcursor = db.cursor()# SQL 插入语句sql = &quot;INSERT INTO stu(name,sex,age,classid) values(&apos;%s&apos;,&apos;%c&apos;,&apos;%d&apos;,&apos;%s&apos;)&quot; % (&apos;uu142&apos;,&apos;m&apos;,22,&apos;lamp180&apos;) try: # 执行sql语句 cursor.execute(sql) # 执行sql语句 db.commit() print(&quot;ok: %d &quot; % (cursor.rowcount))except: # 发生错误时回滚 db.rollback()# 关闭数据库连接db.close() 6. 执行删除操作--------------------------------------------------------------------- #!/usr/bin/python3 import pymysql # 打开数据库连接 db = pymysql.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;&quot;,&quot;mydemo&quot; ) # 使用 cursor() 方法创建一个游标对象 cursor cursor = db.cursor() # SQL 删除语句 sql = &quot;delete from stu where id = &apos;%d&apos;&quot; % (13) try: # 执行SQL语句 cursor.execute(sql) # 提交修改 db.commit() except: # 发生错误时回滚 db.rollback() # 关闭数据库连接 db.close() 数据库查询操作： Python查询Mysql使用 fetchone() 方法获取单条数据, 使用fetchall() 方法获取多条数据。 fetchone(): 该方法获取下一个查询结果集。结果集是一个对象 fetchall(): 接收全部的返回结果行. rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。 pip命令------------------------------------------------------------列出已安装的包： $ pip list $ pip freeze # 查看自己安装的安装软件（安装特定版本的package，通过使用==, &amp;gt;=, &amp;lt;=, &amp;gt;, &amp;lt;来指定一个版本号）** $ pip install SomePackage $ pip install &apos;Markdown&lt;2.0&apos; $ pip install &apos;Markdown&gt;2.0,&lt;2.0.3&apos; 卸载软件pip uninstall SomePackage $ pip uninstall SomePackage 下载所需的软件包： $ pip download SomePackage -d directory 例如下载PyMySQL软件包 $ pip download PyMySQL -d D:/pypackage安装下载好的软件包文件 $ pip install 目录/软件包文件名 如安装PyMySQL软件包 $ pip install D:/pypackage/PyMySQL-0.7.11-py2.py3-none-any.whl 修改完结符1\\d $$ 把最后的完结符号由;改为$$ 用于写代码时用 python3 Mysql数据库连接123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141 Python3 MySQL 数据库连接======================================================1. 什么是 PyMySQL？ PyMySQL 是在 Python3.x 版本中用于连接 MySQL 服务器的一个库，Python2中则使用mysqldb。 PyMySQL 遵循 Python 数据库 API v2.0 规范，并包含了 pure-Python MySQL 客户端库。 2. PyMySQL安装 PyMySQL下载地址：https://github.com/PyMySQL/PyMySQL。 2.1 使用pip命令进行安装： $ pip install PyMySQL 2.2 使用 git 命令下载安装包安装(你也可以手动下载)： $ git clone https://github.com/PyMySQL/PyMySQL $ cd PyMySQL/ $ python3 setup.py install 3. 数据库连接 通过如下代码测试数据库连接---------------------------------------------------------------------- #!/usr/bin/python3 import pymysql # 打开数据库连接 db = pymysql.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;123456&quot;,&quot;mydb&quot; ) # 使用 cursor() 方法创建一个游标对象 cursor cursor = db.cursor() # 使用 execute() 方法执行 SQL 查询 cursor.execute(&quot;SELECT VERSION()&quot;) # 使用 fetchone() 方法获取单条数据. data = cursor.fetchone() print (&quot;Database version : %s &quot; % data) # 关闭数据库连接 db.close() 4. 执行数据查询：------------------------------------------------------------------- #!/usr/bin/python3 import pymysql # 打开数据库连接 db = pymysql.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;&quot;,&quot;mydemo&quot; ) # 使用 cursor() 方法创建一个游标对象 cursor cursor = db.cursor() # SQL 查询语句 sql = &quot;select * from stu limit %d&quot; % (3) #sql = &quot;select * from stu&quot; try: # 执行SQL语句 cursor.execute(sql) # 获取所有记录列表 results = cursor.fetchall() for row in results: id = row[0] name = row[1] sex = row[2] age = row[3] classid = row[4] # 打印结果 print (&quot;id=%d,name=%s,sex=%s,age=%d,classid=%s&quot; % (id,name,sex,age,classid)) except: print (&quot;Error: unable to fetch data&quot;) # 关闭数据库连接 db.close() 5. 执行数据添加---------------------------------------------------------------------#!/usr/bin/python3import pymysql# 打开数据库连接db = pymysql.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;&quot;,&quot;mydemo&quot; )# 使用 cursor() 方法创建一个游标对象 cursorcursor = db.cursor()# SQL 插入语句sql = &quot;INSERT INTO stu(name,sex,age,classid) values(&apos;%s&apos;,&apos;%c&apos;,&apos;%d&apos;,&apos;%s&apos;)&quot; % (&apos;uu142&apos;,&apos;m&apos;,22,&apos;lamp180&apos;) try: # 执行sql语句 cursor.execute(sql) # 执行sql语句 db.commit() print(&quot;ok: %d &quot; % (cursor.rowcount))except: # 发生错误时回滚 db.rollback()# 关闭数据库连接db.close() 6. 执行删除操作--------------------------------------------------------------------- #!/usr/bin/python3 import pymysql # 打开数据库连接 db = pymysql.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;&quot;,&quot;mydemo&quot; ) # 使用 cursor() 方法创建一个游标对象 cursor cursor = db.cursor() # SQL 删除语句 sql = &quot;delete from stu where id = &apos;%d&apos;&quot; % (13) try: # 执行SQL语句 cursor.execute(sql) # 提交修改 db.commit() except: # 发生错误时回滚 db.rollback() # 关闭数据库连接 db.close() 数据库查询操作： Python查询Mysql使用 fetchone() 方法获取单条数据, 使用fetchall() 方法获取多条数据。 fetchone(): 该方法获取下一个查询结果集。结果集是一个对象 fetchall(): 接收全部的返回结果行. rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。 pip123456789101112131415161718192021222324 pip命令------------------------------------------------------------列出已安装的包： $ pip list $ pip freeze # 查看自己安装的安装软件（安装特定版本的package，通过使用==, &amp;gt;=, &amp;lt;=, &amp;gt;, &amp;lt;来指定一个版本号）** $ pip install SomePackage $ pip install &apos;Markdown&lt;2.0&apos; $ pip install &apos;Markdown&gt;2.0,&lt;2.0.3&apos; 卸载软件pip uninstall SomePackage $ pip uninstall SomePackage 下载所需的软件包： $ pip download SomePackage -d directory 例如下载PyMySQL软件包 $ pip download PyMySQL -d D:/pypackage安装下载好的软件包文件 $ pip install 目录/软件包文件名 如安装PyMySQL软件包 $ pip install D:/pypackage/PyMySQL-0.7.11-py2.py3-none-any.whl","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"Linux 下python文件多行注释的方法","slug":"Linux 下python文件多行注释的方法","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.396Z","comments":true,"path":"2019/05/06/Linux 下python文件多行注释的方法/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/Linux 下python文件多行注释的方法/","excerpt":"","text":"按 ctrl+v进入visual block模式（可视化模式）,然后选择想要注释的内容, 然后按 I(大写),加入#号,按两下 esc,OK了 取消注释也很简单,ctrl+v选择好之后,按 d 就可以了","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://127.0.0.1/blog/tags/linux/"}]},{"title":"Requests 和 Scrapy 添加动态IP代理","slug":"Requests 和 Scrapy 添加动态IP代理","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.398Z","comments":true,"path":"2019/05/06/Requests 和 Scrapy 添加动态IP代理/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/Requests 和 Scrapy 添加动态IP代理/","excerpt":"","text":"###Requests import requests # 要访问的目标页面 targetUrl = &quot;http://test.abuyun.com/proxy.php&quot; #targetUrl = &quot;http://proxy.abuyun.com/switch-ip&quot; #targetUrl = &quot;http://proxy.abuyun.com/current-ip&quot; # 代理服务器 proxyHost = &quot;proxy.abuyun.com&quot; proxyPort = &quot;9000&quot; # 代理隧道验证信息 proxyUser = &quot;H225506235A2NG0p&quot; proxyPass = &quot;123456&quot; proxyMeta = &quot;http://%(user)s:%(pass)s@%(host)s:%(port)s&quot; % { &quot;host&quot; : proxyHost, &quot;port&quot; : proxyPort, &quot;user&quot; : proxyUser, &quot;pass&quot; : proxyPass, } proxies = { &quot;http&quot; : proxyMeta, &quot;https&quot; : proxyMeta, } res = requests.get(targetUrl, proxies=proxies).text print(res.text) #####scrapy import base64 from scrapy.downloadermiddlewares.httpproxy import HttpProxyMiddleware # 代理服务器 proxyServer = &quot;http://proxy.abuyun.com:9010&quot; # 隧道身份信息 proxyUser = &quot;H225506235A2NG0p&quot; proxyPass = &quot;123456&quot; proxyAuth = &quot;Basic &quot; + str(base64.b64encode(str(proxyUser + &quot;:&quot; + proxyPass).encode(&apos;utf-8&apos;)), encoding=&apos;utf-8&apos;) class ProxyMiddleware(HttpProxyMiddleware): proxies = {} def __init__(self, auth_encoding=&apos;latin-1&apos;): self.auth_encoding = auth_encoding self.proxies[proxyServer] = proxyUser + proxyPass def process_request(self, request, spider): request.meta[&quot;proxy&quot;] = proxyServer request.headers[&quot;Proxy-Authorization&quot;] = proxyAuth","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"Scrapy中加入selenium+PhantomJS","slug":"Scrapy中加入selenium+PhantomJS","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.399Z","comments":true,"path":"2019/05/06/Scrapy中加入selenium+PhantomJS/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/Scrapy中加入selenium+PhantomJS/","excerpt":"","text":"人生不如意之事十有八九,最近遇到了一个棘手的网站,防爬贼硬,所以喽,就想到了把phantomjs加入到公司的框架中,然后种子利用框架进行爬取,详情一就用scrapy;​ 不说废话,直接上代码,不多 在中间键中,加入一个phantomjs的类 123456789101112131415from selenium import webdriverfrom scrapy.http import HtmlResponseclass PhantomJSMiddleware(object): @classmethod def process_request(cls, request, spider): driver = webdriver.PhantomJS( executable_path=r&quot;../phantomjs_w/bin/phantomjs&quot;)#路径自己定义 driver.get(request.url) content = driver.page_source.encode(&apos;utf-8&apos;) driver.quit() print &apos;success&apos; return HtmlResponse(request.url, encoding=&apos;utf-8&apos;, body=content, request=request)#将phantomjs得到的数据返回到scrapy的处理器进行处理 然后在settings里加入中间键权重 123#可以写个判断,传入固定的某个值才会触发这个中间件,毕竟phantomjs确实是慢,很影响效率,我只用它爬这个网站的种子&apos;ceshi.middlewares.PhantomJSMiddleware&apos;:500, #权重自己定义,看自己框架规则 这就就OK了,可以放心大胆地写爬虫了,友情提醒,少用这个,毕竟效率真的是慢,遇到反爬严重的可以用这个,还有注意自己公司的框架中间件,改好权重值,不然可能顺序错乱,一般用最后就好","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"collapse中点击事件和for循环的添加","slug":"collapse中点击事件和for循环的添加","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.400Z","comments":true,"path":"2019/05/06/collapse中点击事件和for循环的添加/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/collapse中点击事件和for循环的添加/","excerpt":"","text":"因为有些样式要用手风琴效果,然后代码写上之后发现 el-collapse-item里面不能用点击事件,我的代码本来是123456789101112131415161718&lt;el-collapse :data=&quot;menuList&quot; v-for=&quot;(menu,index) in menuList&quot; accordion&gt; &lt;el-collapse-item :title=&quot;menu.field&quot; @click=&quot;details_list(index,menuList)&quot; :name=&quot;index&quot; &gt; &lt;div &gt; &lt;el-table :data=&quot;details_lis&quot; element-loading-text=&quot;给我一点时间&quot; border fit highlight-current-row style=&quot;width: 100%&quot;&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;字段&quot; min-width=&quot;100%&quot;&gt; &lt;template scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.key &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;参数&quot; min-width=&quot;100%&quot;&gt; &lt;template scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.value &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt; &lt;/div&gt; &lt;/el-collapse-item&gt; &lt;/el-collapse&gt; 哇,怎么试都不行,不停在调位置,然后最后参考了一个segmentfault的多级嵌套的点击事件,发现他的点击事件都是在div标签中写的,于是问题解决,代码如下 1234567891011121314151617181920&lt;el-collapse :data=&quot;menuList&quot; accordion&gt; &lt;div v-for=&quot;(menu,index) in menuList&quot; @click=&quot;details_list(index,menuList)&quot;&gt; &lt;el-collapse-item :title=&quot;menu.field&quot; :name=&quot;index&quot; &gt; &lt;div &gt; &lt;el-table :data=&quot;details_lis&quot; element-loading-text=&quot;给我一点时间&quot; border fit highlight-current-row style=&quot;width: 100%&quot;&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;字段&quot; min-width=&quot;100%&quot;&gt; &lt;template scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.key &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;参数&quot; min-width=&quot;100%&quot;&gt; &lt;template scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.value &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt; &lt;/div&gt; &lt;/el-collapse-item&gt; &lt;/div&gt; &lt;/el-collapse&gt;","categories":[],"tags":[{"name":"web前端","slug":"web前端","permalink":"https://127.0.0.1/blog/tags/web前端/"}]},{"title":"Web知识的学习","slug":"Web知识的学习","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.400Z","comments":true,"path":"2019/05/06/Web知识的学习/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/Web知识的学习/","excerpt":"","text":"HTML前端三大块1231、HTML：页面结构2、CSS：页面表现：元素大小、颜色、位置、隐藏或显示、部分动画效果3、JavaScript：页面行为：部分动画效果、页面与用户的交互、页面功能 基本结构12345678910&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;网页标题&lt;/title&gt;&lt;/head&gt;&lt;body&gt; 网页显示内容&lt;/body&gt;&lt;/html&gt; 设置网页编码： 关键字： 描述： 网页标题：本网页标题 导入CSS文件： CSS代码：嵌入css样式代码 JS文件或代码： 。。。 标题123&lt;h1&gt;这是一级标题&lt;/h1&gt;&lt;h2&gt;这是二级标题&lt;/h2&gt;&lt;h3&gt;这是三级标题&lt;/h3&gt; 通过 、、、、、,标签可以在网页上定义6种级别的标题 HTML段落,换行,字符实体 内容 段落标签 换行标签 带有行线的换行标签 &amp;nbsp； 空格 12&amp;lt; 小于号&amp;gt; 大于号 html块元素div标签 块元素，表示一块内容，没有具体的语义 ★行内元素span标签 行内元素，表示一行中的一小段内容，没有具体的语义。 含样式的标签12345em标签 行内元素，表示语气中的强调词i标签 行内元素，原本没有语义，w3c强加了语义，表示专业词汇b标签 行内元素，原本没有语义，w3c强加了语义，表示文档中的关键字或者产品名strong标签 行内元素，表示非常重要的内容del 删除线 html图片1&lt;img src=&quot;images/pic.jpg&quot; alt=&quot;产品图片&quot; /&gt; 标签可以在网页上插入一张图片，它是独立使用的标签，通过“src”属性定义图片的地址，通过“alt”属性定义图片加载失败时显示的文字，以及对搜索引擎和盲人读屏软件的支持。 html链接 与锚点跳转链接 1234567891011&lt;a href=&quot;#&quot;&gt;&lt;/a&gt; &lt;!-- # 表示链接到页面顶部 --&gt;&lt;a href=&quot;http://www.itxdl.cn/&quot; title=&quot;跳转的it兄弟连网站&quot;&gt;兄弟连&lt;/a&gt;&lt;a href=&quot;2.html&quot;&gt;测试页面2&lt;/a&gt;href（必须） 指的是链接跳转地址target: 表示链接的打开方式： _blank 新窗口title属性定义鼠标悬停时弹出的提示文字框&lt;!-- href属性中的url可以携带参数 ?分割后 携带参数 键=值 多个参数之间用&amp;分割--&gt; &lt;a href=&quot;./3.html?id=1&amp;name=zhangsan&amp;sex=nan&quot;&gt;京东&lt;/a&gt; 锚点：定义页面内滚动跳转 1234&lt;a href=&quot;#mao1&quot;&gt;标题一&lt;/a&gt;............&lt;h3 id=&quot;mao1&quot;&gt;跳转到的标题&lt;/h3&gt; 列表有序列表12345&lt;ol&gt; &lt;li&gt;列表文字一&lt;/li&gt; &lt;li&gt;列表文字二&lt;/li&gt; &lt;li&gt;列表文字三&lt;/li&gt;&lt;/ol&gt; ★无序列表123456&lt;ul&gt; &lt;li&gt;列表文字一&lt;/li&gt; &lt;li&gt;列表文字二&lt;/li&gt; &lt;li&gt;列表文字三&lt;/li&gt;&lt;/ul&gt;去li前面的点: list-style:none 定义列表123456789101112&lt;h3&gt;前端三大块&lt;/h3&gt;&lt;dl&gt; &lt;dt&gt;html&lt;/dt&gt; &lt;dd&gt;负责页面的结构&lt;/dd&gt; &lt;dt&gt;css&lt;/dt&gt; &lt;dd&gt;负责页面的表现&lt;/dd&gt; &lt;dt&gt;javascript&lt;/dt&gt; &lt;dd&gt;负责页面的行为&lt;/dd&gt;&lt;/dl&gt; 表格12345678910&lt;table&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; ........ &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;内容&lt;/td&gt; ............ &lt;/tr&gt;&lt;/table&gt; table常用标签1、table标签：声明一个表格 2、tr标签：定义表格中的一行 3、td和th标签：定义一行中的一个单元格，td代表普通单元格，th表示表头单元格 table常用属性123456789101112131、border 定义表格的边框2、cellpadding 定义单元格内内容与边框的距离3、cellspacing 定义单元格与单元格之间的距离4、align 设置单元格中内容的水平对齐方式,设置值有：left | center | right5、valign 设置单元格中内容的垂直对齐方式 top | middle | bottom6、colspan 设置单元格水平合并7、rowspan 设置单元格垂直合并 ★html表单:form12&lt;form action=&quot;http://www...&quot; method=&quot;get&quot;&gt;&lt;/from&gt; form表单中 action 表示数据提交的地址url method代表提交数据的方式方法 get post get提交方式,数据在地址栏 可见,而且数据长度有限制 218k post提交,地址栏不可见,数据长度 2m 123&lt;p&gt; &lt;label&gt;姓名：&lt;/label&gt;&lt;input type=&quot;text&quot; name=&quot;username&quot; /&gt;&lt;/p&gt; label标签 定义表单控件的文字标注 input 类型为 text 定义了一个单行文本输入框 123&lt;p&gt; &lt;label&gt;密码：&lt;/label&gt;&lt;input type=&quot;password&quot; name=&quot;password&quot; /&gt;&lt;/p&gt; input类型为password定义了一个密码输入框 123456&lt;p&gt; &lt;label&gt;性别：&lt;/label&gt; &lt;input type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;0&quot; /&gt; 男 &lt;input type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;1&quot; /&gt; 女&lt;/p&gt;name 属性决定是否关联,name一样则所有的都是单选 input类型为radio定义了单选框 123456&lt;p&gt; &lt;label&gt;爱好：&lt;/label&gt; &lt;input type=&quot;checkbox&quot; name=&quot;like&quot; value=&quot;sing&quot; /&gt; 唱歌 &lt;input type=&quot;checkbox&quot; name=&quot;like&quot; value=&quot;run&quot; /&gt; 跑步 &lt;input type=&quot;checkbox&quot; name=&quot;like&quot; value=&quot;swiming&quot; /&gt; 游泳&lt;/p&gt; input类型为checkbox定义了单选框 1234&lt;p&gt; &lt;label&gt;照片：&lt;/label&gt; &lt;input type=&quot;file&quot; name=&quot;person_pic&quot;&gt;&lt;/p&gt; input类型为file定义上传照片或文件等资源 如果表单中含有文件上传method提交方式必须为post form中必须有enctype属性 enctype=”multipart/form-data” 123456789&lt;p&gt; &lt;label&gt;籍贯：&lt;/label&gt; &lt;select name=&quot;site&quot;&gt; &lt;option value=&quot;0&quot;&gt;北京&lt;/option&gt; &lt;option value=&quot;1&quot;&gt;上海&lt;/option&gt; &lt;option value=&quot;2&quot;&gt;广州&lt;/option&gt; &lt;option value=&quot;3&quot;&gt;深圳&lt;/option&gt; &lt;/select&gt;&lt;/p&gt; select定义下拉列表选择 1隐藏域:&lt;input type=&quot;hidden&quot; name=&quot;id&quot; value=&quot;110&quot;&gt; 123&lt;input type=&quot;submit&quot; value=&quot;注册&quot;&gt;&lt;input type=&quot;reset&quot; value=&quot;重置&quot;&gt;&lt;button&gt;登录&lt;/button&gt; input类型为submit定义提交按钮 input类型为reset定义重置按钮 type属性12345678910text:单行文本框password:密码输入框 checkbox:多选框 注意要提供value值 radio:单选框 注意要提供value值 file:文件上传选择框 button:普通按钮 submit:提交按钮 image:图片提交按钮 reset:重置按钮, 还原到开始\\(第一次打开时\\)的效果 hidden:主表单隐藏域,要是和表单一块提交的信息,但是不需要用户修改 常用属性name属性:表单项名,用于存储内容值的 value属性:输入的值(默认指定值) size属性:输入框 readonly属性:对输入框只读属性的宽度值 disabled属性:禁用属性 checked属性:对选择框指定默认选项 12&lt;input type=&quot;submit&quot; value=&apos;注册&apos; disabled&gt; 生成一个不可点击的按钮 CSS基本语法css的定义方法是：选择器 { 属性:值; 属性:值; 属性:值;} 1、外联式：通过link标签，链接到外部样式表到页面中： 1&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/main.css&quot;&gt; 2，嵌入式：通过style标签，在网页上创建嵌入的样式表： 1234&lt;style type=&quot;text/css&quot;&gt; div&#123; width:100px; height:100px; color:red &#125; ......&lt;/style&gt; 3、内联式：通过标签的style属性，在标签上直接写样式： 123&lt;div style=&quot;width:100px; height:100px; color:red &quot;&gt;......&lt;/div&gt; css颜色颜色名表示，比如：red 红色，gold 金色 1, 16进制数值表示，比如：#ff0000 表示红色，这种可以简写成 #f00 2, RGB颜色: 红(R)、绿(G)、蓝(B)三个颜色通道的变化 background-color: rgba(200,100,0); 3, RGBA颜色: 红(R)、绿(G)、蓝(B)、透明度(A) background-color: rgba(0,0,0,0.5); 鼠标手12cursorcursor:pointer 让鼠标在那块变成可点击状态 CSS文本设置123456789101112color 设置文字的颜色，如： color:red;font-size 设置文字的大小，如：font-size:12px;font-family 设置文字的字体，如：font-family:&apos;微软雅黑&apos;;font-style 设置字体是否倾斜，如：font-style:&apos;normal&apos;; 设置不倾斜，font-style:&apos;italic&apos;;设置文字倾斜font-weight 设置文字是否加粗，如：font-weight:bold; 设置加粗 font-weight:normal 设置不加粗font 同时设置文字的几个属性，写的顺序有兼容问题，建议按照如下顺序写： font：是否加粗 字号/行高 字体；如： font:normal 12px/36px &apos;微软雅黑&apos;;line-height 设置文字的行高，如：line-height:24px;text-decoration 设置文字的下划线，如：text-decoration:none; 将文字下划线去掉text-indent 设置文字首行缩进，如：text-indent:24px; 设置文字首行缩进24pxtext-align 设置文字水平对齐方式，如text-align:center 设置文字水平居中line-style:none 清除格式 例如：li前面的点 CSS边框属性1234567891011border:宽度 样式 颜色;border-color;border-style; 边框样式：solid实现，dotted点状线，dashed虚线border-width:border-left-color;border-left-style;border-left-width:CSS3的样式border-radius：圆角处理box-shadow: 设置或检索对象阴影box-sizing:border-box 元素的大小 在计算时 把边框和内边距计算在内 背景属性 background123456789background-color: 背景颜色*background-image: 背景图片 background:url(图片地址)*background-repeat：是否重复，如何重复?(平铺)*background-position：定位background-attachment： 是否固定背景， scroll:默认值。背景图像是随对象内容滚动 fixed:背景图像固定 *background-size: 背景大小，如 background-size:100px 140px; 元素溢出 overflowoverflow的设置项：1、visible 默认值。内容不会被修剪，会呈现在元素框之外。2、hidden 内容会被修剪，并且其余内容是不可见的，此属性还有清除浮动、清除margin-top塌陷的功能。3、scroll 内容会被修剪，但是浏览器会显示滚动条以便查看其余的内容。4、auto 如果内容被修剪，则浏览器会显示滚动条以便查看其余的内容。5、inherit 规定应该从父元素继承 overflow 属性的值。 CSS内边距12345padding： 检索或设置对象四边的内部边距,如padding:10px; padding:5px 10px;padding-top： 检索或设置对象顶边的内部边距padding-right： 检索或设置对象右边的内部边距padding-bottom：检索或设置对象下边的内部边距padding-left： 检索或设置对象左边的内部边距 CSS外边距1234567margin： 检索或设置对象四边的外延边距,如 margin:10px; margin:5px auto;margin-top： 检索或设置对象顶边的外延边距margin-right： 检索或设置对象右边的外延边距margin-bottom： 检索或设置对象下边的外延边距margin-left： 检索或设置对象左边的外延边距设置元素水平居中： margin:x auto注意,margin 外边距 在垂直方向会合并,水平方向不会合并 盒子设置边距1234567border-top-color:red; /* 设置顶部边框颜色为红色 */ border-top-width:10px; /* 设置顶部边框粗细为10px */ border-top-style:solid; /* 设置顶部边框的线性为实线，常用的有：solid(实线) dashed(虚线) dotted(点线); */上面三句可以简写成一句：border-top:10px solid red; 设置内间距padding1234567891011121314padding-top：20px; /* 设置顶部内间距20px */ padding-left:30px; /* 设置左边内间距30px */ padding-right:40px; /* 设置右边内间距40px */ padding-bottom:50px; /* 设置底部内间距50px */上面的设置可以简写如下：padding：20px 40px 50px 30px; /* 四个值按照顺时针方向，分别设置的是 上 右 下 左 四个方向的内边距值。 */padding：20px 40px 50px; /* 设置顶部内边距为20px，左右内边距为40px，底部内边距为50px */ padding：20px 40px; /* 设置上下内边距为20px，左右内边距为40px*/ padding：20px; /* 设置四边内边距为20px */ ★margin-top 塌陷12345678在两个盒子嵌套时候，内部的盒子设置的margin-top会加到外边的盒子上，导致内部的盒子margin-top设置失败，解决方法如下：1、外部盒子设置一个边框2、外部盒子设置 overflow:hidden3、使用伪元素类： .clearfix:before&#123; content: &apos;&apos;; display:table; &#125; 块元素,内联元素,内联块元素解决内联元素间隙的方法1、去掉内联元素之间的换行2、将内联元素的父级设置font-size为0，内联元素自身再设置font-size display属性display属性是用来设置元素的类型及隐藏的，常用的属性有：1、none 元素隐藏且不占位置2、block 元素以块元素显示3、inline 元素以内联元素显示4、inline-block 元素以内联块元素显示 浮点float:left 左浮动 float:right 右浮动 ★清除浮动123456789方法1：.clearfix:after,.clearfix:before&#123; content: &quot;&quot;;display: table;&#125;.clearfix:after&#123; clear:both;&#125;.clearfix&#123;zoom:1;&#125;浮动的父级添加：&lt;div class=&quot;con2 clearfix&quot;&gt;方法2：父级上增加属性overflow：hidden.con2&#123;... overflow:hidden&#125; ★定位1234567relative：相对定位,不脱离文档流,相对于自己本身的位置进行定位,absolute：绝对定位,脱离文档流,位置相对于已定位的父级, 如果没有父级,或父级没有定位,那么相对于文档的00点 (body) 可以通过 z-index 属性定义层叠(先后),参数值越大,越先 在style里面定义 .z1&#123;z-index:1;background:#000;&#125;fixed：固定定位,脱离文档流,位置相对于浏览器窗口 进行定义 javascrip12341, 在html页面中任意位置 书写 script标签,在标签内写js代码2. 在元素 (标签) 内书写事件属性 来触发js代码的执行3, 注意 ,在 包含src属性的script标签内不能在书写js代码js 是运行在浏览器端的脚本语言,属于解释性语言. 12345锦定义变量时，用var关键字，不然严格模式会报错。console。log(a) 在控制台打印值alert() 弹框内容typeof()函数 检测当前变量的数据类型例 console.log(a,typeof(a)) 使用场景123456789101112131, 注意 ,在 包含src属性的script标签内不能在书写js代码 &lt;script type=&quot;text/javascript&quot; src=&quot;./1.js&quot;&gt;&lt;/script&gt;2. 在元素 (标签) 内书写事件属性 来触发js代码的执行 --&gt; &lt;div onclick=&quot;alert(&apos;点我干啥?&apos;)&quot; style=&quot;width: 200px;height: 200px;background: #369;&quot;&gt;&lt;/div&gt; &lt;a href=&quot;javascript:alert(&apos;点你咋滴&apos;)&quot;&gt;点一下试试&lt;/a&gt; &lt;a href=&quot;javascript:void(0)&quot; onclick=&quot;alert(&apos;试试就试试&apos;)&quot;&gt;再点一下试试&lt;/a&gt;!! void(0) 下面提示不显示值 3在html页面中任意位置 书写 script标签,在标签内写js代码 --&gt; &lt;script type=&quot;text/javascript&quot;&gt; // alert(&apos;哎呦,不错哦&apos;); &lt;/script&gt; 123456789101112131415161718192021222324252627282930313233343536371、行间事件（主要用于事件）&lt;input type=&quot;button&quot; name=&quot;&quot; onclick=&quot;alert(&apos;ok！&apos;);&quot;&gt;2、页面script标签嵌入&lt;script type=&quot;text/javascript&quot;&gt; var a = &apos;你好！&apos;; alert(a);&lt;/script&gt;3、外部引入&lt;script type=&quot;text/javascript&quot; src=&quot;js/index.js&quot;&gt;&lt;/script&gt;javascript语句与注释1、一条javascript语句应该以“;”结尾&lt;script type=&quot;text/javascript&quot;&gt;var a = 123;var b = &apos;str&apos;;function fn()&#123; alert(a);&#125;;fn();&lt;/script&gt;2、javascript注释&lt;script type=&quot;text/javascript&quot;&gt;// 单行注释var a = 123;/* 多行注释 1、... 2、...*/var b = &apos;str&apos;;&lt;/script&gt; 常用方法123456789101112131415161718console.log(a) 在控制台进行输出alert(a) 弹出一个窗口document.write(a) 向文档中输出一个文档流如果遇到有-的单词，去掉-，后面的首字母大写，比如 fontSize.document.write(a) 在页面进行输出。标签对象.innerHTML=&quot;内容&quot;；//在标签对象内放置指定内容onclick 单击事件onsubmit 提交事件docunment.getElementsByTagName 获取元素(比如 input,div)里的状态document.getElementById 获取id所属的状态for (var i in window)&#123; document.write(i+&apos;======&apos;+window[i]+&apos;&lt;br&gt;&apos;) &#125;;查看js的所有属性和方法，window是浏览器最大的对象。var res = rr.constructor; console.log(res);查看当前对象的构造函数（当前这个对象和函数的上一层） 数据类型转换123456789101112131415161718192021222324typeof函数获取一个变量的类型：* boolean - 如果变量是 Boolean 类型的* number - 如果变量是 Number 类型的 (整数、浮点数)* string - 如果变量是 String 类型的 （采用&quot;&quot;、 &apos;&apos;）* object - 如果变量是一种引用类型或 Null 类型的 如：new Array()/ new String()...* function -- 函数类型* undefined - 如果变量是 Undefined 类型的数值类型 Number NaN 任何值与NaN进行比较,都是false,除了!= 检测一个变量是否为NaN,只能使用isNaN()字串类型 string var = &apos;a&apos;对象类型 object var a =new Object() 数组类型 (表现类型为对象0bject) var a = new Array() （数组） var a = [1,2,3,4] 空（表现类型也为对象） var a = null未定义 undefined var a (直接定义不给值) 1234567891011121314151617181920使用：Number（）、parseInt() 和parseFloat（） 做类型转换 Number()强转一个数值(包含整数和浮点数)。 整形和浮点型都可以，如果是纯数字，转数字，包含非数字时，转 NaN，可以转布尔 *parseInt()强转整数， 只能转整型 如果字符转中首字母是非数字，转为NaN *parseFloat（）强转浮点数 （最好用） 整形和浮点都可以，如果字符串中首字母是非数字，转为NaN 函数isNaN()检测参数是否不是一个数字。 isNaN() is not a number ECMAScript 中可用的 3 种强制类型转换如下： Boolean(value) - 把给定的值转换成 Boolean 型； 为假的情况： !!! false,0,NaN,null,undefined,0.0,‘’。 Number(value) - 把给定的值转换成数字（可以是整数或浮点数）； String(value) - 把给定的值转换成字符串； 运算符123++ 自加1 --自减+ 后面是字符串进行连接，数字则进行相加 （必须注意优先级，如果前面为字符串连接，后面也都为连接） 123456789101112131415161718192021222324252627算 字 赋 比 逻 位 它算术运算符 + - * / ++ -- 字符串连接 + 赋值运算 = += -= %= 比较运算符 &lt; &gt; &gt;= &lt;= == === != !== === 值和类型都要相同 == 值相同 逻辑运算符 &amp;&amp; （与） ||（或） ! 位运算 ^ &amp; | &lt;&lt; &gt;&gt; 其它运算符 ? : 三元运算符 delete：用于删除对象中属性的 如：delete o.name; //删除o对象中的name属性void： void 运算符对任何值返回 undefined。没有返回值的函数真正返回的都是 undefined。var iNum1=1, iNum2=2, iNum3=3;// 逗号运算符 用逗号运算符可以在 流程控制12345678910if 判断值一样就可以### else if中间必须有空格if(判断)&#123; 执行&#125;else if&#123; 执行&#125;else&#123; 执行&#125; 12345678910111213141516171819switch 的判断 === 值和类型都一样var a = 6;swith(a)&#123; case 1: case 2: case 2: case 4: case 5: alert&#123;&apos;工作日&apos;&#125;; break; case 6: case 7: alert&#123;&apos;休息日&apos;&#125;； break; !!!!（如果这个祛除，default也会默认出现。） default: alert&#123;&apos;火星人你好&apos;&#125;； break;&#125; 循环123456789101112131415161718192021222324252627282930313233for循环 for(var i=0;i&lt;len;i++)&#123; ...... &#125; while循环 var i=0; while(i&lt;8)&#123; ...... i++; &#125; for-in 语句for-in 语句是严格的迭代语句，用于枚举对象的属性。 var a = [10,20,30,40,50]; //迭代的是数组的下标。 for(i in a)&#123; document.write(a[i]); &#125; //输出： 1020304050 ！！！简短写法 for(car i =1;i&lt;=10,i++)&#123; if(i == 7)&#123; continue; &#125; if(i == 8)&#123; break; &#125; &#125; 元素获取1234567891011121314151617181920212223242526272829303132333435363738394041可以使用内置对象document上的getElementById方法来获取页面上设置了id属性的元素，获取到的是一个html对象，然后将它赋值给一个变量，比如：&lt;script type=&quot;text/javascript&quot;&gt; var oDiv = document.getElementById(&apos;div1&apos;);&lt;/script&gt;....&lt;div id=&quot;div1&quot;&gt;这是一个div元素&lt;/div&gt;上面的语句，如果把javascript写在元素的上面，就会出错，因为页面上从上往下加载执行的，javascript去页面上获取元素div1的时候，元素div1还没有加载，解决方法有两种：第一种方法：将javascript放到页面最下边....&lt;div id=&quot;div1&quot;&gt;这是一个div元素&lt;/div&gt;....&lt;script type=&quot;text/javascript&quot;&gt; var oDiv = document.getElementById(&apos;div1&apos;);&lt;/script&gt;&lt;/body&gt;第二种方法：将javascript语句放到window.onload触发的函数里面,获取元素的语句会在页面加载完后才执行，就不会出错了。&lt;script type=&quot;text/javascript&quot;&gt; window.onload = function()&#123; var oDiv = document.getElementById(&apos;div1&apos;); &#125;&lt;/script&gt;....&lt;div id=&quot;div1&quot;&gt;这是一个div元素&lt;/div&gt;样式操作标签对象.style.css属性名=&quot;值&quot; //改变标签对象的样式。示例：id.style.color=&quot;red&quot;;注意：属性名相当于变量名,所以css属性名中含有双拼词的(font-size)的减号要去掉，将后面的首字母大写。fontSize文本操作标签对象.innerHTML=&quot;内容&quot;；//在标签对象内放置指定内容表单中值的操作标签对象.value； //获取标签对象的value值标签对象.value=”值“；//设置标签对象的value值 定时器123单次定时setTimeout(要执行的代码，时间) 时间以毫秒算clearTimeout 关闭只执行一次的定时器 12345多次计时setInterval 反复执行的定时器 clearInterval 关闭反复执行的定时器 ！！一般都是用单次是来结束多次计时 1234567891011121314做一个小动画图片流畅切换&lt;img src=&quot;./img/p1.png&quot; alt=&quot;&quot; id=&quot;tp&quot;&gt; &lt;script type=&quot;text/javascript&quot;&gt; var tp = document.getElementById(&apos;tp&apos;); var i = 1; setInterval(function()&#123; i++; if(i &gt; 5)&#123; i = 1; &#125; tp.src = &apos;./img/p&apos;+i+&apos;.png&apos;; &#125;,50) &lt;/script&gt; 1234567891011三种写法1 var init = setTimeout(function()&#123; alert(&apos;2&apos;); &#125;,2000); function love()&#123; console.log(&apos;22&apos;); &#125; 2 setTimeout(&apos;love()&apos;,2000);3 setTimeout(love,2000); 函数12345678910111213141516171819202122232425262728*第一种是使用function语句定义函数function abc()&#123; alert(&apos;abc&apos;);&#125;*第二种是在表达式中定义函数var 函数名 = function(参数1，参数2，…\\)&#123; alert(&apos;abc&apos;)；&#125;;！！！在使用函数时,如果没有传递参数,形参的默认值就是undefined第三种是使用Function()构造函数来定义函数（不常用）var 函数名 = new Function\\(“参数1”，”参数2”，”参数3”……”函数体”\\);如：var 函数名 = new Function\\(”x”,”y”,”var z=x+y;return z;”\\);arguments 对象在函数代码中，使用特殊对象 arguments，开发者无需明确指出参数名，就能访问它们。例如，在函数 sayHi() 中，第一个参数是 message。用 arguments[0] 也可以访问这个值，即第一个参数的值（第一个参数位于位置 0，第二个参数位于位置 1，依此类推）。关于变量和参数问题：函数外面定义的变量是全局变量，函数内可以直接使用。在函数内部没有使用var定义的=变量则为全局变量，*在函数内使用var关键字定义的变量是局部变量，即出了函数外边无法获取。js函数定义的参数没有默认值（目前只有最新的火狐浏览器支持） 优先级1234567891011如果有变量和函数通用一个变量名，函数会在执行时，优先加载。函数会在执行时,优先加载,如果在代码中还有变量的定义和函数名一样,那么变量会覆盖函数 ！！！注意,函数名和变量名千万不要冲突 // var love = 222; function love()&#123; alert(&apos;111&apos;); &#125; love(); // alert(love); (打印出来时一个函数) 对象1234567891011121314151617181920var obj = new Object(); 定义对象属性 1， obj.name = &quot;张三&quot;; obj.sex = &quot;女&quot;; obj.age = &quot;18&quot;; 2， obj[&apos;age&apos;] = 18; var a = &apos;age&apos;; obj[a] = 22; alert(obj[&apos;age&apos;]) 定义对象的方法 1， obj.sing = function()&#123; alert(&apos;二营长&apos;) &#125; 2， var a = &apos;dance&apos;; obj[a] = function()&#123; alert(&apos;你他娘的意大利炮呢&apos;); &#125;; obj.dance(); 12345678910111213141516171819json1, var 对象名 = &#123;属性名1：属性值，属性名2：属性值2，…….&#125; var rr = &#123; name:&apos;玲玲&apos;,sex:&apos;女&apos;, dance:function()&#123; alert(this.name); &#125; &#125;;2, function person(a,sex,age)&#123; this.name = a; this.info =function()&#123; alert(this.name); &#125; &#125; var a = new person(&apos;翠兰&apos;) var b = new person(&apos;三炮&apos;) a.info() 数组数组就是一组数据的集合，javascript中，数组里面的数据可以是不同类型的。 1234567891011121314151617181920212223242526272829303132333435363738394041定义数组的方法//对象的实例创建var aList = new Array(1,2,3);//直接量创建var aList2 = [1,2,3,&apos;asd&apos;];操作数组中数据的方法1、获取数组的长度：aList.length;var aList = [1,2,3,4];alert(aList.length); // 弹出42、用下标操作数组的某个数据：aList[0];var aList = [1,2,3,4];alert(aList[0]); // 弹出13、push() 和 pop() 从数组最后增加成员或删除成员var aList = [1,2,3,4];aList.push(5);alert(aList); //弹出1,2,3,4,5aList.pop();alert(aList); // 弹出1,2,3,44、unshift()和 shift() 从数组前面增加成员或删除成员var aList = [1,2,3,4];aList.unshift(5);alert(aList); //弹出5,1,2,3,4aList.shift();alert(aList); // 弹出1,2,3,45、splice() 在数组中增加或删除成员var aList = [1,2,3,4];aList.splice(2,1,7,8,9); //从第2个元素开始，删除1个元素，然后在此位置增加&apos;7,8,9&apos;三个元素alert(aList); //弹出 1,2,7,8,9,4多维数组多维数组指的是数组的成员也是数组的数组。var aList = [[1,2,3],[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;]];alert(aList[0][1]); //弹出2; 正则12345678910111213141516171819202122232425262728293031var str = &apos;aaaa1q?i+cn1312w4o_#ilovem4$2enshaizi &apos;;//转义字符 var reg = /w/; var reg = /\\w/; //单个字母数字下划线 var reg = /\\W/; //单个非字母数字下划线 var reg = /\\d/; //单个数字 var reg = /\\D/; //单个非数字 var reg = /\\s/; //单个空白字符 var reg = /\\S/; //单个非空白字符//元字符串 var reg = /./; //除了换行外的任意字符 var reg = /1*/; //匹配0次或多次(看第一个字符) var reg = /q+/; //匹配至少一次或多次 var reg = /i+?/; //拒绝贪婪模式 var reg = /a&#123;3&#125;/; //指定匹配次数 var reg = /a&#123;1,5&#125;/; //指定匹配1-3次 var reg = /[a-z,A-Z,_,0-9]+/;//指定字符范围 var reg = /i(lo(v)e)m/;//子组 var reg = /cn|com|net/;//或//开头和结尾 var reg = /^\\w+\\d$/; //开头除了特殊字符结尾数字 var reg = /^\\w&#123;10,20&#125;\\d$/; //开头除了特殊数字匹配10-20次数字结尾 var reg = /^\\d+[a-z]+$/;//数字开头字母结尾 var reg = /^\\w+@\\w&#123;2,10&#125;\\.(cn|com)$/;//匹配邮箱// 方法 var res1 = reg.test(str);//返回布尔类型 var res2 = reg.exec(str); //按照规则探索,有则以数组形式返回,无则返回null console.log(res1); console.log(res2); return作用1234在函数中如果不写 return 或者只写return 没有返回指定值时 默认返回值 undefined;在函数中写了return 代表当前函数要立即结束,并将结果返回return flase 1 阻止事件冒泡 2 阻止元素的行为 JQuery选择器1234567891011121314151617181920212223242526272829303132$(&apos;li&apos;) //选择所有的li元素$(&apos;#myId&apos;) //选择id为myId的网页元素$(&apos;.myClass&apos;) // 选择class为myClass的元素$(&apos;input[name=username]&apos;) // 选择name属性等于username的input元素$(&apos;#ul1 li span&apos;) //空格层级获取选择id为为ul1元素下的所有li下的span元素$(&apos;#id,.class&apos;);//逗号并列获取对选择集进行修饰过滤(类似CSS伪类)$(&apos;#ul1 li:first&apos;) //选择id为ul1元素下的第一个li$(&apos;#ul1 li:odd&apos;) //选择id为ul1元素下的li的奇数行$(&apos;#ul1 li:eq(2)&apos;) //选择id为ul1元素下的第3个li对选择集进行函数过滤$(&apos;div&apos;).has(&apos;p&apos;); // 选择包含p元素的div元素$(&apos;div&apos;).not(&apos;.myClass&apos;); //选择class不等于myClass的div元素$(&apos;div&apos;).filter(&apos;.myClass&apos;); //选择class等于myClass的div元素$(&apos;div&apos;).first(); //选择第1个div元素$(&apos;div&apos;).eq(5); //选择第6个div元素选择集转移$(&apos;div&apos;).prev(&apos;p&apos;); //选择div元素前面的第一个p元素$(&apos;div&apos;).next(&apos;p&apos;); //选择div元素后面的第一个p元素$(&apos;div&apos;).children(); //选择div的所有子元素$(&apos;div&apos;).siblings(); //选择div的同级元素$(&apos;div&apos;).parent(); //选择div的父元素$(&apos;#abc&apos;).parents(); //选择id为abc的所有的先辈元素$(&apos;div&apos;).find(&apos;.myClass&apos;); //选择div内的class等于myClass的元素 样式操作和获取操作12345678910// 给当前的楼号加样式 其他移除 $(this).addClass(&apos;cur&apos;).siblings().removeClass(&apos;cur&apos;)// 获取div的样式$(&quot;div&quot;).css(&quot;width&quot;);//设置div的样式$(&quot;div&quot;).css(&quot;width&quot;,&quot;30px&quot;); 设置样式,多个样式 $(&apos;.as&apos;).css(&#123;border:&apos;2px solid red&apos;,background:&apos;#666&apos;&#125;); 123456789101112131415161718192021222324252627282930313233343536//通过标签名获取元素 document.getElementsByTagName() //$(&apos;li&apos;).css(&apos;border&apos;,&apos;2px solid #f39&apos;);//通过标签中的属性获取元素 [] //$(&apos;li[name=y]&apos;).css(&apos;border&apos;,&apos;2px solid #f39&apos;); //$(&apos;img[width=&quot;100%&quot;]&apos;).css(&apos;border&apos;,&apos;2px solid #f39&apos;); //$(&apos;img[name=logo]&apos;).css(&apos;border&apos;,&apos;2px solid #f39&apos;);//空格 层级关系获取元素 //$(&apos;#images li&apos;).css(&apos;border&apos;,&apos;2px solid #f39&apos;);//逗号 并列获取 //$(&apos;.w,#img&apos;).css(&apos;border&apos;,&apos;2px solid #f39&apos;);//选择id为menu元素下的第一个li //$(&apos;#menu li:first&apos;).css(&apos;border&apos;,&apos;2px solid #f39&apos;);/选择id为section元素下的li的奇数行 // $(&apos;#section li:odd&apos;).css(&apos;border&apos;,&apos;2px solid #f39&apos;); // $(&apos;#section li:even&apos;).css(&apos;border&apos;,&apos;2px solid #f63&apos;);//选择id为section元素下的第3个li 下标从0开始 // $(&apos;#section li:eq(1)&apos;).css(&apos;border&apos;,&apos;2px solid #f63&apos;);//id为section 前面第一个div元素 //$(&apos;#footer&apos;).prev(&apos;p&apos;).css(&apos;color&apos;,&apos;#f39&apos;);//id为section 后面第一个div元素 //$(&apos;#section&apos;).next(&apos;p&apos;).css(&apos;color&apos;,&apos;#f63&apos;);//选择images的所有子元素 //$(&apos;#images&apos;).children().css(&apos;border&apos;,&apos;2px solid #f63&apos;);//选择id为acc的同级元素 //$(&apos;#acc&apos;).siblings().css(&apos;border&apos;,&apos;2px solid #f39&apos;);//选择id为acc的父级元素 //$(&apos;#acc&apos;).parent().css(&apos;border&apos;,&apos;2px solid #f63&apos;);//选择id为acc的所有的先辈元素 //$(&apos;#acc&apos;).parents().css(&apos;border&apos;,&apos;2px solid #f39&apos;);//选择id为acc的先辈元素中 id为all的元素 //$(&apos;#acc&apos;).parents(&apos;#all&apos;).css(&apos;border&apos;,&apos;2px solid #f63&apos;);//选择id为images下的id为acc元素 var c = $(&apos;#images&apos;).find(&apos;#acc&apos;); console.log(c) 类名操作123456操作样式类名$(&quot;#div1&quot;).addClass(&quot;divClass2&quot;) //为id为div1的对象追加样式divClass2$(&quot;#div1&quot;).removeClass(&quot;divClass&quot;) //移除id为div1的对象的class名为divClass的样式$(&quot;#div1&quot;).removeClass(&quot;divClass divClass2&quot;) //移除多个样式$(&quot;#div1&quot;).toggleClass(&quot;anotherClass&quot;) //重复切换anotherClass样式 文本操作123456$(&apos;#as&apos;).html(&apos;&lt;span style=&quot;color:red&quot;&gt;11&lt;/span&gt;&apos;) 可以执行的样式操作$(&apos;#as&apos;).text(&apos;&lt;span style=&quot;color:blue&quot;&gt;22&lt;/span&gt;&apos;) 取出或添加文本内容var r = $(&apos;#as&apos;).html();var b = $(&apos;#as&apos;).text(); 属性操作1234567891011121314151617181920212223属性操作1、attr() 取出或设置某个属性的值// 取出图片的地址var $src = $(&apos;#img1&apos;).attr(&apos;src&apos;);$(&quot;input[name=&apos;sex&apos;][value=&apos;&#123;&#123;user.sex&#125;&#125;&apos;]&quot;).attr(&quot;checked&quot;, true);选择框尾name时sex,值为当前选项的添加默认选项// 设置图片的地址和alt属性$(&apos;#img1&apos;).attr(&#123; src: &quot;test.jpg&quot;, alt: &quot;Test Image&quot; &#125;);//也可以用户设置class属性$(&apos;#abc&apos;).attr(&apos;class&apos;,&apos;all&apos;)//也可以自定义 属性$(&apos;#abc&apos;).attr(&apos;love&apos;,&apos;iloveyou&apos;)2、removeattr()删除属性$(&apos;#abc&apos;).removeattr(&apos;class&apos;)$(&apos;#abc&apos;).removeattr(&apos;love&apos;)3 toggleClass()如果存在,则移除,如果不存在.则添加$(&apos;#as&apos;).toggleClass(&apos;myclass&apos;); 获取尺寸操作123456789101112131415161718192021222324251 获取元素距离文档偏移量 //var innero = $(&apos;.inner&apos;).offset(); var innerTo = $(&apos;.inner&apos;).offset().top 2 获取当前元素相对于父级元素的偏移量 //var innerp = $(&apos;.inner&apos;).position(); 3 获取文档滚动的距离 var wt = $(window).scrollTop(); 4 快速获取元素的宽高 // var w = $(&apos;.inner&apos;).width(); // var h = $(&apos;.inner&apos;).height();5 设置元素的宽高 // var w = $(&apos;.inner&apos;).width(200); // var h = $(&apos;.inner&apos;).height(100);6 获取可视区域的宽高 // var ww = $(window).width(); // var wh = $(window).height();7 获取整个文档的宽高 var dw = $(document).width(); var dh = $(document).height(); 事件12345678910111213141516171819202122232425262728293031323334353637方法绑定1 click2 bind 方法绑定 bind(&apos;dblclick&apos;,function()&#123;3 live 动态方法绑定 live(&apos;click&apos;,function()&#123;4 trigger 自动触发 $(&apos;#move&apos;).trigger(&apos;click&apos;);5 解除事件绑定 $(&apos;#move&apos;).die(&apos;click&apos;) 解除动态绑定 $(&apos;#move&apos;).unbind()单击事件 click双击事件 dblclick 鼠标抬起 mouseup鼠标按下 mousedown 鼠标右键 oncontextmenu window.oncontextmenu = function()&#123; alert(2);&#125;鼠标移入 mouseover 鼠标移出 mouseout鼠标移动查看位置: $(&apos;.move&apos;).mousemove(function(e)&#123; // 鼠标相对于浏览器的窗口 var x = e.clientX; var y = e.clientY; // 鼠标相对于文档的窗口 // var x = e.pageX; // var y = e.pageY; console.log(x,y) &#125;) 键盘按下 keydown 键盘抬起 keyup//获取按键信息 function里一般传入参数 e var k = e.keyCode;获取焦点事件 focus 丧失焦点事件 blur改变值之后的事件 change文档滚动事件,当文档发动滚动时触发的事件 $(window).scroll(InitScroll);网页加载事件 window.onload = function()&#123;&#125; 节点操作123456789101112创建节点var $div = $(&apos;&lt;div&gt;&apos;);在元素内部尾部添加 append在元素内部头部添加 prepend在元素外部头部添加 before在元素外部尾部添加 after删除 remove清空 empty克隆 clone弹出一个询问框,带有取消和确定按钮,返回布尔类型var res = confirm(&apos;您确定要删除这个元素码?&apos;); 效果1234567891011121314151617181920212223242526272829303132333435363738394041424344!所有的效果后面都可以加时间.$(&apos;#move&apos;).show(2000); //显示$(&apos;#move&apos;).slideDown();//滑动显示$(&apos;#move&apos;).fadeIn();//渐变$(&apos;#move&apos;).hide(2000);//隐藏$(&apos;#move&apos;).slideUp;//滑动隐藏$(&apos;#move&apos;).fadeOut();//渐变$(&apos;#move&apos;).toggle(2000);//隐藏和显示切换$(&apos;#move&apos;).slideToggle(2000);//滑动隐藏和显示切换$(&apos;#move&apos;).fadeToggle(2000);//渐变隐藏和显示切换自定义动画$(&apos;#move&apos;).animate(&#123; width:&apos;300px&apos;,height:&apos;400px&apos;, top:&apos;100px&apos;,left:&apos;100px&apos;, borderRadius:&apos;50%&apos;&#125;,3000)$(&apos;#move&apos;).stop(); 暂停动画效果 // 延时执行自定义动画 (delay 延时多长时间 )$(&apos;#move&apos;).delay(1000).animate(&#123; width:&apos;300px&apos;,height:&apos;400px&apos;, top:&apos;100px&apos;,left:&apos;100px&apos;, borderRadius:&apos;50%&apos;, &#125;,4000) // 绑定文档滚动事件 $(window).scroll(function()&#123; // 获取整个文档的高度 var dH = $(document).height(); // 获取可视区域的高度 var cH = $(window).height; // 获取文档的滚动距离 var dT = $(window).scrollTop(); // 判断 是否触底 if(dT == dH-cH)&#123; requestGoods(); &#125; &#125;) json123456789101112131415161718json是 JavaScript Object Notation 的首字母缩写，单词的意思是javascript对象表示法，这里说的json指的是类似于javascript对象的一种数据格式，目前这种数据格式比较流行，逐渐替换掉了传统的xml数据格式。javascript对象字面量：var tom = &#123; name:&apos;tom&apos;, age:18&#125;json格式的数据：&#123; &quot;name&quot;:&apos;tom&apos;, &quot;age&quot;:18&#125;与json对象不同的是，json数据格式的属性名称需要用双引号引起来，用单引号或者不用引号会导致读取数据错误。json的另外一个数据格式是数组，和javascript中的数组字面量相同。[&apos;tom&apos;,18,&apos;programmer&apos;] ajax 异步和同步12345678910111213141516171819202122232425AJAX 是与服务器交换数据并更新部分网页的艺术，在不重新加载整个页面的情况下。通过 HTTP 请求加载远程数据jQuery 底层对 AJAX 实现进行了封装.使得我们在进行ajax操作时,不必像原生js中那么复杂$.get, $.post, $.ajax() 返回其创建的 XMLHttpRequest 对象。多数情况下我们不需要去操作返回的对象/发送ajax请求 1.url 2.可选 发送get请求时携带的参数 ,3,可选 回调函数,请求完之后做什么事 4,可选,返回的数据类型 json$.get(url,&#123;携带的参数&#125;,function(data)&#123;&#125;,&apos;json&apos;);$.post(url,&#123;携带的参数&#125;,function(data)&#123;&#125;,&apos;json&apos;);$.ajax(&#123; url:&apos;/cgi-bin/1.py&apos;, 当前请求的url地址 type:&apos;post&apos;, 当前请求的方式 get post data:&#123;name:&apos;fei&apos;&#125;, 请求时携带的参数 dataType:&apos;json&apos;, 返回的数据类型 success:function(data)&#123; 请求成功后执行的代码 alert(&apos;请求成功&apos;) &#125;, error:function()&#123; 请求失败后执行的代码 alert(&apos;请求错误&apos;) &#125;, timeout:2000, 毫秒 设置当前请求的超时时间,必须异步 async:false ture异步, flase 同步&#125;) 12345678910111213ajax异步 同步//设置ajax的全局配置 async:false 设置当前请求为同步$.ajaxSetup(&#123; async:false&#125;)关于ajax中 异步 和 同步 ajax默认就是异步请求,async (默认: true) 默认设置下，所有请求均为异步请求。如果需要发送同步请求，请将此选项设置为 false。同步请求,就发ajax请求发出去后必须等待ajax的结果返回后才能继续往下执行一般情况下都使用异步操作就可以,除非有特殊情况,必须等ajax的结果回来后才能做处理的,就用同步 1234567891011121314151617181920212223注意1.ajax是无刷新请求服务器,所以我们在浏览器中是感觉不到,也看不到ajax的具体请求和执行情况的., 因此我们需要借助浏览器的调试工具 (F12打开) 进行查看2.ajax的请求是基础HTTP协议的,就要求你当前打开这个带有ajax的html时必须使用http协议3.ajax要求同源策略 http://127.0.0.1:8000/cgi-bin/1.py 即: 协议(http https) 域名或IP 以及端口(80 443 8000 8080 ...)都必须一致4.关于返回的数据类型 在get() post() ajax() 都可以设置返回的数据类型 &apos;json&apos; 如果要求返回json格式数据,那么就必须返回json,如果不正确, 在get和post方法将拿不到data中返回的数据,在ajax方法中则会进去error方法5.在python中返回json格式数据, 引入 json模块 json.dumps(数据) 使用json_dumps方法进行json格式的编码转换6.在使用ajax方法时.会创建一个对象 XMLHttpRequest 那么在ajax的方法中使用的 $(this) 就代表 ajax的对象 $(this) 永远代表一个对象,没有指明对象时 代表的时window对象, 在它有对象时 代表的就是当前的这个对象 ajax注意123在ajax使用$(this)时,一定要用变量接受var uid=$(this).parents(&apos;tr&apos;).find(&apos;td:first&apos;).text() var btn = $(this) Bootstrap12345678910111213head格式(注意:js需要改名)&lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt; &lt;!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ --&gt; &lt;title&gt;Bootstrap 101 Template&lt;/title&gt; &lt;!-- Bootstrap --&gt; &lt;link href=&quot;./public/css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot;&gt; &lt;!-- jQuery (necessary for Bootstrap&apos;s JavaScript plugins) --&gt; &lt;script src=&quot;./public/js/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt; &lt;!-- Include all compiled plugins (below), or include individual files as needed --&gt; &lt;script src=&quot;./public/js/bootstrap.min.js&quot;&gt;&lt;/script&gt; 商城统计12345678910 window.onload=function()&#123; var x = document.getElementsByName(&apos;xiaoji&apos;); ##小计的name var num = 0; for (var i = x.length - 1; i &gt;= 0; i--) &#123; console.log($(x[i]).text()); num = num + parseInt($(x[i]).text()); &#125;; console.log(num); $(&apos;.zj&apos;).html(num);&#125;","categories":[],"tags":[{"name":"web前端","slug":"web前端","permalink":"https://127.0.0.1/blog/tags/web前端/"}]},{"title":"docker的基本操作","slug":"docker的基本操作","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.400Z","comments":true,"path":"2019/05/06/docker的基本操作/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/docker的基本操作/","excerpt":"","text":"docker的基本操作流程 docker search mongo 搜索镜像 docker pull mongo 下载镜像 docker run -itd –name=spider py3_spider:v2 启动 1 检查运行中的镜像 docker ps 2 运行docker镜像 docker run spider echo “hello word” 镜像名 命令 3 进入容器 docker exec -it 2c272247bca /bin/bash ​ 退出 Ctrl + d 4 终止和重新启动 docker stop name/id docker kill name/id 启动 docker start name 5 文件复制 从主机复制到容器sudo docker cp host_path containerID:container_path 从容器复制到主机sudo docker cp containerID:container_path host_path 6 文件挂载 docker run -itd -v /home/xiaofei/scrapyd/:/xiaofei –name=spider1 REPOSITORY:v1 7 删除所有未运行的容器（已经运行的删除不了，未运行的就一起被删除了） sudo docker rm $(sudo docker ps -a -q) 8 删除none的images docker rmi $(docker images |grep “”)","categories":[],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://127.0.0.1/blog/tags/杂记/"}]},{"title":"es聚合查询并且返回对应组的数据","slug":"es聚合查询并且返回对应组的数据","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.400Z","comments":true,"path":"2019/05/06/es聚合查询并且返回对应组的数据/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/es聚合查询并且返回对应组的数据/","excerpt":"","text":"es 聚合查询并返回每个组的数据需求 我现在是有一个这样的需求, 我需要在es里面按照 cityarea 进行分组(group by), 并且每个 cityarea的组 需要展示 按照时间排序的前10条, 状态全部为1的数据 实现1234567891011121314151617181920212223242526272829303132333435363738&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;term&quot;: &#123; &quot;status&quot;: &quot;1&quot; # 筛选条件, 状态为 1 的 &#125; &#125; ] &#125; &#125;, &quot;from&quot;: 0, &quot;size&quot;: 10, &quot;aggs&quot;: &#123; &quot;top_score&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;cityarea&quot;, ## 按照cityarea 进行分组 &quot;size&quot;: 30 ## 注意: 这个size 是必填的, 因为不填默认是10, 也就是说如果我有 11个cityarea组的话, 在这只能分10个组, 最后一组不显示, &#125;, 个人建议根据分组情况写一个较大的值 &quot;aggs&quot;: &#123; &quot;top_score_hits&quot;: &#123; &quot;top_hits&quot;: &#123; &quot;_source&quot;: [ &quot;name&quot; ## 只展示name字段, 按照自己的需求来就行 ], &quot;size&quot;: 10, ## 这个size是每个组展示多少条数据, 默认是10 &quot;sort&quot;: &#123; &quot;first_time&quot;: &#123; &quot;order&quot;: &quot;desc&quot; ## 按照时间进行排序 &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"git cherry-pick","slug":"git cherry-pick","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.401Z","comments":true,"path":"2019/05/06/git cherry-pick/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/git cherry-pick/","excerpt":"","text":"###git cherry-pick 说一下我工作中常用的一条git 命令,简单高效 工作分支一般是在 develop上,然后在工作分支修改的代码提交到线上时很容易出现错误.冲突 等之类的问题,然后有的时候提交的文件过于分散和量大,你又不想一个一个的checkout 添加,怎么办?git cherry-pick就是最好的方法: 语法很简单,我们常用的提交就是 git add git commit git pull git push 然后提交线上就是 git checkout develop a.txt 很麻烦对吧,然后如果你会用git cherry-pick这条命令,就会发现很简单: git cherry-pick git pull git push 就OK了,是不是很简单,然后这个只会提交你的commit id 的修改情况,也极大程度的避免了冲突的问题.","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://127.0.0.1/blog/tags/git/"}]},{"title":"git stash , git fetch 和 git clear","slug":"git stash , git fetch 和 git clear","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.401Z","comments":true,"path":"2019/05/06/git stash , git fetch 和 git clear/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/git stash , git fetch 和 git clear/","excerpt":"","text":"git stash 网上关于git stash的教程已经很多了，但是这个用多了确实很容易乱，所以除了特殊情况一般不推荐大家用这个 特殊情况是什么呢？ 就是当你改变了本地的代码，但你不想提交，同时又想拉取最新的代码时，就可以用这个命令在进行暂存。 具体用法也很简单： git stash将目前工作的修改保存到一个新的存储条，并且回滚到头; git pop取出最新的一个存储条。 git list查看所有的存储条的版本号 git stash apply stash @ {1}取出版本号为1的工作存储条 git stash clear清空所有的存储条 相关的用法还有很多，这是最常用的几个。 最后还是提醒一句，不要太常用这个，容易乱…git fetch放弃本地修改，强制更新 git fetch --all git reset --hard origin / master ###代码冲突 git clean -d -fx “” x -----删除忽略文件已经对git来说不识别的文件 d -----删除未被添加到git的路径中的文件 f -----强制运行","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://127.0.0.1/blog/tags/git/"}]},{"title":"go time常用方法","slug":"go time常用方法","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.401Z","comments":true,"path":"2019/05/06/go time常用方法/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/go time常用方法/","excerpt":"","text":"前言最近开发项目经常用到go的time包, 照python的略微麻烦一些, 特别是那个layout被无数人吐槽(包括我), 这里整理了一些常用的方法, 有需要的可以了解一下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package mainimport ( &quot;time&quot; &quot;fmt&quot;)func main() &#123; // time函数 layout 2006-01-02 15:04:05 //生成时间 time.Now() time.Now().Unix() //时间转换 time.Format 根据更改layout转成任何自己想要的格式化字段 time.Now().Format(&quot;2006-01-02&quot;) time.Now().Format(&quot;200601&quot;) //格式时间转换为time类型 a := &quot;20190606&quot; b, _ := time.Parse(&quot;20060102&quot;, a) fmt.Println(b.Unix()) //时间戳转为time类型 t := time.Unix(time.Now().Unix(), 0) fmt.Println(t) //time时间操作 tomrrow := time.Now().AddDate(0, 0, 1) //明天 time.Now().AddDate(0, -1, 0) //上月 //也可以是一段时间 fmt.Println(t.Add(time.Duration(10) * time.Minute)) //判断时间前后 bol1 := t.After(tomrrow) bol2 := t.Before(tomrrow) fmt.Println(bol1, bol2) //计算日期时间差 一般都是跟 Add方法一块使用 fmt.Println(t.Sub(tomrrow)) //计算日期离今天间隔几天 aaa, _ := time.Parse(&quot;20060102&quot;, a) fmt.Println(int64(aaa.Sub(time.Now()).Hours() / 24)) //获取明天凌晨的时间戳 t = time.Now() zero := time.Date(t.Year(), t.Month(), t.Day()+1, 0, 0, 0, 0, t.Location()).Unix() fmt.Println(zero)&#125;","categories":[],"tags":[{"name":"GoLang","slug":"GoLang","permalink":"https://127.0.0.1/blog/tags/GoLang/"}]},{"title":"go 发送http请求","slug":"go 发送http请求","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.401Z","comments":true,"path":"2019/05/06/go 发送http请求/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/go 发送http请求/","excerpt":"","text":"写了一下go发送http请求常用的几种方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package mainimport ( &quot;net/http&quot; &quot;io/ioutil&quot; &quot;fmt&quot; &quot;strings&quot; &quot;net/url&quot; &quot;bytes&quot; &quot;encoding/json&quot;)func main() &#123; urls := &quot;http://www.baidu.com/&quot; var data = map[string]interface&#123;&#125;&#123;&#125; res := 1 var resp *http.Response var err error //-------------------------发起请求------------------------------------ switch res&#123; case 1: // get请求 resp, err = http.Get(urls) case 2: // post发送json datas, _ := json.Marshal(data) resp, err = http.Post(urls, &quot;application/json&quot;, bytes.NewBuffer(datas)) case 3: // post发送from表单 datas := make(url.Values) for key, value := range data &#123; datas[string(key)] = []string&#123;value.(string)&#125; &#125; resp, err = http.PostForm(urls, datas) case 4: // 创建请求设置参数 datas := url.Values&#123; &quot;name&quot;: &#123;&quot;fei&quot;&#125;, &#125; req, err := http.NewRequest(&quot;POST&quot;,urls, strings.NewReader(datas.Encode())) if err != nil &#123; // handle error &#125; req.Header.Add(&quot;Content-Type&quot;, &quot;application/x-www-form-urlencoded&quot;) req.Header.Add(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36&quot;) client := &amp;http.Client&#123;&#125; resp, err = client.Do(req) &#125; //-------------------------发起请求成功------------------------------------ if err != nil &#123; fmt.Println(err.Error()) &#125; defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil &#123; fmt.Println(err.Error()) &#125; fmt.Println(string(body)) //解析返回body的话直接用断言就可以&#125;","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://127.0.0.1/blog/tags/Python/"}]},{"title":"go语言基础数据结构学习 ---- 字典(map)","slug":"go语言基础数据结构学习 ---- 字典(map)","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.401Z","comments":true,"path":"2019/05/06/go语言基础数据结构学习 ---- 字典(map)/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/go语言基础数据结构学习 ---- 字典(map)/","excerpt":"","text":"go语言基础数据结构学习–&gt; 字典(map)go 语言中的字典和python 中的字典特性差不多 相同: 键值对, 无序集合, 每个键都是唯一的, 对一个键多次赋值会更新当前键的值; 不同: go语言的字典里面的类型是定好的, 不可变更, python可以随意写类型. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869 package main import &quot;fmt&quot; //字典和python是一样, 无序的 //声明新的类型 type Fei struct &#123; id int name string &#125; type Dic map[string]int func main() &#123; //声明字典 dict := make(map[string]string) dicts := map[string]int&#123; &quot;age&quot;: 10, &quot;丙总&quot;: 2&#125; //新类型 result := make(map[int]*Fei) result[0] = &amp;Fei&#123; id: 6300, name: &quot;刀妹&quot;&#125; letter := []string&#123;&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;&#125; //数组 //用 dict[name] = value 来设置值和修改 dict[&quot;name&quot;] = &quot;薇恩&quot; dict[&quot;age&quot;] = &quot;18&quot; dict[&quot;label&quot;] = &quot;小飞&quot; //新类型的值修改 ss := result[0] ss.id = 4800 //打印字典的值 name := dict[&quot;name&quot;] res := dict[&quot;res&quot;] fmt.Println(name) fmt.Println(res) //打印字典元素个数 fmt.Println(&quot;lens&quot;, len(dict)) //删除字典元素, 有则删除, 无则不删 delete(dict, &quot;label&quot;) delete(dict, &quot;ask&quot;) //删除全部需要循环 for k := range dict&#123; delete(dict, k) &#125; //批量添加字典 for k,v := range letter&#123; fmt.Println(&quot;还可以&quot;, k, v) dicts[v] = k &#125; fmt.Println(dict) fmt.Println(dicts) fmt.Println(result[0]) //字典的嵌套操作 respon := make(map[string]Dic) DicNum := make(Dic) //make 初始化, 分配内存地址, 不为 nil DicNum[&quot;id&quot;] = 1 DicNum[&quot;age&quot;] = 2 respon[&quot;ids&quot;] = DicNum respon[&quot;type&quot;] = Dic&#123;&quot;id&quot;: 11, &quot;age&quot;: 22&#125; fmt.Println(respon)&#125;","categories":[],"tags":[{"name":"GoLang","slug":"GoLang","permalink":"https://127.0.0.1/blog/tags/GoLang/"}]},{"title":"go语言基础数据结构学习---- 数组, 列表(list)和切片(slice)","slug":"go语言基础数据结构学习---- 数组, 列表(list)和切片(slice)","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.402Z","comments":true,"path":"2019/05/06/go语言基础数据结构学习---- 数组, 列表(list)和切片(slice)/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/go语言基础数据结构学习---- 数组, 列表(list)和切片(slice)/","excerpt":"","text":"go语言基础数据结构学习–&gt; 数组, 列表(list)和切片(slice)go 语言中的 数组是类型相同的元素的集合, 列表是双链表的容器, 可以添加不同类型的数据 切片是对现有数组的引用, 比数组更方便灵活, 还可以追加数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package mainimport ( &quot;container/list&quot; &quot;fmt&quot;)func main() &#123; // 切片 slice 比较常用, 很灵活 list1 := [6]int&#123;1,2,3,4&#125; //6是总数, 后面是值, 如果不够会自动补0 list6 := []string&#123;&quot;a&quot;, &quot;b&quot;&#125; var list2 [3]int // 声明列表, 下面两种为初始化, 生成内存地址, 双链表 ----容器 var list3 = list.List&#123;&#125; list4 := list.New() //多维数组 list5 := [3][2]string&#123; &#123;&quot;飞&quot;, &quot;小&quot;&#125;, &#123;&quot;祥&quot;, &quot;泰&quot;&#125;, &#123;&quot;德&quot;, &quot;丙&quot;&#125;, &#125; //列表插入方法 a1 := list3.PushFront(2) //从左插入 a2 :=list3.PushBack(1) //从右插入 list3.InsertAfter(&quot;after&quot;, a2) //在 a2之后 list3.InsertBefore(&quot;before&quot;, a1) //在 a1之前 //列表删除 list3.Remove(a2) //列表(容器)遍历 for x := list3.Front(); x != nil; x = x.Next() &#123; if x.Value == &quot;after&quot; &#123; fmt.Println(x.Value) &#125; fmt.Print(x.Value, &quot; , &quot;) &#125; //切片遍历 for _,x := range list1&#123; if x == 1&#123; fmt.Println(x) &#125; &#125; //切片追加 list6 = append(list6, &quot;c&quot;) //也可以和python一样根据索引覆盖值 list1[5] = 9 list2[2] = 9 fmt.Println(list1) fmt.Println(list2) printlist(list3) fmt.Println(list4) fmt.Println(list5) fmt.Println(list6)&#125;func printlist(lists list.List) &#123; for x := lists.Front(); x != nil; x = x.Next() &#123; fmt.Println(x.Value) &#125;&#125; 参考学习文档: https://www.cnblogs.com/liuzhongchao/p/9159896.html http://c.biancheng.net/view/35.html","categories":[],"tags":[{"name":"GoLang","slug":"GoLang","permalink":"https://127.0.0.1/blog/tags/GoLang/"}]},{"title":"http协议","slug":"http协议","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.402Z","comments":true,"path":"2019/05/06/http协议/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/http协议/","excerpt":"","text":"http协议1234567http是一个属于应用层面的面向对象的协议，由于其简捷，快速的方式，适用于分布式超媒体信息系统。主要特点：1.支持客户／服务器模式2.简捷快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有get,post,head.每种方法规定了客户与服务器联系的类型不同。由于http协议简单，使得http服务器的程序规模小，通信数度快。3.灵活：http允许传输任意类型的数据对象，正在传输的类型由content-type加以标记4.无连接：无连接的含义是限制每次链接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开链接，这样可以节省传输时间。5.无状态：http协议是无状态协议，无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 解释下Http请求头和常见响应状态码请求头：12345678Accept:指浏览器或其他客户可以接爱的MIME文件格式。可以根据它判断并返回适当的文件格式。Accept-Charset：指出浏览器可以接受的字符编码。英文浏览器的默认值是ISO-8859-1.Accept-Language：指出浏览器可以接受的语言种类，如en或en-us，指英语。Accept-Encoding：指出浏览器可以接受的编码方式。编码方式不同于文件格式，它是为了压缩文件并加速文件传递速度。浏览器在接收到Web响应之后先解码，然后再检查文件格式。Cache-Control：设置关于请求被代理服务器存储的相关选项。一般用不到。Connection：用来告诉服务器是否可以维持固定的HTTP连接。HTTP/1.1使用Keep-Alive为默认值，这样，当浏览器需要多个文件时(比如一个HTML文件和相关的图形文件)，不需要每次都建立连接。Content-Type：用来表名request的内容类型。可以用HttpServletRequest的getContentType()方法取得。Cookie：浏览器用这个属性向服务器发送Cookie。Cookie是在浏览器中寄存的小型数据体，它可以记载和服务器相关的用户信息，也可以用来实现会话功能。 状态码：123456789101112131415状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值：1xx：指示信息--表示请求已接收，继续处理2xx：成功--表示请求已被成功接收、理解、接受3xx：重定向--要完成请求必须进行更进一步的操作4xx：客户端错误--请求有语法错误或请求无法实现5xx：服务器端错误--服务器未能实现合法的请求常见状态代码、状态描述、说明：200 OK //客户端请求成功400 Bad Request //客户端请求有语法错误，不能被服务器所理解401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用403 Forbidden //服务器收到请求，但是拒绝提供服务404 Not Found //请求资源不存在，eg：输入了错误的URL500 Internal Server Error //服务器发生不可预期的错误503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常eg：HTTP/1.1 200 OK （CRLF） python多线程 1234567891011121314151617181920212223http://python.jobbole.com/85050/ 一篇比较详细的博文class MyThread(threading.Thread): def init(self): threading.Thread.init(self)def run(self): lock.acquire() print threading.currentThread().getName() lock.release() def build_worker(num): workers = [] for t in range(num): work = MyThread() work.start() workers.append(work) return workersdef producer(): threads = build_worker(4) for w in threads: w.join() print &apos;Done&apos; 123456789101112131415161718192021pool = ThreadPool()创建了线程池，其默认值为当前机器 CPU 的核数，可以指定线程池大小，不是越多越好，因为越多的话，线程之间的切换也是很消耗资源的。results = pool.map(urllib2.urlopen,urls) 该语句将不同的url传给各自的线程，并把执行后结果返回到results中。import urllib2 from multiprocessing.dummy import Pool as ThreadPool urls = [&apos;http://www.baidu.com&apos;,&apos;http://www.sina.com&apos;,&apos;http://www.qq.com&apos;] pool = ThreadPool() results = pool.map(urllib2.urlopen,urls)print resultspool.close()pool.join() print &apos;main ended&apos;http://www.doc88.com/p-0803296137106.html 这个是异步i／o及多线程 1http://cuiqingcai.com/3335.html 静觅。多线程爬虫 mongodb的常用语法。 http://www.cnblogs.com/leskang/p/6000852.html什么是mongodb1234MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 python操作数据库 123456789101112131415161718import pymongocon = pymongo.Connection(&apos;localhost&apos;, 27017)mydb = con.mydb # new a databasemydb.add_user(&apos;test&apos;, &apos;test&apos;) # add a usermydb.authenticate(&apos;test&apos;, &apos;test&apos;) # check authmuser = mydb.user # new a tablemuser.save(&#123;&apos;id&apos;:1, &apos;name&apos;:&apos;test&apos;&#125;) # add a recordmuser.insert(&#123;&apos;id&apos;:2, &apos;name&apos;:&apos;hello&apos;&#125;) # add a recordmuser.find_one() # find a recordmuser.find_one(&#123;&apos;id&apos;:2&#125;) # find a record by querymuser.create_index(&apos;id&apos;)muser.find().sort(&apos;id&apos;, pymongo.ASCENDING) # DESCENDING# muser.drop() delete tablemuser.find(&#123;&apos;id&apos;:1&#125;).count() # get records numbermuser.find(&#123;&apos;id&apos;:1&#125;).limit(3).skip(2) # start index is 2 limit 3 recordsmuser.remove(&#123;&apos;id&apos;:1&#125;) # delet records where id = 1muser.update(&#123;&apos;id&apos;:2&#125;, &#123;&apos;$set&apos;:&#123;&apos;name&apos;:&apos;haha&apos;&#125;&#125;) # update one recordb.auth(usrename,password) 设置数据库连接验证 1234561.mongodb默认端口是27017，上面步骤mongod 命令是属于启动mongo服务端命令，启动后不能关闭，否则mongo就关闭了导致链接时出现10061错误，所以要新开启一个窗口执行：mongo localhost:27017，表示客户端连接2.注：mongodb可以不设账号密码，通过IP地址和端口直接链接3.退出输入：exit4.在mongodb中基本的概念是文档、集合、数据库，下面介绍。5.MongoDB的默认数据库为&quot;db&quot;，该数据库存储在data目录中。6.MongoDB的单个实例可以容纳多个独立的数据库，每一个都有自己的集合和权限，不同的数据库也放置在不同的文件中。 SQL术语 mongodb术语 解释／说明 Database Database 数据库 table Collection 数据库表／集合 Row Document 数据记录行／文档 Column Field 数据字段／域 Index Index 索引 Table joins 表链接，mongodb不支持 Primary key Primary key 主键，mongodb自动将_id字段设置为主键 Mongoldb 数据库语法 12345show dbs;//查看所有的数据库db;//查看当前窗口所在的数据库use 数据库名；//如果数据库不存在，则创建数据库，否则切换到指定数据库。注：show dbs执行结果没有看到test库，但是db查看当前库确是test库，因为test库中刚开始没有任何数据并且是在内存中的，有了数据后就会显示出来了（其他新创建的数据库也是如此）db.dropDatabase();//删除当前数据库，默认为 test，故要切换到某个数据库下进行删除 集合 1234567891011显式创建集合：db.createCollection(&quot;collectionName&quot;);//创建一个名为collectionName的集合，创建完成后会返回 &#123;&quot;ok&quot;,1&#125; json串隐式创建集合：db.collection2.insert(&#123;name:&quot;xiaomu&quot;,age:20&#125;);//往collection2集合中添加数据来创建集合，如果集合不存在就自动创建集合，返回：WriteResult(&#123;&quot;nInserted&quot;:1&#125;)show collections;//查看集合db.collection1.count();//统计集合collection1中的数据数量db.collection1.drop();//删除集合collection1注：mongo中支持js，可通过js操作实现批零处理，如：for(var i=0;i&lt;1000;i++)&#123;db.collection2.insert(&#123;name:&quot;xiaomu&quot;+i,age:20+i&#125;);&#125;固定集合固定集合指的是事先创建而且大小固定的集合。固定集合特性：固定集合很想环形队列，如果空间不足，最早的文档就会被删除，为新的文档腾出空间。一般来说，固定集合适用于任何想要自动淘汰过期属性的场景，没有太多的操作限制.db.createCollection(&quot;collectionName&quot;,&#123;capped:true,size:10000,max:100&#125;);//size指定集合大小，单位为KB，max指定文档数量当文档数量上限时必须同时指定大小。淘汰机制只有在容量还没满时才会依据数量来工作。要是容量满了则会依据容量来工作。","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"js的直接赋值导致在循环中赋值失败的问题","slug":"js的直接赋值导致在循环中赋值失败的问题","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.402Z","comments":true,"path":"2019/05/06/js的直接赋值导致在循环中赋值失败的问题/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/js的直接赋值导致在循环中赋值失败的问题/","excerpt":"","text":"写js遇到了一个问题,就是说我在for循环值通过循环的值给一个对象赋值,但是的话每次赋值打印的结果都为最后一次赋的值,然后我就开始了debugger,发现我debug执行的话并没有问题,但是如果不debug就还会出现所有的赋值都是最后一个值得问题,这是我的代码 12345678910111213141516171819202122232425var poster_name = this.More_Temp_count[&apos;posterity_name&apos;]var city = this.More_Temp_count[&apos;city&apos;]var blackwidow_task = this.More_Temp_count[&apos;blackwidow_task&apos;]var redis_key = blackwidow_task[&apos;redis_key&apos;]var task_id = blackwidow_task[&apos;task_id&apos;]var key_test = blackwidow_task[&apos;blackwidow_output&apos;][&apos;db_config_test&apos;][&apos;key&apos;]var key_db = blackwidow_task[&apos;blackwidow_output&apos;][&apos;db_config&apos;][&apos;key&apos;]this.loading = truefor (var x in city_list)&#123; // 构造请求参数 console.log(&apos;1&apos;) console.log(city_list[x]) // 每次循环重新赋值 var More_Temp_count_copy = this.More_Temp_count More_Temp_count_copy[&apos;city&apos;] = city_list[x] console.log(More_Temp_count_copy[&apos;city&apos;]) More_Temp_count_copy[&apos;posterity_name&apos;] = poster_name.replace(city,city_list[x]) More_Temp_count_copy[&apos;blackwidow_task&apos;][&apos;redis_key&apos;] = redis_key.replace(city,city_list[x]) More_Temp_count_copy[&apos;blackwidow_task&apos;][&apos;task_id&apos;] = task_id.replace(city,city_list[x]) More_Temp_count_copy[&apos;blackwidow_task&apos;][&apos;blackwidow_output&apos;][&apos;db_config_test&apos;] = key_test.replace(city,city_list[x]) More_Temp_count_copy[&apos;blackwidow_task&apos;][&apos;blackwidow_output&apos;][&apos;db_config&apos;] = key_db.replace(city,city_list[x]) console.log(&apos;准备多次新增的复制模板信息&apos;,More_Temp_count_copy[&quot;city&quot;]) console.log(&apos;2&apos;)&#125; ———-然后我以为是因为请求异步的问题,然后把每次的值添加到一个列表里,在通过索引进行获取,然而还是不对 ———最后公司大佬进行解决,是因为js的拷贝问题,js的=赋值会直接把对象的内存地址赋值过去,所以改More_Temp_count_copy这个参数就相当于改this.More_Temp_count,所以才导致问题出现,解决办法呢,就是用深拷贝,直接把对象转为字符串,然后将字符串拷贝过去,这样就不会有赋值失败的问题了,修改一行代码 12// 每次循环重新赋值var More_Temp_count_copy = JSON.parse(JSON.stringify(this.More_Temp_count)) 问题解决!","categories":[],"tags":[{"name":"web前端","slug":"web前端","permalink":"https://127.0.0.1/blog/tags/web前端/"}]},{"title":"linux 安装Elasticsearchhe和kibana以及启动遇到的错误解决(已成功运行)","slug":"linux 安装Elasticsearchhe和kibana以及启动遇到的错误解决(已成功运行)","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.402Z","comments":true,"path":"2019/05/06/linux 安装Elasticsearchhe和kibana以及启动遇到的错误解决(已成功运行)/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/linux 安装Elasticsearchhe和kibana以及启动遇到的错误解决(已成功运行)/","excerpt":"","text":"linux安装es和kibana参考博文 https://blog.csdn.net/han12398766/article/details/88373869 启动报错11Exception elasticsearch.keystore 这个错是因为先用root用户启动的es创建的文件, 所以删除就好了 启动报错21234567892019-05-01 19:50:28,655 main ERROR Null object returned for RollingFile in Appenders.2019-05-01 19:50:28,656 main ERROR Null object returned for RollingFile in Appenders.2019-05-01 19:50:28,656 main ERROR Null object returned for RollingFile in Appenders.2019-05-01 19:50:28,656 main ERROR Null object returned for RollingFile in Appenders.2019-05-01 19:50:28,657 main ERROR Null object returned for RollingFile in Appenders.2019-05-01 19:50:28,657 main ERROR Null object returned for RollingFile in Appenders.2019-05-01 19:50:28,658 main ERROR Unable to locate appender &quot;rolling&quot; for logger config &quot;root&quot;2019-05-01 19:50:28,660 main ERROR Unable to locate appender &quot;index_indexing_slowlog_rolling&quot; for logger config &quot;index.indexing.slowlog.index&quot;2019-05-01 19:50:28,660 main ERROR Unable to locate appender &quot;audit_rolling&quot; for logger config &quot;org.elasticsearch.xpack.security.audit.logfile.LoggingAuditTrail&quot; 需要修改config配置里的log4j2.properties 文件, 将 logger.deprecation.level = warn 改为 error 启动错误312ERROR: [1] bootstrap checks failed[1]: max file descriptors [65535] for elasticsearch process is too low, increase to at least [65536] 修改 /etc/security/limits.conf 文件, 添加“ - nofile 65536 - memlock unlimited”","categories":[],"tags":[{"name":"linux,数据库","slug":"linux-数据库","permalink":"https://127.0.0.1/blog/tags/linux-数据库/"}]},{"title":"mongo中'dict' object has no attribute '_txn_read_preference'和 Sort exceeded memory limit","slug":"mongo中'dict' object has no attribute '_txn_read_preference'和 Sort exceeded memory limit","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.403Z","comments":true,"path":"2019/05/06/mongo中'dict' object has no attribute '_txn_read_preference'和 Sort exceeded memory limit/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/mongo中'dict' object has no attribute '_txn_read_preference'和 Sort exceeded memory limit/","excerpt":"","text":"前言 今天遇到了mongo 的一条语句两个问题, 在这里分享一下留个记录 问题一1Sort exceeded memory limit of 104857600 bytes, but did not opt in to external sorting. Aborting operation. Pass allowDiskUse:true to opt in. 这个问题是我使用mongo的aggregate聚合语句时出现的, 意思就是说排序超过了100M的限制, 没有进行外部缓存, 需要添加allowDiskUse 这个参数, 来做一个磁盘缓存, 我的语句1234567db.getCollection(&apos;price&apos;).aggregate([ &#123;&quot;$match&quot;: &#123;&quot;date&quot;: &#123;&quot;$lte&quot;: 20190326&#125;&#125;&#125;, &#123;&quot;$sort&quot;: &#123;&quot;date&quot;: -1&#125;&#125;, &#123;&quot;$group&quot;: &#123;&quot;_id&quot;: &quot;$city&quot;, &quot;dat&quot;: &#123;&quot;$first&quot;: &quot;$$ROOT&quot;&#125;&#125;&#125; ], &#123;&quot;allowDiskUse&quot;: true&#125; ) 这样就ok了 问题二因为上面在mongo可视化工具里面执行成功了, 所以我就放到程序中, 然后报了一个错1&#123;AttributeError&#125;&apos;dict&apos; object has no attribute &apos;_txn_read_preference&apos; 这就比较懵了, 解决办法就是把 {“allowDiskUse”: true} 换成 allowDiskUse=true 就可以了, 但是一般来说mongo的后续参数在可视化工具里面也可以这样写, 比如 multi=True之类的, 这个就不行, 可能是因为参数使用范围的问题吧..","categories":[],"tags":[{"name":"数据库,Python","slug":"数据库-Python","permalink":"https://127.0.0.1/blog/tags/数据库-Python/"}]},{"title":"mysql explain学习","slug":"mysql explain学习","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.404Z","comments":true,"path":"2019/05/06/mysql explain学习/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/mysql explain学习/","excerpt":"","text":"转自: https://www.cnblogs.com/yycc/p/7338894.html explain显示了mysql如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。 使用方法，在select语句前加上explain就可以了： 如： explain select surname,first_name form a,b where a.id=b.idEXPLAIN列的解释： table：显示这一行的数据是关于哪张表的 type：这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL type显示的是访问类型，是较为重要的一个指标，结果值从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL 一般来说，得保证查询至少达到range级别，最好能达到ref。 possible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句 key： 实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MYSQL会选择优化不足的索引。这种情况下，可以在SELECT语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MYSQL忽略索引 key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好 ref：显示索引的哪一列被使用了，如果可能的话，是一个常数 rows：MYSQL认为必须检查的用来返回请求数据的行数 Extra：关于MYSQL如何解析查询的额外信息。将在表4.3中讨论，但这里可以看到的坏的例子是Using temporary和Using filesort，意思MYSQL根本不能使用索引，结果是检索会很慢 extra列返回的描述的意义 Distinct:一旦MYSQL找到了与行相联合匹配的行，就不再搜索了 Not exists: MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行，就不再搜索了 Range checked for each Record（index map:#）:没有找到理想的索引，因此对于从前面表中来的每一个行组合，MYSQL检查使用哪个索引，并用它来从表中返回行。这是使用索引的最慢的连接之一 Using filesort: 看到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行 Using index: 列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候 Using temporary 看到这个的时候，查询需要优化了。这里，MYSQL需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上，而不是GROUP BY上 Where used 使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行，并且连接类型ALL或index，这就会发生，或者是查询有问题不同连接类型的解释（按照效率高低的顺序排序） system 表只有一行：system表。这是const连接类型的特殊情况 const:表中的一个记录的最大值能够匹配这个查询（索引可以是主键或惟一索引）。因为只有一行，这个值实际就是常数，因为MYSQL先读这个值然后把它当做常数来对待 eq_ref:在连接中，MYSQL在查询时，从前面的表中，对每一个记录的联合都从表中读取一个记录，它在查询使用了索引为主键或惟一键的全部时使用 ref:这个连接类型只有在查询使用了不是惟一或主键的键或者是这些类型的部分（比如，利用最左边前缀）时发生。对于之前的表的每一个行联合，全部记录都将从表中读出。这个类型严重依赖于根据索引匹配的记录多少—越少越好 range:这个连接类型使用索引返回一个范围中的行，比如使用&gt;或&lt;查找东西时发生的情况 index: 这个连接类型对前面的表中的每一个记录联合进行完全扫描（比ALL更好，因为索引一般小于表数据） ALL:这个连接类型对于前面的每一个记录联合进行完全扫描，这一般比较糟糕，应该尽量避免 先看一个例子： mysql&gt; explain select * from t_order; +----+-------------+---------+------+---------------+------+---------+------+--------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+------+---------------+------+---------+------+--------+-------+ | 1 | SIMPLE | t_order | ALL | NULL | NULL | NULL | NULL | 100453 | | +----+-------------+---------+------+---------------+------+---------+------+--------+-------+ 1 row in set (0.03 sec) 加上extended后之后： mysql&gt; explain extended select * from t_order; +----+-------------+---------+------+---------------+------+---------+------+--------+----------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------+------+---------------+------+---------+------+--------+----------+-------+ | 1 | SIMPLE | t_order | ALL | NULL | NULL | NULL | NULL | 100453 | 100.00 | | +----+-------------+---------+------+---------------+------+---------+------+--------+----------+-------+ 1 row in set, 1 warning (0.00 sec) 有必要解释一下这个长长的表格里每一列的含义： id SELECT识别符。这是SELECT的查询序列号select_typeSELECT类型,可以为以下任何一种: SIMPLE:简单SELECT(不使用UNION或子查询)PRIMARY:最外面的SELECTUNION:UNION中的第二个或后面的SELECT语句DEPENDENT UNION:UNION中的第二个或后面的SELECT语句,取决于外面的查询UNION RESULT:UNION 的结果SUBQUERY:子查询中的第一个SELECTDEPENDENT SUBQUERY:子查询中的第一个SELECT,取决于外面的查询DERIVED:导出表的SELECT(FROM子句的子查询)table输出的行所引用的表 type联接类型。下面给出各种联接类型,按照从最佳类型到最坏类型进行排序: system:表仅有一行(=系统表)。这是const联接类型的一个特例。const:表最多有一个匹配行,它将在查询开始时被读取。因为仅有一行,在这行的列值可被优化器剩余部分认为是常数。const表很快,因为它们只读取一次!eq_ref:对于每个来自于前面的表的行组合,从该表中读取一行。这可能是最好的联接类型,除了const类型。ref:对于每个来自于前面的表的行组合,所有有匹配索引值的行将从这张表中读取。ref_or_null:该联接类型如同ref,但是添加了MySQL可以专门搜索包含NULL值的行。index_merge:该联接类型表示使用了索引合并优化方法。unique_subquery:该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。index_subquery:该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr)range:只检索给定范围的行,使用一个索引来选择行。index:该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。ALL:对于每个来自于先前的表的行组合,进行完整的表扫描。possible_keys指出MySQL能使用哪个索引在该表中找到行 key 显示MySQL实际决定使用的键(索引)。如果没有选择索引,键是NULL。key_len 显示MySQL决定使用的键长度。如果键是NULL,则长度为NULL。ref 显示使用哪个列或常数与key一起从表中选择行。rows 显示MySQL认为它执行查询时必须检查的行数。多行之间的数据相乘可以估算要处理的行数。filtered 显示了通过条件过滤出的行数的百分比估计值。Extra该列包含MySQL解决查询的详细信息 Distinct:MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。Not exists:MySQL能够对查询进行LEFT JOIN优化,发现1个匹配LEFT JOIN标准的行后,不再为前面的的行组合在该表内检查更多的行。range checked for each record (index map: #):MySQL没有发现好的可以使用的索引,但发现如果来自前面的表的列值已知,可能部分索引可以使用。Using filesort:MySQL需要额外的一次传递,以找出如何按排序顺序检索行。Using index:从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。Using temporary:为了解决查询,MySQL需要创建一个临时表来容纳结果。Using where:WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。Using sort_union(…), Using union(…), Using intersect(…):这些函数说明如何为index_merge联接类型合并索引扫描。Using index for group-by:类似于访问表的Using index方式,Using index for group-by表示MySQL发现了一个索引,可以用来查 询GROUP BY或DISTINCT查询的所有列,而不要额外搜索硬盘访问实际的表。 一.select_type的说明 1.UNION: 当通过union来连接多个查询结果时，第二个之后的select其select_type为UNION。 mysql&gt; explain select * from t_order where order_id=100 union select * from t_order where order_id=200; +----+--------------+------------+-------+---------------+---------+---------+-------+------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+--------------+------------+-------+---------------+---------+---------+-------+------+-------+ | 1 | PRIMARY | t_order | const | PRIMARY | PRIMARY | 4 | const | 1 | | | 2 | UNION | t_order | const | PRIMARY | PRIMARY | 4 | const | 1 | | | NULL | UNION RESULT | &lt;union1,2&gt; | ALL | NULL | NULL | NULL | NULL | NULL | | +----+--------------+------------+-------+---------------+---------+---------+-------+------+-------+ 3 rows in set (0.34 sec) 2.DEPENDENT UNION与DEPENDENT SUBQUERY: 当union作为子查询时，其中第二个union的select_type就是DEPENDENT UNION。第一个子查询的select_type则是DEPENDENT SUBQUERY。 mysql&gt; explain select * from t_order where order_id in (select order_id from t_order where order_id=100 union select order_id from t_order where order_id=200); +----+--------------------+------------+-------+---------------+---------+---------+-------+--------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+--------------------+------------+-------+---------------+---------+---------+-------+--------+-------------+ | 1 | PRIMARY | t_order | ALL | NULL | NULL | NULL | NULL | 100453 | Using where | | 2 | DEPENDENT SUBQUERY | t_order | const | PRIMARY | PRIMARY | 4 | const | 1 | Using index | | 3 | DEPENDENT UNION | t_order | const | PRIMARY | PRIMARY | 4 | const | 1 | Using index | | NULL | UNION RESULT | &lt;union2,3&gt; | ALL | NULL | NULL | NULL | NULL | NULL | | +----+--------------------+------------+-------+---------------+---------+---------+-------+--------+-------------+ 4 rows in set (0.03 sec) 3.SUBQUERY: 子查询中的第一个select其select_type为SUBQUERY。 mysql&gt; explain select * from t_order where order_id=(select order_id from t_order where order_id=100); +----+-------------+---------+-------+---------------+---------+---------+-------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+-------+---------------+---------+---------+-------+------+-------------+ | 1 | PRIMARY | t_order | const | PRIMARY | PRIMARY | 4 | const | 1 | | | 2 | SUBQUERY | t_order | const | PRIMARY | PRIMARY | 4 | | 1 | Using index | +----+-------------+---------+-------+---------------+---------+---------+-------+------+-------------+ 2 rows in set (0.03 sec) 4.DERIVED: 当子查询是from子句时，其select_type为DERIVED。 mysql&gt; explain select * from (select order_id from t_order where order_id=100) a; +----+-------------+------------+--------+---------------+---------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+------------+--------+---------------+---------+---------+------+------+-------------+ | 1 | PRIMARY | &lt;derived2&gt; | system | NULL | NULL | NULL | NULL | 1 | | | 2 | DERIVED | t_order | const | PRIMARY | PRIMARY | 4 | | 1 | Using index | +----+-------------+------------+--------+---------------+---------+---------+------+------+-------------+ 2 rows in set (0.03 sec) 二.type的说明 1.system，const 见上面4.DERIVED的例子。其中第一行的type就是为system，第二行是const，这两种联接类型是最快的。 2.eq_ref 在t_order表中的order_id是主键，t_order_ext表中的order_id也是主键，该表可以认为是订单表的补充信息表，他们的关系是1对1，在下面的例子中可以看到b表的连接类型是eq_ref，这是极快的联接类型。 mysql&gt; explain select * from t_order a,t_order_ext b where a.order_id=b.order_id; +----+-------------+-------+--------+---------------+---------+---------+-----------------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+-------+--------+---------------+---------+---------+-----------------+------+-------------+ | 1 | SIMPLE | b | ALL | order_id | NULL | NULL | NULL | 1 | | | 1 | SIMPLE | a | eq_ref | PRIMARY | PRIMARY | 4 | test.b.order_id | 1 | Using where | +----+-------------+-------+--------+---------------+---------+---------+-----------------+------+-------------+ 2 rows in set (0.00 sec) 3.ref 下面的例子在上面的例子上略作了修改，加上了条件。此时b表的联接类型变成了ref。因为所有与a表中order_id=100的匹配记录都将会从b表获取。这是比较常见的联接类型。 mysql&gt; explain select * from t_order a,t_order_ext b where a.order_id=b.order_id and a.order_id=100; +----+-------------+-------+-------+---------------+----------+---------+-------+------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+-------+-------+---------------+----------+---------+-------+------+-------+ | 1 | SIMPLE | a | const | PRIMARY | PRIMARY | 4 | const | 1 | | | 1 | SIMPLE | b | ref | order_id | order_id | 4 | const | 1 | | +----+-------------+-------+-------+---------------+----------+---------+-------+------+-------+ 2 rows in set (0.00 sec) 4.ref_or_null user_id字段是一个可以为空的字段，并对该字段创建了一个索引。在下面的查询中可以看到联接类型为ref_or_null，这是mysql为含有null的字段专门做的处理。在我们的表设计中应当尽量避免索引字段为NULL，因为这会额外的耗费mysql的处理时间来做优化。 mysql&gt; explain select * from t_order where user_id=100 or user_id is null; +----+-------------+---------+-------------+---------------+---------+---------+-------+-------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+-------------+---------------+---------+---------+-------+-------+-------------+ | 1 | SIMPLE | t_order | ref_or_null | user_id | user_id | 5 | const | 50325 | Using where | +----+-------------+---------+-------------+---------------+---------+---------+-------+-------+-------------+ 1 row in set (0.00 sec) 5.index_merge 经常出现在使用一张表中的多个索引时。mysql会将多个索引合并在一起，如下例: mysql&gt; explain select * from t_order where order_id=100 or user_id=10; +----+-------------+---------+-------------+-----------------+-----------------+---------+------+------+-------------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+-------------+-----------------+-----------------+---------+------+------+-------------------------------------------+ | 1 | SIMPLE | t_order | index_merge | PRIMARY,user_id | PRIMARY,user_id | 4,5 | NULL | 2 | Using union(PRIMARY,user_id); Using where | +----+-------------+---------+-------------+-----------------+-----------------+---------+------+------+-------------------------------------------+ 1 row in set (0.09 sec) 6.unique_subquery 该联接类型用于替换value IN (SELECT primary_key FROM single_table WHERE some_expr)这样的子查询的ref。注意ref列，其中第二行显示的是func，表明unique_subquery是一个函数，而不是一个普通的ref。 mysql&gt; explain select * from t_order where order_id in (select order_id from t_order where user_id=10); +----+--------------------+---------+-----------------+-----------------+---------+---------+------+--------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+--------------------+---------+-----------------+-----------------+---------+---------+------+--------+-------------+ | 1 | PRIMARY | t_order | ALL | NULL | NULL | NULL | NULL | 100649 | Using where | | 2 | DEPENDENT SUBQUERY | t_order | unique_subquery | PRIMARY,user_id | PRIMARY | 4 | func | 1 | Using where | +----+--------------------+---------+-----------------+-----------------+---------+---------+------+--------+-------------+ 2 rows in set (0.00 sec) 7.index_subquery 该联接类型与上面的太像了，唯一的差别就是子查询查的不是主键而是非唯一索引。 mysql&gt; explain select * from t_order where user_id in (select user_id from t_order where order_id&gt;10); +----+--------------------+---------+----------------+-----------------+---------+---------+------+--------+--------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+--------------------+---------+----------------+-----------------+---------+---------+------+--------+--------------------------+ | 1 | PRIMARY | t_order | ALL | NULL | NULL | NULL | NULL | 100649 | Using where | | 2 | DEPENDENT SUBQUERY | t_order | index_subquery | PRIMARY,user_id | user_id | 5 | func | 50324 | Using index; Using where | +----+--------------------+---------+----------------+-----------------+---------+---------+------+--------+--------------------------+ 2 rows in set (0.00 sec) 8.range 按指定的范围进行检索，很常见。 mysql&gt; explain select * from t_order where user_id in (100,200,300); +----+-------------+---------+-------+---------------+---------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+-------+---------------+---------+---------+------+------+-------------+ | 1 | SIMPLE | t_order | range | user_id | user_id | 5 | NULL | 3 | Using where | +----+-------------+---------+-------+---------------+---------+---------+------+------+-------------+ 1 row in set (0.00 sec) 9.index 在进行统计时非常常见，此联接类型实际上会扫描索引树，仅比ALL快些。 mysql&gt; explain select count(*) from t_order; +----+-------------+---------+-------+---------------+---------+---------+------+--------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+-------+---------------+---------+---------+------+--------+-------------+ | 1 | SIMPLE | t_order | index | NULL | user_id | 5 | NULL | 100649 | Using index | +----+-------------+---------+-------+---------------+---------+---------+------+--------+-------------+ 1 row in set (0.00 sec) 10.ALL 完整的扫描全表，最慢的联接类型，尽可能的避免。 mysql&gt; explain select * from t_order; +----+-------------+---------+------+---------------+------+---------+------+--------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+------+---------------+------+---------+------+--------+-------+ | 1 | SIMPLE | t_order | ALL | NULL | NULL | NULL | NULL | 100649 | | +----+-------------+---------+------+---------------+------+---------+------+--------+-------+ 1 row in set (0.00 sec) 三.extra的说明 1.Distinct MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。对于此项没有找到合适的例子，求指点。 2.Not exists 因为b表中的order_id是主键，不可能为NULL，所以mysql在用a表的order_id扫描t_order表，并查找b表的行时，如果在b表发现一个匹配的行就不再继续扫描b了，因为b表中的order_id字段不可能为NULL。这样避免了对b表的多次扫描。 mysql&gt; explain select count(1) from t_order a left join t_order_ext b on a.order_id=b.order_id where b.order_id is null; +----+-------------+-------+-------+---------------+--------------+---------+-----------------+--------+--------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+-------+-------+---------------+--------------+---------+-----------------+--------+--------------------------------------+ | 1 | SIMPLE | a | index | NULL | express_type | 1 | NULL | 100395 | Using index | | 1 | SIMPLE | b | ref | order_id | order_id | 4 | test.a.order_id | 1 | Using where; Using index; Not exists | +----+-------------+-------+-------+---------------+--------------+---------+-----------------+--------+--------------------------------------+ 2 rows in set (0.01 sec) 3.Range checked for each record 这种情况是mysql没有发现好的索引可用，速度比没有索引要快得多。 mysql&gt; explain select * from t_order t, t_order_ext s where s.order_id&gt;=t.order_id and s.order_id&lt;=t.order_id and t.express_type&gt;5; +----+-------------+-------+-------+----------------------+--------------+---------+------+------+------------------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+-------+-------+----------------------+--------------+---------+------+------+------------------------------------------------+ | 1 | SIMPLE | t | range | PRIMARY,express_type | express_type | 1 | NULL | 1 | Using where | | 1 | SIMPLE | s | ALL | order_id | NULL | NULL | NULL | 1 | Range checked for each record (index map: 0x1) | +----+-------------+-------+-------+----------------------+--------------+---------+------+------+------------------------------------------------+ 2 rows in set (0.00 sec) 4.Using filesort 在有排序子句的情况下很常见的一种情况。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行。 mysql&gt; explain select * from t_order order by express_type; +----+-------------+---------+------+---------------+------+---------+------+--------+----------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+------+---------------+------+---------+------+--------+----------------+ | 1 | SIMPLE | t_order | ALL | NULL | NULL | NULL | NULL | 100395 | Using filesort | +----+-------------+---------+------+---------------+------+---------+------+--------+----------------+ 1 row in set (0.00 sec) 5.Using index 这是性能很高的一种情况。当查询所需的数据可以直接从索引树中检索到时，就会出现。上面的例子中有很多这样的例子，不再多举例了。 6.Using temporary 发生这种情况一般都是需要进行优化的。mysql需要创建一张临时表用来处理此类查询。 mysql&gt; explain select * from t_order a left join t_order_ext b on a.order_id=b.order_id group by b.order_id; +----+-------------+-------+------+---------------+----------+---------+-----------------+--------+---------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+-------+------+---------------+----------+---------+-----------------+--------+---------------------------------+ | 1 | SIMPLE | a | ALL | NULL | NULL | NULL | NULL | 100395 | Using temporary; Using filesort | | 1 | SIMPLE | b | ref | order_id | order_id | 4 | test.a.order_id | 1 | | +----+-------------+-------+------+---------------+----------+---------+-----------------+--------+---------------------------------+ 2 rows in set (0.00 sec) 7.Using where 当有where子句时，extra都会有说明。 8.Using sort_union(…)/Using union(…)/Using intersect(…) 下面的例子中user_id是一个检索范围，此时mysql会使用sort_union函数来进行索引的合并。而当user_id是一个固定值时，请参看上面type说明5.index_merge的例子，此时会使用union函数进行索引合并。 mysql&gt; explain select * from t_order where order_id=100 or user_id&gt;10; +----+-------------+---------+-------------+-----------------+-----------------+---------+------+------+------------------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+-------------+-----------------+-----------------+---------+------+------+------------------------------------------------+ | 1 | SIMPLE | t_order | index_merge | PRIMARY,user_id | user_id,PRIMARY | 5,4 | NULL | 2 | Using sort_union(user_id,PRIMARY); Using where | +----+-------------+---------+-------------+-----------------+-----------------+---------+------+------+------------------------------------------------+ 1 row in set (0.00 sec) 对于Using intersect的例子可以参看下例，user_id与express_type发生了索引交叉合并。 mysql&gt; explain select * from t_order where express_type=1 and user_id=100; +----+-------------+---------+-------------+----------------------+----------------------+---------+------+------+----------------------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+-------------+----------------------+----------------------+---------+------+------+----------------------------------------------------+ | 1 | SIMPLE | t_order | index_merge | user_id,express_type | user_id,express_type | 5,1 | NULL | 1 | Using intersect(user_id,express_type); Using where | +----+-------------+---------+-------------+----------------------+----------------------+---------+------+------+----------------------------------------------------+ 1 row in set (0.00 sec)9.Using index for group-by 表明可以在索引中找到分组所需的所有数据，不需要查询实际的表。 mysql&gt; explain select user_id from t_order group by user_id; +----+-------------+---------+-------+---------------+---------+---------+------+------+--------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+---------+-------+---------------+---------+---------+------+------+--------------------------+ | 1 | SIMPLE | t_order | range | NULL | user_id | 5 | NULL | 3 | Using index for group-by | +----+-------------+---------+-------+---------------+---------+---------+------+------+--------------------------+ 1 row in set (0.00 sec) 除了上面的三个说明，还需要注意rows的数值，多行之间的数值是乘积的关系，可以估算大概要处理的行数，如果乘积很大，那就很有优化的必要了。","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"mysql和redis数据库的查询添加脚本","slug":"mysql和redis数据库的查询添加脚本","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.404Z","comments":true,"path":"2019/05/06/mysql和redis数据库的查询添加脚本/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/mysql和redis数据库的查询添加脚本/","excerpt":"","text":"从mysql查询数据导入redis12345678910111213141516171819select_sql = &quot;select A.source_id,A.pic_url,A.id from newhouse_%s.complex_pic as A LEFT JOIN newhouse_%s.complex as B ON A.complex_id=B.complex_id WHERE A.source_id=%s AND B.weight &gt;= 50;&quot;def mysql_select(city, source_id): #从sql查询数据 cur_complex_r.execute(select_sql % (city, city, source_id)) #获取全部数据 row_1 = cur_complex_r.fetchall() #获取表名+sourceID 作为队列名 source_name = SOURCES_DICT[source_id] reids_dui = &quot;%s_%s&quot; % (source_name, city) reids_dui_tmp = &quot;%s_%s_tmp&quot; % (source_name, city) redisdb.delete(reids_dui) redisdb.delete(reids_dui_tmp) for x in row_1: ##存入redis队列 data = &#123;&apos;id&apos;: x.get(&apos;id&apos;, 0), &apos;pic_url&apos;: x.get(&apos;pic_url&apos;, &apos;&apos;)&#125; print reids_dui, x.get(&apos;pic_url&apos;, &apos;&apos;) redisdb.lpush(reids_dui, x.get(&apos;pic_url&apos;, &apos;&apos;)) redisdb.lpush(reids_dui_tmp, json.dumps(data)) 用redis的数据来更新mysql数据123456789101112131415161718192021222324update_sql = &quot;update newhouse_%s.complex_pic set noer_pic_url=&apos;%s&apos; where id=%s;&quot;#---------------------------------------从redis数据更新mysqldef mysql_update(city): #获取城市信息 #获取该城市所有的队列名 redis_names = redisdb.keys(&quot;*_%s_update&quot; % city) for redis_name in redis_names: #获取队列中所有的值 i = 0 while redisdb.llen(redis_name): x = redisdb.lpop(redis_name) if x: x = json.loads(x) nopic = x[&apos;nofinger_pic_url&apos;] pic_id = x[&apos;id&apos;] i += 1 print i, update_sql % (city, nopic, pic_id) cur_complex_w.execute(update_sql % (city, nopic, pic_id)) if i % 100 == 0: conn_complex_w.commit() else: conn_complex_w.commit() break","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"mysql普通索引和联合索引测试","slug":"mysql普通索引和联合索引测试","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.404Z","comments":true,"path":"2019/05/06/mysql普通索引和联合索引测试/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/mysql普通索引和联合索引测试/","excerpt":"","text":"索引就用空间来换取时间explain学习和参数代表的意思请参考 https://blog.csdn.net/ywdhzxf/article/details/84316712下面我会用explain 来测试联合索引和普通索引的作用项, 只测两个字段, source和name有兴趣的可以看下我下面的测试, 并不繁琐, 没兴趣的直接看结论吧 1 联合索引的第一个字段可以当普通索引来用(没有普通索引快, 但确实可以提高查询效率, 可以看下面只有联合索引的测试结果), 即比如我的联合索引是name+source, 那么我只拿name当where当条件也会命中索引, 但是用source就不会了, 查询全部的数据; 2 如果只是两个字段联合查询的话, 两个字段单个查询的次数也比较高, 那么就不如直接建立两个普通索引了(我的测试用的都是等于, 如果有其他条件的命中rows较多的话还是建议联合索引, 毕竟联合索引的type优先级较高); 3 如果几个字段经常联合查询的话, 很有必要建一个联合索引, 但可以把某个单个查询应用较高的字段放在第一位, 这样也比较省索引了; 4 相同rows的情况下, type的优先级越高(type的优先级查看explain学习那篇), 查的越快; 做的简单测试, 如果不对请大神评论指导, 谢谢. 联合索引(name+source), 普通索引(source, name)select * from db where source=1 and name=1 explain 测试: 三个索引全部命中 type ref rows 21行 select * from db where name=1 eplain 测试: 命中两个索引 type ref rows 30行 联合索引(name+source)select * from db where source=1 and name=1 explain 测试: 联合索引命中 type ref rows 21行 select * from db where name=1 eplain 测试: 命中索引 type ref rows 30行 select * from db where source=1 explain 测试: 没有命中索引 type all rows 10W+(所有的数据) 普通索引(source, name)select * from db where source=1 and name=1 explain 测试: 命中两个索引 type index_merge rows 2 select * from db where name=1 eplain 测试: 命中索引 type ref rows 30","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"pandas用法总结","slug":"pandas用法总结","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.404Z","comments":true,"path":"2019/05/06/pandas用法总结/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/pandas用法总结/","excerpt":"","text":"转载 https://blog.csdn.net/yiyele/article/details/80605909 在后面加了自己比较常用的一些方法代码 一、生成数据表1、首先导入pandas库，一般都会用到numpy库，所以我们先导入备用：import numpy as npimport pandas as pd 2、导入CSV或者xlsx文件：df = pd.DataFrame(pd.read_csv(‘name.csv’,header=1))df = pd.DataFrame(pd.read_excel(‘name.xlsx’)) 3、用pandas创建数据表： df = pd.DataFrame({&quot;id&quot;:[1001,1002,1003,1004,1005,1006], &quot;date&quot;:pd.date_range(&apos;20130102&apos;, periods=6), &quot;city&quot;:[&apos;Beijing &apos;, &apos;SH&apos;, &apos; guangzhou &apos;, &apos;Shenzhen&apos;, &apos;shanghai&apos;, &apos;BEIJING &apos;], &quot;age&quot;:[23,44,54,32,34,32], &quot;category&quot;:[&apos;100-A&apos;,&apos;100-B&apos;,&apos;110-A&apos;,&apos;110-C&apos;,&apos;210-A&apos;,&apos;130-F&apos;], &quot;price&quot;:[1200,np.nan,2133,5433,np.nan,4432]}, columns =[&apos;id&apos;,&apos;date&apos;,&apos;city&apos;,&apos;category&apos;,&apos;age&apos;,&apos;price&apos;]) 二、数据表信息查看1、维度查看：df.shape 2、数据表基本信息（维度、列名称、数据格式、所占空间等）：df.info() 3、每一列数据的格式：df.dtypes 4、某一列格式：df[‘B’].dtype 5、空值：df.isnull() 6、查看某一列空值：df.isnull() 7、查看某一列的唯一值：df[‘B’].unique() 8、查看数据表的值：df.values 9、查看列名称：df.columns 10、查看前10行数据、后10行数据：df.head() #默认前10行数据df.tail() #默认后10 行数据 三、数据表清洗1、用数字0填充空值：df.fillna(value=0) 2、使用列prince的均值对NA进行填充：df[‘prince’].fillna(df[‘prince’].mean()) 3、清楚city字段的字符空格：df[‘city’]=df[‘city’].map(str.strip) 4、大小写转换：df[‘city’]=df[‘city’].str.lower() 5、更改数据格式：df[‘price’].astype(‘int’) 6、更改列名称：df.rename(columns={‘category’: ‘category-size’}) 7、删除后出现的重复值：df[‘city’].drop_duplicates() 8、删除先出现的重复值：df[‘city’].drop_duplicates(keep=’last’) 9、数据替换：df[‘city’].replace(‘sh’, ‘shanghai’) 四、数据预处理 df1=pd.DataFrame({&quot;id&quot;:[1001,1002,1003,1004,1005,1006,1007,1008], &quot;gender&quot;:[&apos;male&apos;,&apos;female&apos;,&apos;male&apos;,&apos;female&apos;,&apos;male&apos;,&apos;female&apos;,&apos;male&apos;,&apos;female&apos;], &quot;pay&quot;:[&apos;Y&apos;,&apos;N&apos;,&apos;Y&apos;,&apos;Y&apos;,&apos;N&apos;,&apos;Y&apos;,&apos;N&apos;,&apos;Y&apos;,], &quot;m-point&quot;:[10,12,20,40,40,40,30,20]}) 1、数据表合并1.1 merge df_inner=pd.merge(df,df1,how=&apos;inner&apos;) # 匹配合并，交集 df_left=pd.merge(df,df1,how=&apos;left&apos;) # 左为主 df_right=pd.merge(df,df1,how=&apos;right&apos;) # 右为主 df_outer=pd.merge(df,df1,how=&apos;outer&apos;) # 并集 1.2 appendresult = df1.append(df2) 1.3 joinresult = left.join(right, on=’key’) 1.4 concat pd.concat(objs, axis=0, join=&apos;outer&apos;, join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True) objs︰ 一个序列或系列、 综合或面板对象的映射。如果字典中传递，将作为键参数，使用排序的键，除非它传递，在这种情况下的值将会选择 （见下文）。任何没有任何反对将默默地被丢弃，除非他们都没有在这种情况下将引发 ValueError。axis: {0，1，…}，默认值为 0。要连接沿轴。join: {‘内部’、 ‘外’}，默认 ‘外’。如何处理其他 axis(es) 上的索引。联盟内、 外的交叉口。ignore_index︰ 布尔值、 默认 False。如果为 True，则不要串联轴上使用的索引值。由此产生的轴将标记 0，…，n-1。这是有用的如果你串联串联轴没有有意义的索引信息的对象。请注意在联接中仍然受到尊重的其他轴上的索引值。join_axes︰ 索引对象的列表。具体的指标，用于其他 n-1 轴而不是执行内部/外部设置逻辑。keys︰ 序列，默认为无。构建分层索引使用通过的键作为最外面的级别。如果多个级别获得通过，应包含元组。levels︰ 列表的序列，默认为无。具体水平 （唯一值） 用于构建多重。否则，他们将推断钥匙。names︰ 列表中，默认为无。由此产生的分层索引中的级的名称。verify_integrity︰ 布尔值、 默认 False。检查是否新的串联的轴包含重复项。这可以是相对于实际数据串联非常昂贵。副本︰ 布尔值、 默认 True。如果为 False，请不要，不必要地复制数据。 例子：1.frames = [df1, df2, df3]2.result = pd.concat(frames) 2、设置索引列df_inner.set_index(‘id’) 3、按照特定列的值排序：df_inner.sort_values(by=[‘age’]) 4、按照索引列排序：df_inner.sort_index() 5、如果prince列的值&gt;3000，group列显示high，否则显示low：df_inner[‘group’] = np.where(df_inner[‘price’] &gt; 3000,’high’,’low’) 6、对复合多个条件的数据进行分组标记df_inner.loc[(df_inner[‘city’] == ‘beijing’) &amp; (df_inner[‘price’] &gt;= 4000), ‘sign’]=1 7、对category字段的值依次进行分列，并创建数据表，索引值为df_inner的索引列，列名称为category和sizepd.DataFrame((x.split(‘-‘) for x in df_inner[‘category’]),index=df_inner.index,columns=[‘category’,’size’])) 8、将完成分裂后的数据表和原df_inner数据表进行匹配df_inner=pd.merge(df_inner,split,right_index=True, left_index=True) 五、数据提取主要用到的三个函数：loc,iloc和ix，loc函数按标签值进行提取，iloc按位置进行提取，ix可以同时按标签和位置进行提取。 1、按索引提取单行的数值df_inner.loc[3] 2、按索引提取区域行数值df_inner.iloc[0:5] 3、重设索引df_inner.reset_index() 4、设置日期为索引df_inner=df_inner.set_index(‘date’) 5、提取4日之前的所有数据df_inner[:’2013-01-04’] 6、使用iloc按位置区域提取数据df_inner.iloc[:3,:2] #冒号前后的数字不再是索引的标签名称，而是数据所在的位置，从0开始，前三行，前两列。 7、适应iloc按位置单独提起数据df_inner.iloc[[0,2,5],[4,5]] #提取第0、2、5行，4、5列 8、使用ix按索引标签和位置混合提取数据df_inner.ix[:’2013-01-03’,:4] #2013-01-03号之前，前四列数据 9、判断city列的值是否为北京df_inner[‘city’].isin([‘beijing’]) 10、判断city列里是否包含beijing和shanghai，然后将符合条件的数据提取出来df_inner.loc[df_inner[‘city’].isin([‘beijing’,’shanghai’])] 11、提取前三个字符，并生成数据表pd.DataFrame(category.str[:3]) 六、数据筛选使用与、或、非三个条件配合大于、小于、等于对数据进行筛选，并进行计数和求和。 1、使用“与”进行筛选df_inner.loc[(df_inner[‘age’] &gt; 25) &amp; (df_inner[‘city’] == ‘beijing’), [‘id’,’city’,’age’,’category’,’gender’]] 2、使用“或”进行筛选df_inner.loc[(df_inner[‘age’] &gt; 25) | (df_inner[‘city’] == ‘beijing’), [‘id’,’city’,’age’,’category’,’gender’]].sort([‘age’]) 3、使用“非”条件进行筛选df_inner.loc[(df_inner[‘city’] != ‘beijing’), [‘id’,’city’,’age’,’category’,’gender’]].sort([‘id’]) 4、对筛选后的数据按city列进行计数df_inner.loc[(df_inner[‘city’] != ‘beijing’), [‘id’,’city’,’age’,’category’,’gender’]].sort([‘id’]).city.count() 5、使用query函数进行筛选df_inner.query(‘city == [“beijing”, “shanghai”]’) 6、对筛选后的结果按prince进行求和df_inner.query(‘city == [“beijing”, “shanghai”]’).price.sum() 七、数据汇总主要函数是groupby和pivote_table 1、对所有的列进行计数汇总df_inner.groupby(‘city’).count() 2、按城市对id字段进行计数df_inner.groupby(‘city’)[‘id’].count() 3、对两个字段进行汇总计数df_inner.groupby([‘city’,’size’])[‘id’].count() 4、对city字段进行汇总，并分别计算prince的合计和均值df_inner.groupby(‘city’)[‘price’].agg([len,np.sum, np.mean]) 八、数据统计数据采样，计算标准差，协方差和相关系数 1、简单的数据采样df_inner.sample(n=3) 2、手动设置采样权重weights = [0, 0, 0, 0, 0.5, 0.5]df_inner.sample(n=2, weights=weights) 3、采样后不放回df_inner.sample(n=6, replace=False) 4、采样后放回df_inner.sample(n=6, replace=True) 5、 数据表描述性统计df_inner.describe().round(2).T #round函数设置显示小数位，T表示转置 6、计算列的标准差df_inner[‘price’].std() 7、计算两个字段间的协方差df_inner[‘price’].cov(df_inner[‘m-point’]) 8、数据表中所有字段间的协方差df_inner.cov() 9、两个字段的相关性分析df_inner[‘price’].corr(df_inner[‘m-point’]) #相关系数在-1到1之间，接近1为正相关，接近-1为负相关，0为不相关 10、数据表的相关性分析df_inner.corr() 九、数据输出分析后的数据可以输出为xlsx格式和csv格式 1、写入Exceldf_inner.to_excel(‘excel_to_python.xlsx’, sheet_name=’bluewhale_cc’) 2、写入到CSVdf_inner.to_csv(‘excel_to_python.csv’) 十、测试代码` -- coding: utf-8 --“””@author xiaofei@email@auth@desc“””import time, jsonimport pandas as pd data = [{“name”: “skr”, “value”: 1}, {“name”: “test”, “value”: 2}, {“name”: “xi”, “value”: 3}] res = pd.DataFrame(data)print(res) 更改行名称res.rename(columns={‘name’: ‘keyword’, ‘value’: ‘other_id’}, inplace=True)print(res) 指定字段去重(保留第一个)res.drop_duplicates(subset=[‘keyword’], keep=’first’, inplace=True)print(res) 增加指定列res[‘time’] = time.time() # 全部赋固定值print(res)res[‘score’] = res[‘other_id’].map(lambda x: x + 1) # 根据对应值改变print(res) 更改指定列的类型res[‘times’] = res[‘time’].astype(‘int’) 删除指定列res.drop(‘time’, axis=1, inplace=True)print(res) 合并data2 = [{“name”: “skr”, “Gender”: 1}, {“name”: “test”, “Gender”: 2}, {“name”: “xi”, “Gender”: 1}, {“name”: “fei”}]res2 = pd.DataFrame(data2)res2.rename(columns={‘name’: ‘keyword’}, inplace=True)print(res2) 这块注意下, 以哪边为准很重要, 结果会差很多result = pd.merge(res, res2, how=’right’, on=’keyword’).fillna(value=0)result2 = pd.merge(res, res2, how=’left’, on=’keyword’).fillna(value=0)print(result)print(result2) 重置序列号index (可以在去重之后使用)result2.reset_index()print(result2) 格式转换datas = list(json.loads(result2.T.to_json()).values())print(datas)","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://127.0.0.1/blog/tags/Python/"}]},{"title":"pycurl的学习之路","slug":"pycurl的学习之路","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.404Z","comments":true,"path":"2019/05/06/pycurl的学习之路/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/pycurl的学习之路/","excerpt":"","text":"pycurl的模块用法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051c = pycurl.Curl() #创建一个curl对象 c.setopt(pycurl.CONNECTTIMEOUT, 5) #连接的等待时间，设置为0则不等待 c.setopt(pycurl.TIMEOUT, 5) #请求超时时间 c.setopt(pycurl.NOPROGRESS, 0) #是否屏蔽下载进度条，非0则屏蔽 c.setopt(pycurl.MAXREDIRS, 5) #指定HTTP重定向的最大数 c.setopt(pycurl.FORBID_REUSE, 1) #完成交互后强制断开连接，不重用 c.setopt(pycurl.FRESH_CONNECT,1) #强制获取新的连接，即替代缓存中的连接 c.setopt(pycurl.DNS_CACHE_TIMEOUT,60) #设置保存DNS信息的时间，默认为120秒 c.setopt(pycurl.URL,&quot;http://www.baidu.com&quot;) #指定请求的URL c.setopt(pycurl.USERAGENT,&quot;Mozilla/5.2 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322; .NET CLR 2.0.50324)&quot;) #配置请求HTTP头的User-Agentc.setopt(pycurl.HEADERFUNCTION, getheader) #将返回的HTTP HEADER定向到回调函数getheaderc.setopt(pycurl.WRITEFUNCTION, getbody) #将返回的内容定向到回调函数getbodyc.setopt(pycurl.WRITEHEADER, fileobj) #将返回的HTTP HEADER定向到fileobj文件对象c.setopt(pycurl.WRITEDATA, fileobj) #将返回的HTML内容定向到fileobj文件对象c.getinfo(pycurl.HTTP_CODE) #返回的HTTP状态码c.getinfo(pycurl.TOTAL_TIME) #传输结束所消耗的总时间c.getinfo(pycurl.NAMELOOKUP_TIME) #DNS解析所消耗的时间c.getinfo(pycurl.CONNECT_TIME) #建立连接所消耗的时间c.getinfo(pycurl.PRETRANSFER_TIME) #从建立连接到准备传输所消耗的时间c.getinfo(pycurl.STARTTRANSFER_TIME) #从建立连接到传输开始消耗的时间c.getinfo(pycurl.REDIRECT_TIME) #重定向所消耗的时间c.getinfo(pycurl.SIZE_UPLOAD) #上传数据包大小c.getinfo(pycurl.SIZE_DOWNLOAD) #下载数据包大小 c.getinfo(pycurl.SPEED_DOWNLOAD) #平均下载速度c.getinfo(pycurl.SPEED_UPLOAD) #平均上传速度c.getinfo(pycurl.HEADER_SIZE) #HTTP头部大小 发送post请求1234567891011121314151617181920#coding:utf8import pycurlimport StringIO import urllib url =&quot;http://www.baidu.com&quot;post_data_dic = &#123;&quot;project&quot;:&quot;test&quot;&#125;crl = pycurl.Curl() crl.setopt(pycurl.VERBOSE,1) crl.setopt(pycurl.FOLLOWLOCATION, 1) crl.setopt(pycurl.MAXREDIRS, 5)crl.setopt(pycurl.CONNECTTIMEOUT, 60) crl.setopt(pycurl.TIMEOUT, 300)crl.setopt(pycurl.HTTPPROXYTUNNEL,1)crl.fp = StringIO.StringIO() crl.setopt(pycurl.USERAGENT,&quot;dhgu hoho&quot;)crl.setopt(crl.POSTFIELDS, urllib.urlencode(post_data_dic)) crl.setopt(pycurl.URL, url) crl.setopt(crl.WRITEFUNCTION, crl.fp.write) crl.perform() print crl.fp.getvalue()","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://127.0.0.1/blog/tags/Python/"}]},{"title":"pymysql.err.OperationalError(2013, 'Lost connection to MySQL server during query')","slug":"pymysql.err.OperationalError(2013, 'Lost connection to MySQL server during query')","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.404Z","comments":true,"path":"2019/05/06/pymysql.err.OperationalError(2013, 'Lost connection to MySQL server during query')/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/pymysql.err.OperationalError(2013, 'Lost connection to MySQL server during query')/","excerpt":"","text":"问题描述 在执行脚本插入操作的时候, 报了一个 mysql 连接断开的错误, 报错信息为 pymysql.err.OperationalError: (2013, ‘Lost connection to MySQL server during query’), 原因是同时操作了太大的数据, 比如我就用 cursor.execute(sql) 执行了上千条插入语句, 然后再commit 一次, 这样同时数据量过大, 就会造成mysql连接断开, 但是数据还是会插进入, 不过有可能会丢数据; 解决办法加一个全局变量计数器, 然后在执行语句达到一定数量后再commint 一次, 这个数据可以根据mysql的性能来设置, 我这边设置成100之后就没问题了 (别忘了commit之后把计数器变量清零)","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"python divmod函数的使用和限制字符的写法","slug":"python divmod函数的使用和限制字符的写法","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.405Z","comments":true,"path":"2019/05/06/python divmod函数的使用和限制字符的写法/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/python divmod函数的使用和限制字符的写法/","excerpt":"","text":"###divmod python 的内置函数 这个函数是实现 a除以b，然后返回商与余数的元组。如果两个参数a,b都是整数，那么会采用整数除法，结果相当于（a//b, a % b)。如果a或b是浮点数，相当于（math.floor(a/b), a%b)。 ####例子 print divmod(10,100) print divmod(100,10) 值为: (0, 10) (10, 0) ###限定字串 ‘%2d-%02d’ % (5, 1) d是digit整数 %02d是表示输出不小于两位数，不足两位前面填充0， f是float小数 %.2f是保留2位小数，四舍五入，%.3f就是保留3位 ####例子 &gt;&gt;&gt; ‘%2d-%02d’ % (5, 1) ‘ 5-01’ &gt;&gt;&gt; ‘%.2f’ % 3.1415926 ‘3.14’ ##转换秒数格式 seconds = 500 m, s = divmod(seconds, 60) h, m = divmod(m, 60) print (“%02d:%02d:%02d” % (h, m, s))","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://127.0.0.1/blog/tags/Python/"}]},{"title":"python jpath的使用","slug":"python jpath的使用","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.405Z","comments":true,"path":"2019/05/06/python jpath的使用/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/python jpath的使用/","excerpt":"","text":"jsonpath一种跟xpath语法差不多的,专门用来解析json格式的提取方法 1234567from jsonpath_rw import jsonpath, parsehtml = &#123;&quot;rating&quot;:&#123;&quot;max&quot;:10,&quot;numRaters&quot;:79,&quot;average&quot;:&quot;9.1&quot;,&quot;min&quot;:0&#125;,&quot;subtitle&quot;:&quot;&quot;,&quot;author&quot;:[&quot;野夫&quot;],&quot;pubdate&quot;:&quot;2013-9&quot;,&quot;tags&quot;:[&#123;&quot;count&quot;:313,&quot;name&quot;:&quot;野夫&quot;,&quot;title&quot;:&quot;野夫&quot;&#125;,&#123;&quot;count&quot;:151,&quot;name&quot;:&quot;散文随笔&quot;,&quot;title&quot;:&quot;散文随笔&quot;&#125;,&#123;&quot;count&quot;:83,&quot;name&quot;:&quot;身边的江湖&quot;,&quot;title&quot;:&quot;身边的江湖&quot;&#125;,&#123;&quot;count&quot;:82,&quot;name&quot;:&quot;土家野夫&quot;,&quot;title&quot;:&quot;土家野夫&quot;&#125;,&#123;&quot;count&quot;:70,&quot;name&quot;:&quot;散文&quot;,&quot;title&quot;:&quot;散文&quot;&#125;,&#123;&quot;count&quot;:44,&quot;name&quot;:&quot;中国文学&quot;,&quot;title&quot;:&quot;中国文学&quot;&#125;,&#123;&quot;count&quot;:43,&quot;name&quot;:&quot;随笔&quot;,&quot;title&quot;:&quot;随笔&quot;&#125;,&#123;&quot;count&quot;:38,&quot;name&quot;:&quot;中国现当代文学&quot;,&quot;title&quot;:&quot;中国现当代文学&quot;&#125;],&quot;origin_title&quot;:&quot;&quot;,&quot;image&quot;:&quot;http://img5.douban.com/mpic/s27008269.jpg&quot;,&quot;binding&quot;:&quot;&quot;,&quot;translator&quot;:[],&quot;catalog&quot;:&quot;自序 让记忆抵抗n001 掌瓢黎爷n024 遗民老谭n039 乱世游击：表哥的故事n058 绑赴刑场的青春n076 风住尘香花已尽n083 “酷客”李斯n100 散材毛喻原n113 颓世华筵忆黄门n122 球球外传：n一个时代和一只小狗的际遇n141 童年的恐惧与仇恨n151 残忍教育n167 湖山一梦系平生n174 香格里拉散记n208 民国屐痕&quot;,&quot;pages&quot;:&quot;256&quot;,&quot;images&quot;:&#123;&quot;small&quot;:&quot;http://img5.douban.com/spic/s27008269.jpg&quot;,&quot;large&quot;:&quot;http://img5.douban.com/lpic/s27008269.jpg&quot;,&quot;medium&quot;:&quot;http://img5.douban.com/mpic/s27008269.jpg&quot;&#125;,&quot;alt&quot;:&quot;http://book.douban.com/subject/25639223/&quot;,&quot;id&quot;:&quot;25639223&quot;,&quot;publisher&quot;:&quot;广东人民出版社&quot;,&quot;isbn10&quot;:&quot;7218087353&quot;,&quot;isbn13&quot;:&quot;9787218087351&quot;,&quot;title&quot;:&quot;身边的江湖&quot;,&quot;url&quot;:&quot;http://api.douban.com/v2/book/25639223&quot;,&quot;alt_title&quot;:&quot;&quot;,&quot;author_intro&quot;:&quot;郑世平，笔名野夫，，以其特有的韵律表达世间的欢笑和悲苦。&quot;,&quot;price&quot;:&quot;32元&quot;&#125;res = parse(&quot;$.rating.average&quot;)cont = res.find(html)for x in cont: print x.value","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"python 中__init__ ,__new__ ,__call__,__del__ 方法","slug":"python 中__init__ ,__new__ ,__call__,__del__ 方法","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.405Z","comments":true,"path":"2019/05/06/python 中__init__ ,__new__ ,__call__,__del__ 方法/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/python 中__init__ ,__new__ ,__call__,__del__ 方法/","excerpt":"","text":"python 中__init__ ,__new__ ,__call__,__del__ 方法三个方法的作用123__new__ 负责创建一个实例对象__init__ 负责将该实例对象初始化__call__ 使实例能够像函数一样被调用，同时不影响实例本身的生命周期（__call__()不影响一个实例的构造和析构）。但是__call__()可以用来改变实例的内部成员的值。 __init__()1负责初始化, 在Python中，__init__()函数的意义等同于类的构造器（同理，__del__()等同于类的析构函数）。因此，__init__()方法的作用是创建一个类的实例 ###__call__() 123在Python中, 函数其实就是对象, 所有的函数都是一级对象, 也叫可调用对象, 这意味着Python中的函数的引用可以作为输入传递到其他的函数/方法中，并在其中被执行。 而Python中类的实例（对象）可以被当做函数对待。 一个类实例也可以变成一个可调用对象，只需要实现一个特殊方法__call__()。 也就是说，我们可以将它们作为输入传递到其他的函数/方法中并调用他们，正如我们调用一个正常的函数那样。而类中__call__()函数的意义正在于此。为了将一个类实例当做函数调用，我们需要在类中实现__call__()方法。也就是我们要在类中实现如下方法：def __call__(self, *args)。这个方法接受一定数量的变量作为输入。 假设x是X类的一个实例。那么调用x.__call__(1,2)等同于调用x(1,2)。这个实例本身在这里相当于一个函数。 __del__12345在对象的生命周期结束时, __del__会被调用,可以将__del__理解为&quot;析构函数&quot;.__del__定义的是当一个对象进行垃圾回收时候的行为。有一点容易被人误解, 实际上，x.__del__() 并不是对于del x的实现,但是往往执行del x时会调用x.__del__();调用x.__del__, 并不会删除这个对象, 但是如果你 del x,他会自动调用__del__方法, x这个对象就不存在了 __new__()123456789101112官方文档的说法, __new__方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。可以参考两段代码class PositiveInteger(int): def __init__(self, value): super(PositiveInteger, self).__init__(self, abs(value))i = PositiveInteger(-3)print i结果是 -3, 因为 int 是不可变的对象, 我们必须要重载__new__的方法才能起到自定义的作用class PositiveInteger(int): def __new__(cls, value): return super(PositiveInteger, cls).__new__(cls, abs(value)) i = PositiveInteger(-3) new方法可以做很多有趣的事情, 比如我最喜欢用new来实现单例模式 12345678因为类每一次实例化后产生的过程都是通过__new__来控制的，所以通过重载__new__方法，我们 可以很简单的实现单例模式class ChromeDriver(object): _instance = None def __new__(cls, *args, **kw): if not cls._instance: cls._instance = super(ChromeDriver, cls).__new__(cls, *args, **kw) return cls._instance 这是我在爬虫中间件中加的一个chromedrive 中间件, 实现了单例模式, 因为如果不用单例我开多并发的话可能会导致实例很多浏览器, 造成服务器压力过大(因为浏览器很吃内存), 实现单例模式就可以避免这个问题, 只会实例一个浏览器来进行页面请求. 单例模式1234单例模式（Singleton Pattern）是一种常用的软件设计模式，该模式的主要目的是确保某一个类只有一个实例存在。当你希望在整个系统中，某个类只能出现一个实例时，单例对象就能派上用场。具体的python实现单例模式的几种方法可以参考下面博客: https://www.cnblogs.com/huchong/p/8244279.html不过, 我感觉应该用__new__来实现单例模式应该是比较简单的一种了 比较1234567891 执行顺序 __new__, __init__, __call__2 __new__在创建一个实例的过程中必定会被调用,但__init__就不一定, __new__()决定是否要使用该__init__()方法，因为__new__()可以调用其他类的构造方法或者直接返回别的对象来作为本类 的实例。3 __new__方法总是需要返回该类的一个实例，而__init__不能返回除了None的任何值。比如下面例子: class Doo(object): def __init__(self): print(&apos;aa&apos;) return None (TypeError: __init__() should return None, 只能返回None) ###参考文档: https://www.cnblogs.com/superxuezhazha/p/5793536.html https://blog.csdn.net/yaokai_assultmaster/article/details/70256621 https://www.cnblogs.com/34fj/p/6358702.html https://segmentfault.com/a/1190000007256392(这篇对魔术方法介绍的很详细)","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://127.0.0.1/blog/tags/Python/"}]},{"title":"python 操作ES","slug":"python 操作ES","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.405Z","comments":true,"path":"2019/05/06/python 操作ES/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/python 操作ES/","excerpt":"","text":"python 操作es 的基操配置部分123456789101112131415161718192021222324252627&quot;&quot;&quot;@author xiaofei@email @auth@desc &quot;&quot;&quot;import pymongo, jsonfrom elasticsearch import Elasticsearchfrom elasticsearch import helpersimport math# mapping 定义你的es字段doc_mapping = &#123; &apos;properties&apos;: &#123; &quot;other_id&quot;: &#123;&quot;type&quot;: &quot;long&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;id&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &#125; &#125;# 创建ES连接es_conn_test = Elasticsearch([&quot;127.0.0.1:6666&quot;], maxsize=25)# es的基础配置, index_name, alias(别名可以创建多个), doc_type(表名)index_name = f&apos;complex_test&apos;online_alias = f&apos;online_complex_test&apos;type_name = f&apos;complex_city&apos; es的基操12345678910111213141516# es 创建库es_conn_test.indices.create(index=index_name, ignore=400)es_conn_test.indices.put_mapping(index=index_name, doc_type=type_name, body=doc_mapping)es_conn_test.indices.put_alias(index_name, online_alias)# 获取mappingres = es_conn_test.indices.get_mapping(index=index_name)print(json.dumps(res))# es查询res = es_conn_test.search(index=index_name, doc_type=type_name, body=&#123;&#125;)print(json.dumps(res))# 删除索引res = es_conn_test.indices.delete(index=index_name)print(res) mongo 数据批量插入es(注意, 如果需要插入的数据量太多的话要分批插入, 比如1000条一次, 根据性能自己调整)12345678910111213141516171819202122232425262728293031323334353637383940# 连接mongomongo_spider = pymongo.MongoClient(host=&apos;&apos;)cli = mongo_spider.test.test_test# 统计mongo里面的数量, 计算分页nums = cli.count()print(nums)pages = math.ceil(nums/1000)print(pages)for page in range(pages): ls = page *1000 # mongo分页查询 datas = list(cli.find(&#123;&#125;).limit(1000).skip(ls)) data = [] for x in datas: # 判断数据完整 res = &#123;&#125; for k, v in doc_mapping[&apos;properties&apos;].items(): if k == &apos;id&apos;: res[&apos;id&apos;] = x[&apos;key&apos;] elif not x.get(k, &apos;&apos;): if v[&apos;type&apos;] in [&apos;keyword&apos;, &apos;text&apos;]: res[k] = &apos;&apos; elif v[&apos;type&apos;] == &apos;long&apos;: res[k] = 0 elif v[&apos;type&apos;] == &apos;float&apos;: res[k] = 0.0 else: res[k] = x[k] # 下面注释这行是单条插入 # es_conn_test.create(index=index_name, doc_type=type_name, id=1, body=x) action = &#123;&quot;_index&quot;: index_name, &quot;_type&quot;: type_name, &quot;_source&quot;: res, &quot;_id&quot;: res[&apos;id&apos;]&#125; print(action) data.append(action) helpers.bulk(es_conn_test, data) print(f&apos;插入&#123;ls&#125;条&apos;)mongo_spider.close() es数据批量更新 (注意, 如果需要更新的数据量太多的话要分批更新, 比如1000条一次, 根据性能自己调整)1234567891011for x in data: id = x[&apos;id&apos;] time_score = x[&apos;time_score&apos;] price_score = x[&apos;price_score&apos;] doc = &#123;&quot;time_score&quot;: time_score, &quot;price_score&quot;: price_score&#125; datas = &#123;&quot;_index&quot;: f&quot;online_complex_test&quot;, &quot;_op_type&quot;: &quot;update&quot;, &quot;_type&quot;: f&quot;complex_city&quot;, &quot;_id&quot;: id, &apos;doc&apos;: doc&#125; print(datas) result.append(datas)helpers.bulk(es_conn, result)print(&apos;更新成功&apos;)","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"python 爬虫之字体(@font-face)防爬","slug":"python 爬虫之字体(@font-face)防爬","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.405Z","comments":true,"path":"2019/05/06/python 爬虫之字体(@font-face)防爬/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/python 爬虫之字体(@font-face)防爬/","excerpt":"","text":"python 爬虫 字体(@font-face)防爬字体防爬就是该网站在源码上的字体不是正常字体编码, 可能是自定义的一种字体, 然后通过对应关系在页面上进行展示, 这就是所谓的字体防爬, 但是他们想要在页面上进行展示的话还是需要导入字体包的, 所以咱们只需要把字体包下载下来进行对应关系转换就可以获得正确的内容了 一 主要是找到该网站导入的字体包的路径 这就是一般网站的字体路径, 后面的那个url在新页面打开就可以自动下载字体 如果直接在源码找不见的话, 那就打开开发者调试工具, 在network里面搜索font 字体, 找到字体的url地址, 进行下载 二 就是解析字体了需要下载 fontTools 包, 然后下面直接上代码 from fontTools.ttLib import TTFont #解析字体文件，获取字体映射关系 def parse_font(): font1 = TTFont(&apos;/Users/admin/Downloads/b.ttf&apos;) keys, values = [], [] for k, v in font1.getBestCmap().items(): if v.startswith(&apos;uni&apos;): keys.append(eval(&quot;u&apos;\\\\u{:x}&quot;.format(k) + &quot;&apos;&quot;)) values.append(chr(int(v[3:], 16))) else: keys.append(&quot;&amp;#x{:x}&quot;.format(k)) values.append(v) print(keys, values) return dict(zip(keys, values)) 这样就可以获取到 字体和编码的对应关系, 然后直接把抓取的乱码在对应关系里面进行转换就可以了 需要注意的是, 可能有的网站防爬可能会在编码上再给你加点难度, 比如数字的话: 你编码解出来是 5, 但实际是3, 遇到这种不要慌, 很有可能就是减法而已, 自己多测几次知道公式就好了 ###参考链接 https://blog.csdn.net/weixin_40214188/article/details/82596478","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"python3.6操作kafka, 生产者消费者队列","slug":"python3.6操作kafka, 生产者消费者队列","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.405Z","comments":true,"path":"2019/05/06/python3.6操作kafka, 生产者消费者队列/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/python3.6操作kafka, 生产者消费者队列/","excerpt":"","text":"介绍一下使用场景, 我这边之前使用redis做生产者消费者队列, 然后因为redis容量不大, 升级成本也比较高, 所以就拿kafka用来做消息队列, 因为数据是及时生产及时消费的, 所以说也就没有用太深, 拿topic当redis的key用的后续测试了一下, 用kafka的速度要比pykafka的速度快10倍左右, 代码也比较简便, 所以说还是用kafka连接吧, 示例代码:1234567891011121314from kafka import KafkaConsumerfrom kafka import KafkaProducerserver_list = [ &quot;192.168.0.1:xxxx&quot;,&quot;192.168.0.2:xxxx&quot;]# 生产者producer = KafkaProducer(bootstrap_servers=server_list, compression_type=&apos;gzip&apos;)msg = &#123;&quot;name&quot;: &quot;小飞1&quot;, &quot;text&quot;: &quot;测试1&quot;&#125;bmsg = bytes(str(msg).encode(&apos;utf-8&apos;))producer.send(&apos;xiaofei_test&apos;, bmsg)# 消费者consumer = KafkaConsumer(&apos;xiaofei_test&apos;, auto_offset_reset=&apos;earliest&apos;, bootstrap_servers=server_list)print(consumer)for msg in consumer: print(msg) 生产者(pykafka)12345678910111213141516171819202122from pykafka import KafkaClientimport jsonhosts = &quot;192.168.0.1:xxxx,192.168.0.2:xxxx&quot;client = KafkaClient(hosts=hosts)print(client.topics)key = &quot;test&quot;key = bytes(key, encoding=&apos;utf8&apos;)topic = client.topics[key]##因为是简单使用, 所以没有分组, 只是用topic 当redis中的key使用producer = topic.get_producer(sync=True)producer.start()print(producer)# 生产消息msg_dict =&#123;&quot;test&quot;: &quot;测试数据&quot;&#125;msg = json.dumps(msg_dict)with topic.get_sync_producer() as producer: producer.produce(bytes(msg, encoding=&apos;utf8&apos;)) print(msg) print(&apos;插入成功&apos;) 消费者(pykafka)123456789101112131415161718from pykafka import KafkaClienthosts = &quot;192.168.0.1:xxxx,192.168.0.2:xxxx&quot;client = KafkaClient(hosts=hosts)print(&quot;Kafka client:&quot;, client.topics)# 消费者key = &quot;chengdu-cdfgjtj-research_details&quot;key = bytes(key, encoding=&apos;utf8&apos;)topic = client.topics[key]#一些参数信息可以看一下 https://www.cnblogs.com/jun1019/p/6656223.htmlconsumer = topic.get_simple_consumer(auto_commit_enable=True)# consumer = topic.get_simple_consumer(consumer_group=&apos;test&apos;, auto_commit_enable=True, consumer_id=&apos;test&apos;)for message in consumer: if message is not None: print(&quot;consumer message:&quot;, message.offset) print(message.value)","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"python常用的一些方法","slug":"python常用的一些方法","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.406Z","comments":true,"path":"2019/05/06/python常用的一些方法/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/python常用的一些方法/","excerpt":"","text":"###列表分组 根据每个列表的最大数进行分组，返回多个列 def list_of_groups（init_list，childern_list_len）： list_of_groups = zip（（iter（init_list），） childern_list_len） end_list = [list（i）for our here_of_groups] count = len（init_list）％childern_list_len end_list.append（ini​​ t_list [-count：]）if count！= 0 else end_list return end_list list_of_groups（列表，10） 生成时间列表import datetime,time ##生成时间列表 def create_assist_date(self, datestart=None, dateend=None): # 创建日期辅助表 if dateend is None: dateend = datetime.datetime.now().strftime(&apos;%Y%m%d&apos;) # 转为日期格式` datestart = datetime.datetime.strptime(datestart, &apos;%Y%m%d&apos;) dateend = datetime.datetime.strptime(dateend, &apos;%Y%m%d&apos;) date_list = [] date_list.append(datestart.strftime(&apos;%Y%m%d&apos;)) while datestart &lt; dateend: # 日期叠加一天 datestart += datetime.timedelta(days=+1) # 日期转字符串存入列表 date_list.append(datestart.strftime(&apos;%Y%m%d&apos;)) return date_list ##时间转换 + - datestart = datetime.datetime.strptime(&apos;20170715&apos;, &apos;%Y%m%d&apos;) datestart += datetime.timedelta(days=-36) start = datestart.strftime(&apos;%Y%m%d&apos;) date_list = create_assist_date(start, &apos;20170715&apos;) ###获取列表的值的索引 知道列表的元素但不知道索引，可以用索引方法来进行查取，不过最好先设定一下，避免列表里有重复数据 list.index（ ‘想要查索引的元素’） 获取当前机器的cpu和内存使用率import psutil memory_now = psutil.virtual_memory().percent cpu_now = psutil.cpu_percent(interval=1) ###获取当前的Python脚本运行的PID和机器IP import platform import socket pids = os.getpid() addrs = socket.getaddrinfo(socket.gethostname(), None) ip = [item[4][0] for item in addrs if &apos;:&apos; not in item[4][0]][0] pid = re.findall(&quot;\\d+&quot;, str(pids))[0] 列表排序123按照a倒叙排列, 当a相同时, 按b倒叙排列all_list = [&#123;&quot;a&quot;: 10, &quot;b&quot;: 22&#125;, &#123;&quot;a&quot;: 11, &quot;b&quot;: 23&#125;, &#123;&quot;a&quot;: 11, &quot;b&quot;: 12&#125;]all_list.sort(key=lambda x: (-x[&quot;a&quot;], -x[&quot;b&quot;]))","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://127.0.0.1/blog/tags/Python/"}]},{"title":"python脚本,从mongo取数据发送html格式表格邮件","slug":"python脚本,从mongo取数据发送html格式表格邮件","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.406Z","comments":true,"path":"2019/05/06/python脚本,从mongo取数据发送html格式表格邮件/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/python脚本,从mongo取数据发送html格式表格邮件/","excerpt":"","text":"####工作需要,我要把我的工作成果每隔三天发送邮件,展示三天的工作情况,所以在linux上写了个脚本,每三天发一次邮件,下面是源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131coding: utf-8import sysreload(sys)sys.setdefaultencoding(&apos;utf8&apos;)from config import *from mongo_db import MongoDBimport time,datetimeimport randomimport jsonimport arrowimport smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.application import MIMEApplicationfrom email.mime.text import MIMETextfrom email.header import Headerfrom email import encoders#我是用当天日期作为表名存入mongo#链接mongo进行查询def select_mongo(data): pic_mongo = MongoDB(config = mongo_config).getClient().get_database(&apos;pic_db&apos;).get_collection(data) #查询值 record = pic_mongo.find_one(&#123;&quot;name&quot;: &quot;log&quot;&#125;) return recorddef querydata(): res = [] records = [] #获取现在的时间 &quot;2018-01-20&quot; qq = time.strftime(&quot;%Y-%m-%d&quot;) res.append(qq) #获取前两天的时间 for x in range(1,3): now = arrow.get(qq) tomorrow = now.replace(days=-x) res.append(tomorrow.strftime(&quot;%Y-%m-%d&quot;)) print res sendhead = [&apos;上传信息&lt;br&gt;&apos;] for tim in res: record =select_mongo(tim) records.append(record) sendhead.append(&apos;%s&lt;br&gt;&apos; % tim) #print records tablecontent = &apos;&lt;table border=&quot;1&quot; class=&quot;imagetable&quot;&gt;&lt;caption&gt;&lt;h4&gt;数据展示&lt;/h4&gt;&lt;/caption&gt;&apos; tablecontent += &quot;&lt;tr&gt;&quot; for title in sendhead: tablecontent += &apos;&lt;th&gt;&apos;+title+&apos;&lt;/th&gt;&apos; tablecontent += &quot;&lt;/tr&gt;&quot; for city_name in records[1]: if city_name == &apos;_id&apos; or city_name == &apos;name&apos;: pass else: tablecontent += &apos;&lt;tr&gt;&apos; tablecontent += &apos;&lt;td&gt;%s&lt;/td&gt;&apos; % city_name #print city_name for record in records: count_sum = record[city_name] tablecontent += &apos;&lt;td&gt;%s&lt;/td&gt;&apos; % count_sum tablecontent += &apos;&lt;/tr&gt;&apos; tablecontent += &apos;&lt;/table&gt;&apos; return tablecontenthead=&apos;&apos;&apos;&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;数据展示&lt;/title&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt; &lt;!-- &lt;meta http-equiv=&quot;refresh&quot; content=&quot;3600&quot;&gt; --&gt; &lt;style type=&quot;text/css&quot;&gt; table.imagetable &#123; font-family: verdana,arial,sans-serif; font-size:11px; color:#333333; border-width: 1px; border-color: #999999; border-collapse: collapse; width: 800px; &#125; table.imagetable th &#123; background:#b5cfd2 url(&apos;cell-white.jpg&apos;); border-width: 1px; padding: 8px; border-style: solid; border-color: #999999; &#125; table.imagetable td &#123; background:#dcddc0 url(&apos;cell-grey.jpg&apos;); border-width: 1px; padding: 8px; border-style: solid; border-color: #999999; width:150px; &#125; table.imagetable td.tou &#123; background:#dcddc0 url(&apos;cell-grey.jpg&apos;); border-width: 1px; padding: 8px; border-style: solid; border-color: #999999; width:800px; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt;&apos;&apos;&apos;tail=&apos;&apos;&apos; &lt;/body&gt;&lt;/html&gt;&apos;&apos;&apos;res = querydata()msg = MIMEMultipart()content=head+res+tailmsgtitle = &apos;【图片展示】&apos;text=MIMEText(content,&apos;html&apos;,&apos;utf-8&apos;)msg.attach(text)msg[&apos;from&apos;] = &apos;me&apos;msg[&apos;to&apos;] = &apos;小&apos;msg[&apos;Subject&apos;] = msgtitles = smtplib.SMTP(&apos;smtp.exmail.qq.com&apos;)s.login(&apos;邮箱&apos;, &apos;smtp码&apos;)s.sendmail(&apos;邮箱&apos;, [&apos;收件人邮箱&apos;], msg.as_string())print(&apos;success&apos;)s.close()if __name__ == &quot;__main__&quot;: content = head+res+tail print content","categories":[],"tags":[{"name":"Python,数据库","slug":"Python-数据库","permalink":"https://127.0.0.1/blog/tags/Python-数据库/"}]},{"title":"redis 哈希查询关键字的队列","slug":"redis 哈希查询关键字的队列","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.406Z","comments":true,"path":"2019/05/06/redis 哈希查询关键字的队列/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/redis 哈希查询关键字的队列/","excerpt":"","text":"redis 在哈希里面查询带关键字的小key hscan问题 比如说我现在有一个哈希队列, 做的是 用户id+行为编号: 时间 的一个缓存(随意举得例子,不要介意), 现在有一个用户注销了, 我现在需要把这个用户的所有信息缓存全部干掉, 你要怎么做? 获去该哈希队列所有的key然后再匹配? 太捞了, redis 提供了一种匹配机制, 类似 keys * 这种规则的匹配模式 解决比如我现在有一个这样的哈希队列 然后我现在想删除用户id 为617的所有信息, 调用命令 这样就好了, 然后再把小key 用hdel命令批量干掉就可以了, 是不是很简单方便 他其实还有很多用法:SCAN 命令用于迭代当前数据库中的数据库键。 SSCAN 命令用于迭代集合键中的元素。 HSCAN 命令用于迭代哈希键中的键值对。 ZSCAN 命令用于迭代有序集合中的元素（包括元素成员和元素分值）。 具体用法可以参考 http://redisdoc.com/key/scan.html#scan","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"scrapyd的安装和部署","slug":"scrapyd的安装和部署","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.406Z","comments":true,"path":"2019/05/06/scrapyd的安装和部署/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/scrapyd的安装和部署/","excerpt":"","text":"windows下scrapyd的安装和部署1 安装12345678环境要求: python 2.6 以上 Twisted 8.0 以上 scrapy setuptools scrapyd-client 直接 pip install scrapyd 就可以 在cmd输出scrapyd,然后在浏览器端访问 http://localhost:6800/ 就可以成功访问 2 部署scrapy项目12345678910scrapy startproject 项目名然后会有一个scrapy.cfg的文件![文件](http://img.blog.csdn.net/20180303173818819?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveXdkaHp4Zg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)好了之后在cmd项目目录直接启动scrapyd,然后再打开新的cmd进行项目部署 ![启动成功](http://img.blog.csdn.net/20180303173154636?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveXdkaHp4Zg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)项目部署直接通过scrapyd-deploy进行部署即可,找到安装好的scrapyd-client文件夹,在site-packages里面,打开把 scrapyd-deploy 复制到 C:\\Python27\\Scripts(自己的python安装目录)下,然后新建文件 scrapyd-deploy.bat ,在里面输入 @echo off &quot;C:\\Python27\\python.exe&quot; &quot;C:\\Python27\\Scripts\\scrapyd-deploy&quot; %1 %2 %3 %4 %5 %6 %7 %8 %9里面的路径同样是你的python安装路径 3 使用scrapyd-deploy进行部署123456789同样是cmd进入scrapy项目路径,指令格式为 scrapyd-deploy &lt;target&gt; -p &lt;project&gt; * target就是配置文件的deploy的名称，针对上面的配置就是demo * project如果不输就是配置文件中的project本例部署的指令：scrapyd-deploy demo ![部署成功](http://img.blog.csdn.net/20180303173212409?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveXdkaHp4Zg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)如果部署失败请参考 http://blog.csdn.net/ywdhzxf/article/details/79430378部署成功后就可以在scrapy项目里看见一个eggs文件夹,里面所存放的就是scrapyd-deploy的工程打包成.egg的文件，可以看到version就是文件的名称，每当我们执行一次scrapyd-deploy就会生成一个新的egg 4 运行Spider123456789我就随便写了一个进行测试,爬虫名叫 bai_spider,，现在就可以用API中的请求去调用或者执行爬虫了，这里以schedule.json为示例(详细参数http://scrapyd.readthedocs.io/en/stable/api.html#schedule-json)： curl http://localhost:6800/schedule.json -d project=fei -d spider=bai_spider curlwindows安装指南 http://blog.csdn.net/ywdhzxf/article/details/79431414 返回OK就成功了,可以通过scrapyd的jobs目录查看爬虫的运行情况参考博客: http://blog.csdn.net/u013708440/article/details/53425655","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"selenium+PhantomJS","slug":"selenium+PhantomJS","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.406Z","comments":true,"path":"2019/05/06/selenium+PhantomJS/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/selenium+PhantomJS/","excerpt":"","text":"selenium+PhantomJS123一直没时间写,今天有时间来写一下selenium+phantomjs是一个非常强大的工具,requests,urllib2是模拟请求发送参数获取页面,这个是直接用浏览器获取页面,很硬很强大的,不过他也有一个致命的bug,速度!速度贼慢,所以说他只适合爬取某些特别困难而且数据量不大的网站,然后浏览器我一般都用pahntomjds,毕竟无界面,感觉比谷歌火狐能快一点. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647说一下基本语法吧from selenium import webdriverfrom selenium.webdriver.common.keys import Keysbrowser1 = webdriver.PhantomJS(executable_path=r&quot;C:\\Users\\Administrator\\Desktop\\phantomjs-2.1.1-windows\\bin\\phantomjs.exe&quot;, ) # //内核 ###第一步往往是初学者最头疼的一步,因为有的时候你设置好了环境变量然后也不好用,所以说我一般都是直接用executable_path来指定路径,在项目里面也可以用相对路径来指定.browser1.get(&apos;www.baidu.com&apos;) ##输入要获取的网址browser1.save_screenshot(&apos;a.png&apos;) ###把当前打开的浏览器保存成图片,可以查看当前到哪步,建议在前面time.sleep()个一两秒,因为有的网站打开较慢,有延迟print browser1.page_source ###打印出当前获取到页面的源码#这个相当于是css选择器,by后面的可以为id,name,class等.res = browser1.find_element_by_id(&apos;fei&apos;).text # 获取标签名值res = browser1.find_elements_by_tag_name(&quot;input&quot;)# 也可以通过XPath来匹配res = browser1.find_element_by_xpath(&quot;//input[@id=&apos;passwd-id&apos;]&quot;) #可以定位输入框来往里面输入值,一般用于模拟登陆和查询browser1.find_element_by_id(&quot;fei&quot;).send_keys(u&quot;飞啊飞&quot;) #模拟点击browser1.find_element_by_id(&quot;fei&quot;).click() # ctrl+a 全选输入框内容browser1.find_element_by_id(&quot;fei&quot;).send_keys(Keys.CONTROL,&apos;a&apos;)# ctrl+x 剪切输入框内容browser1.find_element_by_id(&quot;fei&quot;).send_keys(Keys.CONTROL,&apos;x&apos;)# 输入框重新输入内容browser1.find_element_by_id(&quot;fei&quot;).send_keys(&quot;baidu&quot;)# 模拟Enter回车键browser1.find_element_by_id(&quot;fei&quot;).send_keys(Keys.RETURN)# 清除输入框内容browser1.find_element_by_id(&quot;fei&quot;).clear()# 关闭浏览器browser1.quit() 鼠标操作12345678910111213141516171819202122232425262728#导入 ActionChains 类from selenium.webdriver import ActionChains# 鼠标移动到 ac 位置ac = driver.find_element_by_xpath(&apos;element&apos;)ActionChains(driver).move_to_element(ac).perform()# 在 ac 位置单击ac = driver.find_element_by_xpath(&quot;elementA&quot;)ActionChains(driver).move_to_element(ac).click(ac).perform()# 在 ac 位置双击ac = driver.find_element_by_xpath(&quot;elementB&quot;)ActionChains(driver).move_to_element(ac).double_click(ac).perform()# 在 ac 位置右击ac = driver.find_element_by_xpath(&quot;elementC&quot;)ActionChains(driver).move_to_element(ac).context_click(ac).perform()# 在 ac 位置左键单击hold住ac = driver.find_element_by_xpath(&apos;elementF&apos;)ActionChains(driver).move_to_element(ac).click_and_hold(ac).perform()# 将 ac1 拖拽到 ac2 位置ac1 = driver.find_element_by_xpath(&apos;elementD&apos;)ac2 = driver.find_element_by_xpath(&apos;elementE&apos;)ActionChains(driver).drag_and_drop(ac1, ac2).perform() ###通过模拟登陆获取cookie 登录完成后可以通过get_cookies()开获取到通行cookie cookie = browser1.get_cookies() 更多内容:12参考链接,写的很详细,内容也很到位 链接：https://www.jianshu.com/p/4b89c92ff9b4","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"selenium+chromedrive 添加代理","slug":"selenium+chromedrive 添加代理","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.406Z","comments":true,"path":"2019/05/06/selenium+chromedrive 添加代理/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/selenium+chromedrive 添加代理/","excerpt":"","text":"selenium+chromedrive 添加代理, 有一个问题就是说不能在无头模式下使用,也就是说只能在本地使用, 我感觉应该是因为谷歌插件的问题, 在网上也没有找到比较好的方法, 下面是一套可以使用的代码, 其实本来phantomjs对代理的兼容性是最好的, 可惜不更新维护了, 所以只能等谷歌那边插件更新了123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103from selenium import webdriverimport string, timeimport zipfile# 代理服务器proxyHost = &quot;http-proxy-sg1.dobel.cn&quot;proxyPort = &quot;9180&quot;# 代理隧道验证信息proxyUser = &quot;********&quot;proxyPass = &quot;********&quot;def create_proxy_auth_extension(proxy_host, proxy_port, proxy_username, proxy_password, scheme=&apos;http&apos;, plugin_path=None): if plugin_path is None: plugin_path = r&apos;&#123;&#125;_&#123;&#125;@http-dyn.dobel.com_9020.zip&apos;.format(proxy_username, proxy_password) manifest_json = &quot;&quot;&quot; &#123; &quot;version&quot;: &quot;1.0.0&quot;, &quot;manifest_version&quot;: 2, &quot;name&quot;: &quot;Dobel Proxy&quot;, &quot;permissions&quot;: [ &quot;proxy&quot;, &quot;tabs&quot;, &quot;unlimitedStorage&quot;, &quot;storage&quot;, &quot;&lt;all_urls&gt;&quot;, &quot;webRequest&quot;, &quot;webRequestBlocking&quot; ], &quot;background&quot;: &#123; &quot;scripts&quot;: [&quot;background.js&quot;] &#125;, &quot;minimum_chrome_version&quot;:&quot;22.0.0&quot; &#125; &quot;&quot;&quot; background_js = string.Template( &quot;&quot;&quot; var config = &#123; mode: &quot;fixed_servers&quot;, rules: &#123; singleProxy: &#123; scheme: &quot;$&#123;scheme&#125;&quot;, host: &quot;$&#123;host&#125;&quot;, port: parseInt($&#123;port&#125;) &#125;, bypassList: [&quot;foobar.com&quot;] &#125; &#125;; chrome.proxy.settings.set(&#123;value: config, scope: &quot;regular&quot;&#125;, function() &#123;&#125;); function callbackFn(details) &#123; return &#123; authCredentials: &#123; username: &quot;$&#123;username&#125;&quot;, password: &quot;$&#123;password&#125;&quot; &#125; &#125;; &#125; chrome.webRequest.onAuthRequired.addListener( callbackFn, &#123;urls: [&quot;&lt;all_urls&gt;&quot;]&#125;, [&apos;blocking&apos;] ); &quot;&quot;&quot; ).substitute( host=proxy_host, port=proxy_port, username=proxy_username, password=proxy_password, scheme=scheme, ) with zipfile.ZipFile(plugin_path, &apos;w&apos;) as zp: zp.writestr(&quot;manifest.json&quot;, manifest_json) zp.writestr(&quot;background.js&quot;, background_js) return plugin_pathproxy_auth_plugin_path = create_proxy_auth_extension( proxy_host=proxyHost, proxy_port=proxyPort, proxy_username=proxyUser, proxy_password=proxyPass)option = webdriver.ChromeOptions()# option.add_argument(&apos;--no-sandbox&apos;)# option.add_argument(&apos;--disable-gpu&apos;)# option.add_argument(&quot;--start-maximized&quot;)option.add_extension(proxy_auth_plugin_path)drive = webdriver.Chrome(executable_path=&quot;../../config/chromedriver_mac&quot;,chrome_options=option)drive.get(&quot;http://httpbin.org/ip&quot;)print(drive.page_source)drive.close()","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"span标签溢出元素设置省略号","slug":"span标签溢出元素设置省略号","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.406Z","comments":true,"path":"2019/05/06/span标签溢出元素设置省略号/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/span标签溢出元素设置省略号/","excerpt":"","text":"###span 我一个写爬虫的也开始搞前端了,工作需要吗. 然后这次的遇到问题是我想把span标签的文本限定一下,让他到一定程度就展示省略号,然后就写了元素溢出的属性: overflow: hidden; text-overflow: ellipsis; 但是不成功,然后找原因,原来span标签为行内元素,必须要让他显示为块级元素才可以,加上属性: display: inline-block; 后成功解决. 贴一下 完美人生级代码: style=&quot;overflow:hidden; text-overflow:ellipsis; white-space:nowrap; -webkit-line-clamp: 1; -webkit-box-orient: vertical; word-break: break-all;width:100%;&quot; 写的是有点复杂了,其实我是不需要换行的,保险起见嘛,稳妥. 参考的博客文章也贴一下: http://blog.csdn.net/u010688587/article/details/53672793","categories":[],"tags":[{"name":"web前端","slug":"web前端","permalink":"https://127.0.0.1/blog/tags/web前端/"}]},{"title":"supervisor的使用","slug":"supervisor的使用","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.407Z","comments":true,"path":"2019/05/06/supervisor的使用/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/supervisor的使用/","excerpt":"","text":"工作需要,学习一波 ###常用 supervisorctl status 查看状态 supervisorctl reload 进程全部重启 在查看状态中第一列就是进程名,可以根据进程名来对单个进程进行操作: supervisorctl stop app进程名 停止单个进程 supervisorctl start app进程名 启动单个进程 supervisorctl shutdown 关闭 supervisorctl restart 重启","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://127.0.0.1/blog/tags/linux/"}]},{"title":"windows下curl的下载和使用","slug":"windows下curl的下载和使用","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.407Z","comments":true,"path":"2019/05/06/windows下curl的下载和使用/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/windows下curl的下载和使用/","excerpt":"","text":"###下载curl在cmd窗口进行使用https://curl.haxx.se/dlwiz/这是curl的下载导航,可以根据他来进行需求的确认然后进行下载 windows下载zip压缩包的,然后进行解压,运行的话有两种方式 ####1 通过exe文件进行使用 下载完进行解压,打开cmd窗口,进入到解压后的src目录,直接curl –help就可以使用了 ####2 全局使用 复制src目录里的exe文件,放到C:\\Windows\\System32 里面,就可以全局使用了","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"从mysql查询数据导入redis入队中","slug":"从mysql查询数据导入redis入队中","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.407Z","comments":true,"path":"2019/05/06/从mysql查询数据导入redis入队中/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/从mysql查询数据导入redis入队中/","excerpt":"","text":"俩篇对mysql和redis用法解释很详细的博客: mysql: http://www.jb51.net/article/117330.htm redis: https://www.cnblogs.com/xuchunlin/p/7067154.html import pymysql 建立mysql连接,ip、端口、用户名、密码(passwd,不能写成其他，例如：pwd或者p，否则报错)、库名 conn = pymysql.connect(host=&apos;127.0.0.1&apos;, user=&apos;root&apos;, passwd=&apos;123456&apos;, db=&apos;szz&apos;, port=3306, charset=&apos;utf8&apos;) #创建游标 cur = conn.cursor(cursor=pymysql.cursors.DictCursor) #指定cursor的类型为字典，返回结果类型是字典，不再是元组 #执行sql，返回值是int，查询出来的结果有几条 cur.execute(&apos;&apos;select source_id,pic_url from pic_%s.pic WHERE source_id=%s&apos;&apos;) #获取全部数据 row_1 = cur.fetchall() #游标移到起始位置 cur_complex_r.scroll(0) for x in row_1: ##存入redis队列 redisdb.lpush(reids_dui,x) redisdb.lpush(reids_dui_tmp,x) ###反向插入也简单 import redis db = 0 #连接redis,password不简写(否则或报错)，db若不写，则默认操作db0 conn_redis = redis.Redis(host=&apos;127.0.0.1&apos;, port=6379, password=&apos;123456&apos;, db=db) sql = &quot;update pic_&apos;%s&apos;.pic set finpic_url=&apos;%s&apos; where pic_url=&apos;%s&apos;; #获取队列中所有的值 zhi_1 = conn_redis.lrange(redis_dui_tmp,0,-1) for x in zhi_1: db = mysql.get(&apos;db&apos;, &apos;&apos;) ct = re.search(r&apos;_(\\s+)&apos;, db).group() cur_complex_w.execute( sql % (a,b,c))","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"使用mongo聚合分组查询获取每一组的时间最大的一条数据","slug":"使用mongo聚合分组查询获取每一组的时间最大的一条数据","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.407Z","comments":true,"path":"2019/05/06/使用mongo聚合分组查询获取每一组的时间最大的一条数据/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/使用mongo聚合分组查询获取每一组的时间最大的一条数据/","excerpt":"","text":"mongo聚合使用mongo的.aggregate方法, 类似一个聚合流水线的一个过程, 可以理解为文档经过多次管道阶段最后生成的结果, 可以直接看mongo aggregate官方文档 的一张图将整体文档经过多次管道最后生成想要的文档这个原理 官方也提供了很多 聚合管道运算符, 用到的朋友可以直接查询 讲一下我自己解决问题写的一条语句1234567db.getCollection(&apos;city&apos;).aggregate([ &#123;&quot;$match&quot;: &#123;&quot;date&quot;: &#123;&quot;$lte&quot;:20190313&#125;&#125;&#125;, &#123;&quot;$sort&quot;: &#123;&quot;date&quot;: -1&#125;&#125;, &#123;&quot;$group&quot;: &#123;_id: &quot;$city_id&quot;, firstDate: &#123; $first: &quot;$$ROOT&quot; &#125;&#125; &#125;]) 简单解释一下, 就是我需要求出按城市id聚合分组求日期小于 20190313的组内数据并按照日期进行倒序求第一条的所有数据, 过程就是1231 先找出日期小于 20190313的所有文档;2 按照日期倒序进行排序3 按照city_id进行聚合并求出第一个文档的所有内容, 内容会放入 firstDate 里面","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"使用pyocr和tesseract 来解析数字图片","slug":"使用pyocr和tesseract 来解析数字图片","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.407Z","comments":true,"path":"2019/05/06/使用pyocr和tesseract 来解析数字图片/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/使用pyocr和tesseract 来解析数字图片/","excerpt":"","text":"##获取图片中的数字因为最近要抓取的网站中有参数是在图片里面, 所以就需要来解析图片来获取参数, 图片清楚的话识别率是100%, 发出来工大家参考一下 前期准备 1 pip install pyocr 2 brew install tesseract 安装参考博客 https://www.jianshu.com/p/719c053f170b 3 pip3.6 install -i https://pypi.tuna.tsinghua.edu.cn/simple pillow 用镜像安装pillow ##实现代码 from urllib import request from PIL import Image import pyocr import pyocr.builders url = &apos;http://*******.png&apos; #获取图片后10为作为图片名 bug = url[-10:] path = f&quot;/tmp/{bug}&quot; #下载图片 request.urlretrieve(url, path) #获取里面的数字 nums = self.pic_num(pic=path) #删除图片 os.remove(path) def pic_num(self, pic): try: tools = pyocr.get_available_tools() print(tools) if len(tools) == 0: print(&quot;No OCR tool found&quot;) tool = tools[0] txt = tool.image_to_string( Image.open(pic), lang=&quot;eng&quot;, builder=pyocr.builders.TextBuilder(tesseract_layout=6) ) print(txt) return txt except Exception as e: print(&apos;获取数字失败&apos;, e)","categories":[],"tags":[{"name":"Python爬虫,Python","slug":"Python爬虫-Python","permalink":"https://127.0.0.1/blog/tags/Python爬虫-Python/"}]},{"title":"关于scrapyd-deploy项目部署时出现environment can only contain strings的解决方法","slug":"关于scrapyd-deploy项目部署时出现environment can only contain strings的解决方法","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.407Z","comments":true,"path":"2019/05/06/关于scrapyd-deploy项目部署时出现environment can only contain strings的解决方法/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/关于scrapyd-deploy项目部署时出现environment can only contain strings的解决方法/","excerpt":"","text":"在进行scrapyd学习的时候,用scrapyd-deploy进行项目部署,出现了一个错误 显示是环境只能包含字符串,然后我就在网上进行搜索,发现好多人都碰到过这个问题,没什么有效答案,然后我就找大神进行一波问题解决 根据错误找原因,在scrapyd源码中有一个utils.py文件,打开这个文件在126行和130行进行一点改动 将这两个参数改为str类型,问题解决","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]},{"title":"单字段测试 xpath+jpath+re+requests+phantomjs","slug":"单字段测试 xpath+jpath+re+requests+phantomjs","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.407Z","comments":true,"path":"2019/05/06/单字段测试 xpath+jpath+re+requests+phantomjs/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/单字段测试 xpath+jpath+re+requests+phantomjs/","excerpt":"","text":"xpath+jpath+re单字段测试最近测试发现这三个每次用都要重复写的东西太多了,然后封装了一下,做了一个单字段测试的类和接口,方便以后测试使用,只需要把类和包导入然后就可以直接使用了,简单方便 1234567891011121314151617181920212223242526272829303132333435363738394041424344import reimport json,chardetfrom lxml import etreefrom jsonpath import jsonpathimport requestsclass Spiders(object): def jpath(self, html,regex): body = str(html) # 可能有乱码问题 if isinstance(body, str) or isinstance(body, unicode): body = json.loads(body) try: result = jsonpath(body, regex) except Exception, e: result = [] print e if not result: result = [] return result def rpath(self, html,regex): try: body = html detector = chardet.detect(str(body)) if detector.get(&quot;encoding&quot;) == &quot;ascii&quot;: body = str(body).decode(&quot;unicode-escape&quot;) except Exception, e: body = str(html) result = re.findall(regex, body) return result def xpath(self, html,regex): parse_data = [&quot;&quot;] if regex: regexs = regex.split(&quot;&amp;&quot;) try: for i in range(len(regexs)): xml = etree.HTML(html) result = xml.xpath(regexs[i].strip()) if result: return result return [] except Exception, e: print e return parse_data 接口用的是post传参方式,根据困难度选择式调用requests或是phantomjs1234567891011121314151617181920212223242526272829303132333435363738def spider_xpath(request): result = &#123;&#125; # datas = [] spider = Spiders() try: data = request.body data = json.loads(data) url = data[&apos;url&apos;] #url rule = data[&apos;rule&apos;] #抓取规则 ru_type = data[&apos;type&apos;] #xpath,re,jpath difficult = data[&apos;difficult&apos;] #普通(a),特殊(b) if difficult == &apos;a&apos;: res = requests.get(url,headers=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36&quot;&#125;).text else: browser = webdriver.PhantomJS(executable_path=r&quot;../phantomjs_w/bin/phantomjs.exe&quot;) browser.get(url) time.sleep(2) res = browser.page_source if ru_type == &apos;xpath&apos;: datas = spider.xpath(res,rule) elif ru_type == &apos;rpath&apos;: datas = spider.rpath(res,rule) else: datas = spider.jpath(res,rule) detector = chardet.detect(str(datas)) if detector.get(&quot;encoding&quot;) == &quot;ascii&quot;: datas = str(datas).decode(&quot;unicode-escape&quot;) print datas result[&apos;page&apos;] = datas result[&apos;message&apos;] = &apos;测试成功&apos; result[&apos;code&apos;] = 1 print &apos;成功&apos; except Exception as e: print e result[&apos;message&apos;] = &apos;测试失败&apos; result[&apos;code&apos;] = -1 return HttpResponse(json.dumps(result, cls=JSONEncoder), content_type=&quot;application/json&quot;)","categories":[],"tags":[{"name":"Python爬虫,Python","slug":"Python爬虫-Python","permalink":"https://127.0.0.1/blog/tags/Python爬虫-Python/"}]},{"title":"对上传文件在浏览器端进行解析并使用","slug":"对上传文件在浏览器端进行解析并使用","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.408Z","comments":true,"path":"2019/05/06/对上传文件在浏览器端进行解析并使用/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/对上传文件在浏览器端进行解析并使用/","excerpt":"","text":"###因为工作需要所以要在支持本地上传文件并对文件进行解析和存放,所以用了H5的FileReader接口,超赞,很好用,发一下我参考的博客文档,写的很详细,直接就可以用,支持4种形式的读取操作 http://blog.csdn.net/zk437092645/article/details/8745647/","categories":[],"tags":[{"name":"web前端","slug":"web前端","permalink":"https://127.0.0.1/blog/tags/web前端/"}]},{"title":"将python程序打包成exe文件和播放mp3","slug":"将python程序打包成exe文件和播放mp3","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.408Z","comments":true,"path":"2019/05/06/将python程序打包成exe文件和播放mp3/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/将python程序打包成exe文件和播放mp3/","excerpt":"","text":"##打包文件 ###使用工具 PyInstaller 直接pip install 就可以 ###简单使用 进入文件目录 pyinstaller my.py 出现 successful 则为成功 ###注意事项 1 如果有大的模块的话很有可能会失败,比如 pandas 2 打包完会生成两个文件夹和一个文件,可执行的文件在dist目录下的exe; 3 如果代码里有路径操作则都以当前exe目录为准; 4 源码可以删除 ###使用参考博客 https://blog.csdn.net/zengxiantao1994/article/details/76578421?locationNum=9&amp;fps=1 ##使用python播放音乐 import pygame file=r’text.mp3’ pygame.mixer.init() track = pygame.mixer.music.load(file) pygame.mixer.music.play() time.sleep(30) pygame.mixer.music.stop()","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://127.0.0.1/blog/tags/Python/"}]},{"title":"服务器重启后 Host key verification failed","slug":"服务器重启后 Host key verification failed","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.408Z","comments":true,"path":"2019/05/06/服务器重启后 Host key verification failed/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/服务器重启后 Host key verification failed/","excerpt":"","text":"服务器重启后报错, 主机秘钥验证失败, 下面时解决办法这样就可以重新连接了, 然后再把自己的秘钥加上就行了","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://127.0.0.1/blog/tags/linux/"}]},{"title":"本地连接数据库的一些小知识","slug":"本地连接数据库的一些小知识","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.408Z","comments":true,"path":"2019/05/06/本地连接数据库的一些小知识/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/本地连接数据库的一些小知识/","excerpt":"","text":"mongodblinux安装12345678910111213141516创建一个/etc/yum.repos.d/mongodb-org-3.6.repo文件然后在里面写入: [mongodb-org-3.6] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/testing/x86_64/ gpgcheck=0 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-3.6.ascyum -y install mongodb-org记得关闭selinux service mongod start 启动如果用本地连 ,进入 /etc/mongod.conf 把 127.0.0.1 改为 0.0.0.0 (如果注释不管用的话) 基本操作1234567891011121314151617181920212223242526272829#coding:utf8import pymongo# 建立连接mongoclient = pymongo.MongoClient(host=&apos;192.168.6.6&apos;,port=27017)# 指定操作数据库db = mongoclient[&apos;alice&apos;]# 指定操作表（collection）sheet = db[&apos;host&apos;]try: # 增加一条 # sheet.insert(&#123;&apos;ip&apos; : &apos;192.168.1.1&apos;&#125;) # db.host.insert(&#123;&apos;ip&apos; : &apos;192.168.1.5&apos;, &apos;port&apos; : 27017&#125;) # 修改 # sheet.update(&#123;&apos;ip&apos; : &apos;192.168.1.2&apos;&#125;,&#123;&apos;$set&apos;:&#123;&apos;port&apos;:&apos;3306&apos;&#125;&#125;,multi=True) # 删除 # sheet.remove(&#123;&apos;ip&apos; : &apos;192.168.1.1&apos;&#125;) #查询 # res = sheet.find(&#123;&apos;port&apos; : 27017&#125;) # for item in res: # print item,type(item) passexcept Exception,e: print str(e) 在scrapy里写入 pipeline12345678910111213141516171819202122232425写入import pymongoclass MongoPipeline(object): def __init__(self): try: #建立连接 self.mongoclient = pymongo.MongoClient(host=&apos;39.106.37.83&apos;,port=27017) #制定操作数据库 self.db = self.mongoclient[&apos;demo&apos;] #指定操作表(collection) self.sheet = self.db[&apos;host&apos;] except Exception,e: print (&apos;连接失败&apos;) print str(e) def process_item(self, item, spider): try: #增加一条 self.sheet.insert(&#123;&apos;ip&apos; :item[&apos;ip&apos;], &apos;port&apos; : item[&apos;dk&apos;]&#125;) except Exception,e: print str(e) redispython-redis(分布式爬虫)1pip install python-redis linux安装12345678910111213141516171819202122232425261 下载源码包2 tar zxvf 解压3 mv 移动到 /etc/local4 cd redis里 make 编译5 make install 安装6 cd src7 ./redis-server 启动服务8 编辑redis-4.0.2下面的redis.conf #69行注释掉 69 #bind 127.0.0.1 #88行yes改为no 88 protected-mode no #136行 必须为no,否则连不上本地 136 daemonize no9 复制到etc下 cp redis.conf /etc/redis.conf7)添加全局变量export PATH=$PATH:/usr/local/redis-4.0.2/src8)设置好全局变量之后就可以启动redis了redis-server /etc/redis.conf9)关闭rediskill -9 redis端口#查看端口号ps -aux | grep redis mysql123456789101112131415本地连接mysql1 上阿里云 设置安全组 33062 进来linuxmysql mysql -u root -puse mysql grant all privileges on *.* to root@&quot;xxx.xxx.xxx.xxx&quot; identified by &quot;密码&quot;;flush privileges;select user,password,host from user; #查看是否添加成功如果还是不行,在linux界面运行iptables -L -n --line-numbersiptables -D INPUT 5","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://127.0.0.1/blog/tags/linux/"}]},{"title":"深度剖析Go语言数据结构","slug":"深度剖析Go语言数据结构","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.408Z","comments":true,"path":"2019/05/06/深度剖析Go语言数据结构/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/深度剖析Go语言数据结构/","excerpt":"","text":"转载地址 : http://www.open-open.com/lib/view/open1390373069882.html当向一个新程序员解释Go语言时，我发现如果解释Go的数据是如何在内存中表示的，将有助于建立编写高效程序的良好直觉。 基础类型 让我们从一些简单的例子开始： 深度剖析Go语言数据结构 变量i是int类型，在内存中占用一个32位的存储单位。（上图拿32位系统来举例；对以上的例子，只有指针才会在64位的机器上占用更多的空间——int始终是32位——然而我们仍然可以选择64位的系统。） 变量j是int32类型，因为它经过了显式的类型转化。尽管i和j有着同样的内存布局，但它们的类型是不一样的：像这样的赋值i = j会产生类型异常，必须通过显式的类型转换：i = int(j) 。 变量f是个浮点类型，上例中它代表着占用32位的浮点值。它的内存占用跟int32一样，但内部布局不同。 结构与指针 变量bytes是[5]byte类型，一个具有5个字节的数组。它的内存表示就只有5个紧挨着的字节，就像C里的数组一样。相似地，primes变量是一个拥有4个int数值的数组。 Go就像C而不像Java，它让程序员决定什么是或者不是一个指针。拿这个类型定义来举例： 1 type Point struct { X , Y int }定义一个叫Point的简单的结构类型，意味着内存里是两个相邻的int。 深度剖析Go语言数据结构 Point{ 10, 20 }这句复合语法表示一个被初始化的Point对象。而&amp;Point{ 10, 20 }这句则表示一个指向被初始化的Point对象的指针。前者在内存中有两个数据块，而后者则存放着一个指向两个数据块的指针。 结构中的字段被依次地排列在内存里面。 1 type Rect1 struct { Min, Max Point } 2 type Rect2 struct { Min, Max *Point } Rect1是一个拥有两个Point类型字段的结构，它的一条记录包含了两条Point记录——共4个int。Rect2是一个拥有两个Point类型指针的结构，在内存里它占两个Point指针的空间。 用过C的程序员也许对Point字段和*Point字段的区别并不陌生，而只用过Java或者Python（或者其他）则可能为需要做出选择而惊讶。通过 为程序员提供控制基础内存布局的可能，Go语言让程序员可以操控所有数据结构总尺寸、所分配变量的总数和内存访问的模式，这些对于建造高性能系统都至关重 要。 字符串 接下来我们继续看一些更有趣的数据类型。 （灰色箭头意味着实现上的真实表示方式，但这在编程过程中是不可见的） 一个字符串在内存中的表示被分成两段，一个指向字符串数据的指针和一个长度值。因为字符串是可枚举的，所以多个字符串共享同一段存储空间也是安全的，因此 如果对s字符串进行一个切片选择，将得到一个可能不一样的指针和长度，但它们也指向同一段字节序列。这意味着，切片并不需要分配空间或者是复制数据，创建 切片很容易，只需要传递明确的下标值就行了。 （顺带一句，在Java和某些与严重有一个著名的缺陷，当你对一个字符串进行切片并保存其中的一小部分，引用将在内存中保存原字符串的完整内容，即使只有 很小的一部分是被用到的。Go也有这个缺陷。要不然（我们尝试但最终舍弃了），我们将对切片采取昂贵的做法——分配内存并拷贝数据——大部分语言都避免这 种做法。 切片 切片是对数组中一段数据的引用。在内存中它有三段数据组成：一个指向数据头的指针、切片的长度、切片的容量。长度是索引操作的上界，如：x[i] 。容量是切片操作的上界，如：x[i:j] 。 跟对字符串做切片一样，对数组进行切片也不会导致复制：它只创建一个存放指针、长度和容量的结构体。在这个例子中，语句[ ] int { 2, 3, 5, 7, 11 } 创建了一个包含5个值的新数组，并为x切片设置了对应的值来描述那个数组。切片表达式x[1:3]并不为数据分配内存：它只填充切片结构的字段，用以复用 数组的存储空间。在这个例子中，长度是2，y[0]和y[1]是仅有的合法数据；但容量是4，y[0:4]是个合法的切片表达式。（查看高效GO获取更多关于长度、容量，以及如何使用切片的信息。） 由于切片不是指针而是多字段的结构，切片操作并不需要分配内存，即使对于切片头也是这样，它可以常驻在栈中。这种表示法让切片的使用的代价很低，就像C中 传递精确的指针和长度一样。Go原生地在切片中使用了指针，这也意味着每个切片操作都分配一个内存对象。即使有了一个更快的内存分配器，这为垃圾回收带来 了不必要的工作，并且我们发现，就像字符串那个例子一样，给于精确的下标，比进行切片操作好。大多数情况下，避免不必要的间接引用和内存分配可以让切片足 够高效了。 new和make Go有两种创建数据结构的方法：new和make 。它们的区别是常见的早期困惑，但很快就会变得自然。基础的区别在于，new(T)返回一个*T类型，一个可以被隐性反向引用的指针（如图中的黑色指 针），而make(T,args)返回一个原始的T，它并不是一个指针。T中常有写隐性的指针（如图中的灰色指针）。new返回一个指向初始化为全0值的 指针，而make返回一个复杂的结构。 有一种方式让两者统一起来，它对于传统的C和C++是一个重大的改变：定义make(T)来返回一个指向新分配的T的指针，因此new(Point)和 make(Point)的效果是一致的。我们用这种方法尝试了一段日子，但最终觉得这对于一些期待一个分配函数的人来说，实在太难以接受了。 中文原文地址：http://www.zingscript.com/post/195 英文原文地址：http://research.swtch.com/godata","categories":[],"tags":[{"name":"GoLang","slug":"GoLang","permalink":"https://127.0.0.1/blog/tags/GoLang/"}]},{"title":"深度掌握Redis：5 大难题解决方案+单线程优劣势+高并发快原因","slug":"深度掌握Redis：5 大难题解决方案+单线程优劣势+高并发快原因","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.408Z","comments":true,"path":"2019/05/06/深度掌握Redis：5 大难题解决方案+单线程优劣势+高并发快原因/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/深度掌握Redis：5 大难题解决方案+单线程优劣势+高并发快原因/","excerpt":"","text":"这大概是最详细的一篇关于Redis文章了，分享给热爱钻研技术的童鞋们~1转载 https://studygolang.com/topics/8514 一、Redis雪崩、穿透、并发等5大难题解决方案 缓存雪崩 数据未加载到缓存中，或者缓存同一时间大面积的失效，从而导致所有请求都去查数据库，导致数据库CPU和内存负载过高，甚至宕机。 比如一个雪崩的简单过程： 1、redis集群大面积故障； 2、缓存失效，但依然大量请求访问缓存服务redis； 3、redis大量失效后，大量请求转向到mysql数据库； 4、mysql的调用量暴增，很快就扛不住了，甚至直接宕机； 5、由于大量的应用服务依赖mysql和redis的服务，这个时候很快会演变成各服务器集群的雪崩，最后网站彻底崩溃。 如何预防缓存雪崩： 1.缓存的高可用性 缓存层设计成高可用，防止缓存大面积故障。即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务，例如 Redis Sentinel 和 Redis Cluster 都实现了高可用。 2.缓存降级 可以利用ehcache等本地缓存(暂时支持)，但主要还是对源服务访问进行限流、资源隔离（熔断）、降级等。 当访问量剧增、服务出现问题仍然需要保证服务还是可用的。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级，这里会涉及到运维的配合。 降级的最终目的是保证核心服务可用，即使是有损的。比如推荐服务中，很多都是个性化的需求，假如个性化需求不能提供服务了，可以降级补充热点数据，不至于造成前端页面是个大空白。 在进行降级之前要对系统进行梳理，比如：哪些业务是核心(必须保证)，哪些业务可以容许暂时不提供服务(利用静态页面替换)等，以及配合服务器核心指标，来后设置整体预案，比如： （1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； （2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警； （3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级； （4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。 3.Redis备份和快速预热 Redis数据备份和恢复；快速缓存预热。4.提前演练 最后，建议还是在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，对高可用提前预演，提前发现问题。 缓存穿透 缓存穿透是指查询一个一不存在的数据。例如：从缓存redis没有命中，需要从mysql数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。 解决思路： 如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。设置一个过期时间或者当有值的时候将缓存中的值替换掉即可。 可以给key设置一些格式规则，然后查询之前先过滤掉不符合规则的Key。 缓存并发 这里的并发指的是多个redis的client同时set key引起的并发问题。其实redis自身就是单线程操作，多个client并发操作，按照先到先执行的原则，先到的先执行，其余的阻塞。当然，另外的解决方案是把redis.set操作放在队列中使其串行化，必须的一个一个执行。 缓存预热 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。 这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 解决思路： 直接写个缓存刷新页面，上线时手工操作下；数据量不大，可以在项目启动的时候自动进行加载；目的就是在系统上线前，将数据加载到缓存中。 二、Redis为什么是单线程，高并发快的3大原因详解 Redis的高并发和快速原因 1.redis是基于内存的，内存的读写速度非常快； 2.redis是单线程的，省去了很多上下文切换线程的时间； 3.redis使用多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。 下面重点介绍单线程设计和IO多路复用核心设计快的原因。 为什么Redis是单线程的？ 1.官方答案 因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。 2.性能指标 关于redis的性能，官方网站也有，普通笔记本轻松处理每秒几十万的请求。 3.详细原因 1）不需要各种锁的性能消耗 Redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在hash当中添加或者删除 一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。 总之，在单线程的情况下，就不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。 2）单线程多进程集群方案 单线程的威力实际上非常强大，每核心效率也非常高，多线程自然是可以比单线程有更高的性能上限，但是在今天的计算环境中，即使是单机多线程的上限也往往不能满足需要了，需要进一步摸索的是多服务器集群化的方案，这些方案中多线程的技术照样是用不上的。 所以单线程、多进程的集群不失为一个时髦的解决方案。 3）CPU消耗 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU。 但是如果CPU成为Redis瓶颈，或者不想让服务器其他CUP核闲置，那怎么办？ 可以考虑多起几个Redis进程，Redis是key-value数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。 Redis单线程的优劣势 单进程单线程优势 代码更清晰，处理逻辑更简单不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗不存在多进程或者多线程导致的切换而消耗CPU。 单进程单线程弊端 无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善。 IO多路复用技术 redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。 多路-指的是多个socket连接，复用-指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。epoll是最新的也是目前最好的多路复用技术。 这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。 Redis高并发快总结 Redis是纯内存数据库，一般都是简单的存取操作，线程占用的时间很多，时间的花费主要集中在IO上，所以读取速度快。 再说一下IO，Redis使用的是非阻塞IO，IO多路复用，使用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，减少了线程切换时上下文的切换和竞争。 Redis采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争。 另外，数据结构也帮了不少忙，Redis全程使用hash结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度。 还有一点，Redis采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大。 三、Redis缓存和MySQL数据一致性方案详解 需求起因 在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。所以，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问MySQL等数据库。 这个业务场景，主要是解决读数据从Redis缓存，一般都是按照下图的流程来进行业务操作。 读取缓存步骤一般没有什么问题，但是一旦涉及到数据更新：数据库和缓存更新，就容易出现缓存(Redis)和数据库（MySQL）间的数据一致性问题。 不管是先写MySQL数据库，再删除Redis缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。举一个例子： 1.如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。 2.如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。 因为写和读是并发的，没法保证顺序,就会出现缓存和数据库的数据不一致的问题。如何解决？这里给出两个解决方案，先易后难，结合业务和技术代价选择使用。 缓存和数据库一致性解决方案 1.第一种方案：采用延时双删策略 在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。 伪代码如下：123456public void write(String key,Object data)&#123; redis.delKey(key); db.updateData(data); Thread.sleep(500); redis.delKey(key); &#125; 具体的步骤就是： 先删除缓存；再写数据库；休眠500毫秒；再次删除缓存。 那么，这个500毫秒怎么确定的，具体该休眠多久呢？ 需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。 当然这种策略还要考虑redis和数据库主从同步的耗时。最后的的写数据的休眠时间：则在读数据业务逻辑的耗时基础上，加几百ms即可。比如：休眠1秒。 设置缓存过期时间 从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。 该方案的弊端 结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。 2、第二种方案：异步更新缓存(基于订阅binlog的同步机制) 技术整体思路： MySQL binlog增量订阅消费+消息队列+增量数据更新到redis 读Redis：热数据基本都在Redis写MySQL:增删改都是操作MySQL更新Redis数据：MySQ的数据操作binlog，来更新到Redis。 Redis更新 1）数据操作主要分为两大块 一个是全量(将全部数据一次写入到redis)一个是增量（实时更新） 这里说的是增量,指的是mysql的update、insert、delate变更数据。 2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。 这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。 其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。 这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。 当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://127.0.0.1/blog/tags/数据库/"}]},{"title":"用flask完成mongo的增删改查","slug":"用flask完成mongo的增删改查","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.409Z","comments":true,"path":"2019/05/06/用flask完成mongo的增删改查/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/用flask完成mongo的增删改查/","excerpt":"","text":"用flask小小的写了一下mongo的增删改查,挺好用的上代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#coding:utf8from bson.objectid import ObjectIdfrom pymongo import MongoClientfrom flask import Flask,url_forapp = Flask(__name__)client = MongoClient(&apos;127.0.0.1&apos;,27017)db = client.spider_rulescoon = db.rules_template# items = coon.find_one(&#123;&apos;source_name&apos;:&apos;cdfgj&apos;&#125;)# print items# print 2@app.route(&quot;/select/&lt;source_name&gt;&quot;)def select(source_name): print 1 res = &#123;&#125; x = coon.find_one(&#123;&apos;source_name&apos;:source_name&#125;) print type(x) for y in x: res[y] = x[y] print res return str(res)@app.route(&quot;/dele/&lt;source_name&gt;&quot;)def dele(source_name): print source_name source_name = &#123;&apos;_id&apos;: ObjectId(source_name)&#125; if coon.find(source_name): print type(source_name),source_name coon.remove(source_name) res = &apos;suessce&apos; else: res = &apos;bad&apos; return str(res)@app.route(&quot;/add/&lt;source_name&gt;&quot;)def addd(source_name): coon.insert(&#123;&apos;name&apos;:source_name&#125;) if coon.find(&#123;&apos;name&apos;:source_name&#125;): print source_name res = &apos;suessce&apos; else: res = &apos;bad&apos; return str(res)@app.route(&quot;/update/&lt;source_name&gt;/&lt;sou&gt;&quot;)def up(source_name,sou): coon.update(&#123;&apos;name&apos;:source_name&#125;,&#123;&apos;name&apos;:sou&#125;) if coon.find(&#123;&apos;name&apos;:sou&#125;): print sou res = &apos;suessce&apos; else: res = &apos;bad&apos; return str(res)@app.route(&quot;/xiaofei&quot;)def yes(): return &quot;小飞&quot;if __name__ == &apos;__main__&apos;: app.run(debug=True) # with app.test_request_context(): # print url_for(&apos;hello&apos;, source_name=&apos;cdfgj&apos;)","categories":[],"tags":[{"name":"数据库,Python","slug":"数据库-Python","permalink":"https://127.0.0.1/blog/tags/数据库-Python/"}]},{"title":"编码问题的解决","slug":"编码问题的解决","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.410Z","comments":true,"path":"2019/05/06/编码问题的解决/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/编码问题的解决/","excerpt":"","text":"###编码报错 UnicodeEncodeError: ‘ascii’ codec can’t encode characters in position 7-8: ordinal not in range(128) 一般当出现这种错误的时候我们都知道是编码问题,于是我们一般都在文件中用 import sys reload(sys) sys.setdefaultencoding(&apos;utf-8&apos;) 来进行声明,但是当你运行一个大的项目找不见在哪报错的时候,或者报错文件相对较多的时候,就不能这么麻烦了,可以在python的第三方包下面新建一个文件来解决这个问题 在python的Lib\\site-packages文件夹下新建一个sitecustomize.py，内容为： # encoding=utf8 import sys reload(sys) sys.setdefaultencoding(‘utf8’) 这样就能完美解决这个问题了; 原答案来自: http://wangye.org/blog/archives/629/ 中的评论用户分享","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://127.0.0.1/blog/tags/Python/"}]},{"title":"通过XML-RPC API在本地远程控制supervisor","slug":"通过XML-RPC API在本地远程控制supervisor","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.410Z","comments":true,"path":"2019/05/06/通过XML-RPC API在本地远程控制supervisor/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/通过XML-RPC API在本地远程控制supervisor/","excerpt":"","text":"通过XML-RPC API在本地远程控制supervisorxml-rpc都已经把所有都封装好了,只需要根据文档选择自己需要调用的接口即可 下面是我写的两个测试代码 12345678910111213141516#coding:utf8import xmlrpclibserver = xmlrpclib.Server(&apos;http://127.0.0.1:9001/RPC2&apos;)#api方法 (官网参数: http://supervisord.org/api.html)methods = server.system.listMethods()print methods#停止进程# res = server.supervisor.stopProcess(&apos;text&apos;)#开始进程# res = server.supervisor.startProcess(&apos;text&apos;)#获取进程信息res = server.supervisor.getProcessInfo (&apos;text&apos;)print res 友情提示: 如果实在外网进行连接,记得把 配置文件(/etc/supervisord.conf)中的port端口开为 0.0.0.0:9001 关于supervisor的学习和部署 https://www.cnblogs.com/smail-bao/p/5673434.html 以及另外一种通过代码来连接服务器进行操作 http://blog.csdn.net/ywdhzxf/article/details/79461976","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://127.0.0.1/blog/tags/linux/"}]},{"title":"通过python代码远程连接服务器进行操作之paramiko模块","slug":"通过python代码远程连接服务器进行操作之paramiko模块","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.410Z","comments":true,"path":"2019/05/06/通过python代码远程连接服务器进行操作之paramiko模块/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/通过python代码远程连接服务器进行操作之paramiko模块/","excerpt":"","text":"###通过python的paramiko模块来远程连接服务器进行linux命令操作 参考博文 https://www.cnblogs.com/wang-yc/p/5628114.html 里面里很全面,不过python版本是3.5的, 2.7也可以使用,不过里面的参数可能会不一样,比如通过秘钥链接时的参数 key ,在python2.7使用时,为 pkey.","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://127.0.0.1/blog/tags/Python/"}]},{"title":"linux的基础命令","slug":"linux的基础命令","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.403Z","comments":true,"path":"2019/05/06/linux的基础命令/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/linux的基础命令/","excerpt":"","text":"linux简介安装 安装操作系统软件 CentOS6.8-***.iso 密码原则 12位以上 大小写字符 数字 特殊符号 DeskTop 图形界面 开发 Basic Server 服务器 没有图形界面 Server 安装Basic Server 701软件包 分区 swap备用内存2000M ，/boot exit 执行内存200M 剩余全部为根目录exit空间 setup 设置防火墙之类 ifconfig 查看网络状态 最后service network restart 重启网络服务确定无误 常用端口123306 mysql 80 apache（http） 22 sshpgrep 应用 得到进程号 常用命令12345678ls (显示当前目录下文件)ls 目录名 (显示指定目录下文件)ls -l (长格式显示目录文件)ls -l 文件名 (长格式显示指定文件)ls -a (显示所有文件(包含隐藏文件))ls -al (长格式显示当前目录下所有文件)ls -h (文件大小显示为常见大小单位 B KB MB ...)ls -d (显示目录本身，而不是里面的子文件) 12345cd /usr/local/src 切换到指定路径(使用绝对路径方式)cd ~ 进入当前用户的家目录cd - 进入上次目录cd .. 进入上一级目录cd . 进入当前目录 1234567891011121314151617181920/bin 命令保存目录（普通用户就可以读取的命令）/boot 启动目录，启动相关文件/dev 设备文件保存目录/etc 配置文件保存目录/home 普通用户的家目录/lib 系统库保存目录/mnt 系统挂载目录/media 挂载目录/root 超级用户的家目录/tmp 临时目录/sbin 命令保存目录（超级用户才能使用的目录）/proc 直接写入内存的/sys 将内核的一些信息映射，可供应用程序所用/usr 系统软件资源目录/usr/bin/ 系统命令（普通用户）/usr/sbin/ 系统命令（超级用户）/var 系统相关文档内容/var/log/ 系统日志位置/var/spool/mail/ 系统默认邮箱位置/var/lib/ 默认安装的库文件目录 提示符123456789[dragon@localhost ~]$ ① ② ③ ④①：dragon 代表 当前登录用户②：localhost 代表 主机名③：~ 代表 当前所在目录 ~ 用户家目录； /root 管理员； /home/用户名 普通用户④：$ 代表 当前用户身份 $ 普通用户； # 超级用户 linux简单操作追加12345ls -lR 可以看当前目录文件以及目录里面的文件/opt 临时应用的SH 可以放置bd 数据库 bak 备份last 查看历史登录记录（用户名，时间，登录中断之类）$0 文件本身 printf 格式化打印 常用操作1234567891011121314151617181920212223242526mkdir t1 创建目录mkdir -p t1/t2/t3 递归创建目录rmdir t1 删除目录（只能删除空目录）rm -rf t1 强制删除目录文件rm -r t1 递归删除文件和目录 touch t1.py 创建空文件touch -t 20170612 t1 修改文件时间cat t1.py 查看文件内容cat -n t1.py 查看文件内容并列出行号more t1.py 分屏显示文件内容 空格向上 b 向下 q 退出head t1.py 显示文件前几行（默认10行）head -n 20 文件名 显示文件前20 行head -n -29 文件名 显示文件最后20行（不常用，有tail）ln -s 源文件 目标文件 创建链接文件（必须用绝对路径）nano 文件名 纳米编辑器man ls 帮助命令 ls --help 帮助命令date 查看系统时间 date -s 20170220 设定日期 date -s 09:30:00 设定时间du -sh 目录名 统计目录大小 -s 和 -h 常见单位 df -h 查看系统内存（查看占用内存。以便为后安装程序做准备）df -hT 查看系统内存（T 类型）netstat -an |grep ESTABLISHED | wc -l 查看服务器的连接数source 文件名 执行这个文件（一般在改配置时使用） 123456789cp 源文件 目标位置 (复制) 或cp 源文件 目标位置/目标名称 (复制并改名)cp -r 复制目录cp -p 连带文件属性一起复制cp -d 若源文件是链接文件，则复制链接属性cp -a 相当于 cp -pdr 123mv 源文件 目标位置mv /root/test /tmp/ 将/root/下的test文件移动到/tmp/目录下mv /root/test /root/newtest 将/root/下的test文件改名为newtest 快捷键1234ctrl +c 强行终止ctrl + l 清屏tab 命令补全 文件目录名补全（常用）反撤销 ctrl + r 权限位123456789101112131415161718192021222324-rw-r--r--. 1 root root 44736 7月 18 00:38 install.log权限位是十位 第一位：代表文件类型 - 普通文件 d 目录文件 l 链接文件默认文件 644 默认目录 755 默认链接文件 777最大 777 最小 000 其他九位：代表各用户的权限 (前三位=属主权限u 中间三位=属组权限g 其他人权限o) r 读 4 w 写 2 x 执行 1 权限对文件的含义 r：读取文件内容 如：cat、more、head、tail w：编辑、新增、修改文件内容 如：vi、echo 但是不包含删除文件 x：可执行 /tmp/11/22/abc --------- 权限对目录的含义 r：可以查询目录下文件名 如：ls w：具有修改目录结构的权限 如：touch、rm、mv、cp x：可以进入目录 如：cd 权限操作123456789chmod u+x aa aa文件的属主加上执行权限chmod u-x aa aa文件的属主减去执行权限chmod g+w,o+w aa aa文件的属组和其他人加上写权限chmod u=rwx aa aa文件的用户权限改为所有权限(读+写+执行)chmod 777 -R aa 给当前文件和子文件都给上权限另一种表现方式：chmod 755 aa aa文件的属主权限是rwx，属组和其他人是rxchmod 644 aa aa文件的属主权限是rw，属组和其他人是r 123chown 用户名 文件名 改变文件属主chown user1 aa user1必须存在chown user1:user1 aa 改变属主同时改变属组 用户操作12345useradd 用户名 功能描述：添加用户userdel -r 用户名 功能描述： 连同家目录一起删除用户id -u 检测当前用户的UIDpasswd 用户名 功能描述：设定用户密码 查找命令whereis ls 查找命令所在位置 12345678910111213141516171819202122find 查找位置 -name 文件名find / -name aabbcc 查找/目录下名为 aabbcc的文件更多选项： -name 文件名 按照文件名查找 -user 用户名 按照属主用户名查找文件 -group 组名 按照属组组名查找文件 -nouser 找没有属主的文件 (\b除了这三个文件：/proc、/sys、/mnt/cdrom) -size 按照文件大小k M 如：find / -size +50k -type 按照文件类型查找(f=普通 d=目录 l=链接) -perm 按照权限查找 如：find /root -perm 644 -iname 按照文件名查找，不区分大小写格式 find / -name index.htmlfind / -user pythonfind / -group pythonfind / -nouserfind / -type ffind / -perm 777find / -size +10M -a -size -20M -exec rm -rf &#123;&#125; \\;find / -size +10M -a -size -20M -ok rm -rf &#123;&#125; \\;exec 直接执行不提示 OK 提示危险操作 123456grep 选项 &apos;字串&apos; 查找路径grep &apos;字串&apos; 路径grep -i &quot;root&quot; /etc/passwd -v 反向选择 -i 忽略大小写 -n 显示行号 管道符 | 连接命令 ls -l /etc/ | more 分屏显示etc里面的目录和文件 cat -n install.log | grep “zip” 查看文档显示行号并且查找‘zip’字符 压缩和解压1234567tar.gz tar -zcvf p1.tar.gz test1.py install.log 压缩文件tar -zxvf p1.tar.gz 解压缩 tar -ztvf p1.tar.gz 查看不解压tar -zxvf p1.tar.gz -C txt 定向解压缩tar -zcPf p1.tar.gz test1.py 压缩文件 -P 保留备份文件的原有权限和属性。常用于备份 12345.tar.bz2tar -jcvf txt.tar.bz2 txt 压缩目录tar -jxvf txt.tar.bz2 解压缩tar -jtvf txt.tar.bz2 查看不解压tar -jxvf txt.tar.bz2 -C /tmp 定向解压缩 关机重启12345shutdown -h now 现在关机 init 0 关机shutdown -r now 重启系统 reboot 重启系统 init 6 重启 挂载12345678910111. 物理连接 2.手动挂载 3.识别设备使用 mount 光驱设备名 （/dev/sr0 /dev/cdrom） 挂载点 /media /mnt (手动建立挂载点 mkdir /mnt/cdrom) mount /dev/sr0 /media cd /media/1. 卸载 umount umount /dev/sr0 umount /media 注意：退出挂载目录，才能卸载fdisk -l 查看设备名mount -t iso9660 /dev/cdrom /mnt/cdrom 网络命令12345ping 测试网络连通性ping -c 5 192.168.2.222 ifconfig 查看网络设备 Linux ipconfig windows ipconfig /all vim操作 1234567891011121314151617181920212223242526272829303132333435363738394041vim编辑器全屏幕纯文本编辑器vi -&gt; vim (加强版)三种模式： 命令模式 插入模式 末行模式 a i o s Shitft + : ESCa 追加 i 插入 o 打开 s 删除当前字符插入 :wq 保存退出 :w 保存 :q 退出:q! 不保存退出 :wq! 强制保存退出（root）vim test1.py 命令模式vim install.log 光标移动 h j k l :n 行号 :300 gg 光标移动到第一行 G 移动最后一行设置行号 :set nu 取消行号 :set nonu 复制 yy 复制多行 nyy 粘贴 p 删除(剪切)单字符 x 删除多字符 nx 删除（剪切）行 dd 删除多行 ndd dG 从当前行到最后全部删除撤销 u 反撤销 ctrl + r颜色开关（语法高亮） :syntax off 关闭 :syntax on 开启 手动建立配置文件vim ~/.vimrc 可以写 set nu 让每个文件都显示行号查找功能vim install.log /i686 N 向下 n 向上 查找i686 /root 查找root 替换功能vim install.log:%s/要替换内容/替换后内容/g 全文替换:1,20s/要替换内容/替换后内容/g 范围替换注释 # :21,30s/^/#/g 添加注释 :25,30s/^#//g 取消注释:60,70s/^/\\/\\//g 添加注释 :65,70s/^\\/\\///g 取消注释 软件包安装12345678910一 软件包分类源码包: 优点： 特点 开源 自由定制 缺点： 编译时间长，一旦报错，很难解决二进制包:rpm包 优点：安装速度快 简易 缺点：自定义性差 依赖性 a----&gt;b----&gt;c 树形依赖 a---b----c---a 环形依赖 库文件依赖 www.rpmfind.net rpm手动安装1234567891011121314151617181920手动RPM命令安装 1 包命名 包名-版本号-发布次数-适合linux系统-硬件平台.rpm 2 安装 rpm -ivh 包名（绝对路径） -i 安装 -v 显示详细信息 -h 显示进度 rpm -Uvh 包名 -U 升级 3 卸载 rpm -e 软件名 4 查询 rpm -q 软件名 查询包是否安装 rpm -qa | grep httpd 显示所有安装包 rpm -qi 软件名 查询包的信息 -p 未安装包 rpm -qip 包名 查询没有安装包的信息 -i information rpm -ql 软件名 查询包中文件的安装位置 rpm -qlp 包名 查询没有安装的包，打算安装位置 -l list rpm -qf 系统文件名 查询系统文件属于哪个包 yum安装1234567891011121314yum -y install 软件名 安装 -y 自动回答yesyum -y remove 软件名 删除yum -y update 软件名 升级yum list 查询所有可以安装的包光盘作为yum源： 1 cd /etc/yum.repos.d/ mv CentOS-Base.repo CentOS-Base.repo.bak 2 mount /dev/sr0 /mnt/cdrom 3 vim /etc/yum.repos.d/CentOS-Media.repo baseurl=file:///mnt/cdrom/ 指定yum源位置 enabled=1 yum源文件生效 gpgcheck=0 rpm验证不生效yum -y install gcc (gcc是c语言编译器，不装gcc，源码包不能安装) 源码包安装(apache)1234567891011121314151617181920212223242526！！！ 必须先安装gcc !apache解析php的效率特别高1 远程传输工具传输apache到linux。 httpd-2.2.29.tar.gz2 安装 1）解压 2） cd 解压目录 3） 查看安装文档 INSTALL README 4）编译前准备 ./configure --prefix=/usr/local/apache2 功能： 1 检测系统环境，生成Makefile 2 定义软件选项 5)编译 make 6）编译安装 make install 报错判断： 第一：安装过程是否停止 第二：注意error warning no 等错误报警3 启动 /usr/local/apache2/bin/apachectl start /usr/local/apache2/bin/apachectl stop 4 删除 直接删除安装目录 用户和用户组管理用户管理命令12345678910111213141516171819202122232425262728一 用户管理命令 用户信息文件： /etc/passwd 超级用户 uid 0 普通不需要登录， uid 500 开始 人为用户（系统服务使用） 影子文件： /etc/shadow 组信息文件： /etc/group 1 添加用户 useradd 用户名 useradd 选项 用户名useradd -g python f1 添加f1 同时修改初始组为pythonuseradd -G python f2 添加f2 同时添加f2为python组的附加组员useradd -c &quot;pyer&quot; f3 添加f3用户 同时注释useradd -d /home/four f4 添加用户f4同时修改家目录名useradd -s /bin/nologin f5 添加用户f5同时禁止登录 2 设定密码 passwd 用户名 passwd 改变当前用户密码 passwd root 改变root密码 3 删除用户 userdel -r 用户名 -r 连带家目录一起删除 4 添加组 groupadd 组名 5 删除组 groupdel 组名 6 把已经存在的用户加入组 gpasswd -a 用户名 组名 用户加入组 gpasswd -d 用户名 组名 把用户从组中删除 用户相关命令（id和切换）12id 用户名 查看用户相关ID号 ，显示用户的UID，初始组和附加组su - 用户名 切换用户身份 ACL权限1234567891011121314151617181920212223241.给特殊身份的人设置权限 getfacl 文件名 查看文件的acl权限 setfacl -m u:用户名:权限 文件名 设置用户的ACL权限 ls -l 查看有没有 + getfacl test1.py setfacl -m g:组名:权限 文件名 设置组的ACL权限 getfacl 文件名 查看权限 setfacl -x u:f2 test1.py 删除f2用户ACL权限 setfacl -b 文件名 删除所有ACL权限2.对目录设置ACL权限 1）对目录本身设置ACL权限 setfacl -m u:f2:rwx 目录名 2）对目录和目录内文件设置ACL权限 setfacl -m u:f2:rwx -R 目录名 递归设置 3）对未来建立的文件设置ACL权限 setfacl -m d:u:f2:rwx -R 目录名 -R 递归 ！！！ 如果给目录赋予ACL权限，2和3 命令都要输入 ！！！ 输出重定向123ls &gt; name.listls -l &gt; name.list 覆盖 ls &gt;&gt; name.list 追加 进程和服务管理1234进程管理三个主要任务： 判断服务器健康状态 查看所有正在运行的进程 强制终止进程 进程查看系统运行状况12345678910111213141516171819202122232425262728293031323334351 ps aux 查看当前系统所有运行的进程 -a 显示前台所有进程 -u 显示用户名 -x 显示后台进程 user： 用户名 pid： 进程id。PID init 系统启动的第一个进程 %CPU cpu占用百分比 %MEM 内存占用百分比 VSZ 虚拟内存占用量 KB RSS 固定内存占有量 tty 登录终端 本地终端 远程终端 stat 状态 S：睡眠 D：不可唤醒 R：运行 T：停止 start 进程触发时间 time 占用cpu时间 command 进程本身2 pstree 查看进程树3 top （动态查看） 第一行： 系统当前时间 系统持续时间 登录用户 1,5,15分钟之前的平均负载 第二行：进程总数 第三行：CPU占用率 %id 空闲百分比 第四行：内存使用： 总共 使用 空闲 缓存 第五行：swap使用 操作命令 M 内存排序 P CPU排序 q 退出4 w 查看系统运行情况和登录用户（静态查看）5 进程管理 终止进程 kill -9 PID 结束单个进程 -9 强制 killall -9 进程名 终止进程树 pkill -9 -t 终端号 把某个终端登录的用户踢出 例：pkill -9 -t tty1 把本地登录终端1登录用户踢出 服务管理123456789101112131415161718192021222324252627282930313233343536371 分类 1）系统默认安装的服务 安装二进制包的服务 2）源码包安装的服务（一）系统默认安装的服务 1 确定服务分类 chkconfig --list 查看服务的自启动状态 运行级别：0-6 0 关机 1 单用户模式 2 不完全多用户，不包含NFS服务 3 完全多用户 字符界面 4 未分配 5 图形界面 6 重启 init 0 关机 init 6 重启 runlevel 查询系统当前运行级别 vi /etc/inittab id:3:initdefault: 定义系统默认运行级别 2 系统默认安装的服务器管理 1）启动 /etc/rc.d/init.d/服务 start|stop|restart|status 例： /etc/rc.d/init.d/httpd start service 服务名 start|stop|restart|status 2)自启动 chkconfig --list 查看 chkconfig --level 245 服务名 on|off ！！！ 245 都可以 尽量不要写3，因为是系统服务 ！！！ 推荐用下面这种方法 vi /etc/rc.local----&gt;/etc/rc.d/rc.local /etc/rc.d/init.d/httpd start（二）源码包安装的服务 1）手动管理 绝对路径启动 不可以状态查询 /usr/local/apache2/bin/apachectl start 2)开机自启动 vi /etc/rc.local /usr/local/apache2/bin/apachectl start 计划任务1234567891011121314151617181920212223crontab -e 编辑定时任务 * * * * * 命令（命令一般是绝对路径） 第一个*：一小时中第几分钟 0-59 第二个：一天中第几个小时 0-23 第三个：一个月中第几天 1-31 第四个：一年第几个月 1-12 第五个：一周中星期几 0-6 例： 5 3 * 5,7,10 * 命令 5,7和10月每天三点5分执行 */10 * * * 1-3 命令 星期一到星期三每隔10分钟执行命令： 开启/关闭服务 service sshd start service sshd stop /usr/local/apache2/bin/apachectl restart 备份文件/目录 cp -r /root/bbs /tmpcrontab -l 查看系统定时任务crontab -r 删除所有定时任务注意事项：选项都不能为空，必须填入，不知道的值使用通配符*表示任何时间 每个时间字段都可以指定多个值，不连续的值用,间隔，连续的值用-间隔间隔固定时间执行书写为*/n格式 命令应该给出绝对路径 星期几何第几天不能同时出现 最小时间范围是分钟，最大时间范围是月 网络配置12345678910111213141516171819202122232425262728293031323334353637IP设置 ifconfig eth0 192.168.2.251 临时IP setup 设置永久IP 关闭防火墙service network restart (/etc/rc.d/init.d/network restart) 重启网络服务网卡信息文件 vim /etc/sysconfig/network-scripts/ifcfg-eth0 8 IPADDR=192.168.2.251 IP地址 9 NETMASK=255.255.255.0 掩码 10 GATEWAY=192.168.2.1 网关 BOOTPROTO=none 是否自动获取IP。none：不生效 static：手动 dhcp：动态获取IP DEVICE=eth0 网卡设备名 ONBOOT=yes 网卡开机启动 主机名修改 hostname 查看主机名 hostname lampbrother 临时修改主机名 vim /etc/sysconfig/network 永久修改主机名 HOSTNAME=lampbrother DNS设置 setup 设置DNS vim /etc/resolv.conf nameserver 114.114.114.114网络命令 vim /etc/services 查看网络端口 ifup eth0 开启网卡 ifdown eth0 关闭网卡 netstat -an 查看网络状态 netstat -tlun 查看查看tcp和udp协议监听端口 t tcp u udp l listen netstat -rn 查看网关（默认路由default） route del default gw 192.168.2.1 删除默认网关 route add default gw 192.168.2.1 添加默认网关 ping 192.168.2.250 ICMP协议 测试网络连通协议 ping -c 5 -s 10000 192.168.2.250 -s 发送数据大小 VSFTP服务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152一 文件服务器简介 ftp：在内网和公网使用。 服务器：windows，linux 客户端： windows，linux 服务器 用 s 表示 客户端用 c 表示1 ftp软件 linux： wu-ftp 早期，安全一般 proftp 增强ftp工具 vsftp 安全，强大 windows IIS windows下网页搭建服务，可以搭建ftp服务 Serv-U 专用ftp服务器2 原理 开启 21 命令传输端口 20 数据传输端口3 ftp的用户 1）ftp允许登录用户 就是系统用户 使用密码也是系统密码 上传位置：/home/家目录 2）匿名用户 anonymous 密码： 空 下载位置：/var/ftp/pub二 安装 mount /dev/sr0 /media cd /media/Packages/ yum -y install vsftpd 三 相关文件（了解） /etc/vsftpd/ftpusers 用户访问控制文件(不是必要步骤) /etc/vsftpd/vsftpd.conf 配置文件四 配置文件配置 vim /etc/vsftpd/vsftpd.conf 1主机相关配置 listen_port=21 监听端口 connect_from_port_20=YES 数据传输端口 ftpd_banner= 欢迎信息 2 匿名用户登录 在linux下识别为 ftp 用户 nonymous_enable=YES 允许匿名用户登录 3 本地用户 local_enable=YES 允许系统用户登录 write_enable=YES 允许上传 local_umask=022 默认上传权限 4 限制用户访问目录 chroot_local_user=YES 所有用户限制在家目录下 5 关闭防火墙和selinux 关闭防火墙 setup 关闭 selinux vim /etc/selinux/config SELINUX = disabled 6 重启生效 reboot 重启五 ftp客户端使用 1、使用windows窗口 ftp://用户名@IP 匿名用户可以不用用户名和密码 ftp://@ip 2、使用第三方工具登录 FileZilla 12345实验 限制用户目录权限vim /etc/vsftpd/vsftpd.conf96 chroot_local_user = YESservice vdftpd restart 重启服务FileZilla 登录 Samba服务器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374文件共享服务windows -&gt; linux （一）端口 smbd：为clinet提供资源访问 tcp 139 445 nmbd：提供netbios主机名解析 udp 137 138（二）安装 ISO mount /dev/sr0 /media yum -y install samba samba-common 主要配置文件 samba-client 客户端文件(三)修改配置文件 安全级别 share 无密码 user 添加samba用户设置samba密码 server 需要服务器做解析 实验1： 安全级别 share 共享目录 /movie 1）建立目录/movie mkdir /movie chmod 777 /movie 2）修改配置文件 vim /etc/samba/smb.conf 101 security = share 263 [movie] （这步是添加共享文件） 264 comment = dianying （说明） 265 path = /movie （路径） 266 browseable = yes （目录对用户可见） 267 guest ok = yes （访问） 268 writable = yes （可写） 3）启动服务 测试 关闭防火墙 关闭selinux vim /etc/selinux/config SELINUX = disabled service smb start service nmb start netstat -tlun （查看端口是否出现） 测试 \\\\192.168.2.251 网络驱动映射 进入共享文件，右键，网络驱动映射，就可以在我的电脑里查看信息 实验2：安全级别 user 共享 /pub 所有用户能访问上传 /soft 只有aa能访问上传1）建立目录 mkdir /pub mkdir /soft chmod 777 /pub chmod 700 /soft useradd aa passwd aa chown aa /soft2）修改配置文件 vim /etc/samba/smb.conf 101 security = user 263 [pub] 264 comment = public 265 path = /pub 266 browseable = yes 267 writable = yes 268 269 [soft] 270 comment = software 271 path = /soft 272 browseable = yes 273 writable = yes3）添加samba用户 smbpasswd -a aa smbpasswd -a f1 pdbedit -L 查看samba用户4）重启服务 测试 service smb restart service nmb restart测试 f1 登录 windows 界面登录 CMD net use * /del 删除连接缓存 aa 登录 SSH安全登录（必会）12345678910111213141516171819202122232425联机加密工具 非对称钥匙对加密默认（不用改）： 安装 openssh 开机自启 service sshd restart配置文件 vim /etc/ssh/sshd.config远程连接 ssh root@192.168.2.251 网络复制 scp scp root@192.168.2.140:/root/httpd-2.2.29.tar.gz /root 下载文件 scp hello.list root@192.168.2.140:/root/ 上传文件 scp -r root@192.168.2.140:/etc/ /root/ 下载目录 scp -r /etc root@192.168.2.140:/root/ 上传目录 SSH密钥登录 ssh-keygen -t rsa -P &apos;&apos; (必须要写) -P 表示密码 cd .ssh 进入自动生成的隐藏目录 cp id_rsa.pub authorized_keys 必须要写（文件49行要求） chmod 600 authorized_keys客户端: 下载私钥 登录测试 设置 /etc/ssh/sshd_config 禁止使用密码登录（慎用！！） 66 PasswordAuthentication no 重启sshd服务 service sshd restart lamp环境搭建123456789101112131配置yum源mount /dev/sr0 /media vim /etc/yum.repos.d/CentOS-Media.repo [c6-media] name=CentOS-$releasever - Mediabaseurl=file:///media/ * 修改为光盘挂载点gpgcheck=0enabled=1 * 改为1意为启用gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-62）剪切/etc/yum.repos.d/CentOS-Base.repo mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak3）依次安装gcc、gcc-c++ yum -y install gcc gcc-c++ 1234567关闭防火墙 和 selinuxsetup 或iptables -Fiptables -Xiptables -Zvim /etc/selinux/config SELINUX=disabled 123456789101112复制源码包 解压缩mv lamp /lampvim tar.sh cd /lamp /bin/ls *.tar.gz &gt; ls.list for TAR in `cat ls.list` do /bin/tar -zxf $TAR done /bin/rm ls.list chmod 777 tar.sh ./tar.sh 查看磁盘空间（产看安装软件有没有足够的空间） 安装辅助软件包123456789安装libxml2yum -y install python-devel 必须安装 cd /lamp/libxml2-2.9.1 ./configure --prefix=/usr/local/libxml2/ make make install yum install -y libxml2-devel 如果报错，安装此包后再尝试安装 12345安装libmcryptcd /lamp/libmcrypt-2.5.8 ./configure --prefix=/usr/local/libmcrypt/ make make install 12345安装libltdlcd /lamp/libmcrypt-2.5.8/libltdl ./configure --enable-ltdl-install make make install 12345安装mhashcd /lamp/mhash-0.9.9.9./configure makemake install 123456安装mcryptcd /lamp/mcrypt-2.6.8LD_LIBRARY_PATH=/usr/local/libmcrypt/lib:/usr/local/lib \\./configure --with-libmcrypt-prefix=/usr/local/libmcryptmakemake install 12345安装zlibcd /lamp/zlib-1.2.3 ./configure make make install 12345安装libpng cd /lamp/libpng-1.2.31 ./configure --prefix=/usr/local/libpng make make install 1234567891011安装jpeg6 mkdir /usr/local/jpeg6 mkdir /usr/local/jpeg6/bin mkdir /usr/local/jpeg6/lib mkdir /usr/local/jpeg6/include mkdir -p /usr/local/jpeg6/man/man1 ###目录必须手工建立 cd /lamp/jpeg-6b ./configure --prefix=/usr/local/jpeg6/ --enable-shared --enable-static make make install 12345安装freetype cd /lamp/freetype-2.3.5./configure --prefix=/usr/local/freetype/ make make install 安装APACHE123456789101112131415161718192021cp -r /lamp/apr-1.4.6 /lamp/httpd-2.4.7/srclib/aprcp -r /lamp/apr-util-1.4.1 /lamp/httpd-2.4.7/srclib/apr-utilcd /lamp/pcre-8.34 ./configure &amp;&amp; make &amp;&amp; make install cd /lamp/httpd-2.4.7 ./configure --prefix=/usr/local/apache2/ --sysconfdir=/usr/local/apache2/etc/ --with-included-apr --enable-so --enable-deflate=shared --enable-expires=shared --enable-rewrite=shared make make install 启动服务 /usr/local/apache2/bin/apachectl startps aux | grep httpdnetstat –tlun | grep :80测试 打开浏览器 192.168.2.251 有 IT works设置开机自启动vim /etc/rc.local/usr/local/apache2/bin/apachectl start 123456安装ncursesyum -y install ncurses-develcd /lamp/ncurses-5.9./configure --with-shared --without-debug --without-ada --enable-overwritemake make install 123#安装cmake和bisonyum -y install cmakeyum -y install bison MySQL服务12345678910111213141516171819202122232425262728293031323334353637383940414243444546安装服务yum -y install ncurses-develyum -y install cmakeyum -y install bison groupadd mysql useradd -g mysql mysql cd /lamp/mysql-5.5.48cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_UNIX_ADDR=/tmp/mysql.sock -DEXTRA_CHARSETS=all -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_MEMORY_STORAGE_ENGINE=1 -DWITH_READLINE=1 -DENABLED_LOCAL_INFILE=1 -DMYSQL_USER=mysql -DMYSQL_TCP_PORT=3306make &amp;&amp; make install----------------------------------------------------------配置服务cd /usr/local/mysql/chown -R mysql .chgrp -R mysql .#修改mysql目录权限/usr/local/mysql/scripts/mysql_install_db --user=mysql#创建数据库授权表，初始化数据库chown -R root .chown -R mysql data#修改mysql目录权限cp support-files/my-medium.cnf /etc/my.cnf#复制mysql配置文件二次授权/usr/local/mysql/scripts/mysql_install_db --user=mysql-------------------------------------------------启动MySQL服务：1.用原本源代码的方式去使用和启动mysql/usr/local/mysql/bin/mysqld_safe --user=mysql &amp;2.重启以后还要生效:vim /etc/rc.local/usr/local/mysql/bin/mysqld_safe --user=mysql &amp;3.设定mysql密码/usr/local/mysql/bin/mysqladmin -uroot password 123456 清空历史命令 history -c /usr/local/mysql/bin/mysql -u root -p mysql&gt; \\s 查看配置 mysql&gt; quit 退出 安装PHP12345678910111213141516171819202122232425yum -y install &quot;libtool*&quot;cd /lamp/php-7.0.7./configure --prefix=/usr/local/php/ --with-config-file-path=/usr/local/php/etc/ --with-apxs2=/usr/local/apache2/bin/apxs --with-libxml-dir=/usr/local/libxml2/ --with-jpeg-dir=/usr/local/jpeg6/ --with-png-dir=/usr/local/libpng/ --with-freetype-dir=/usr/local/freetype/ --with-mcrypt=/usr/local/libmcrypt/ --with-mysqli=/usr/local/mysql/bin/mysql_config --enable-soap --enable-mbstring=all --enable-sockets --with-pdo-mysql=/usr/local/mysql --with-gd --without-pearmake &amp;&amp; make install-------------------------------------------------------生成php.inimkdir /usr/local/php/etc/cp /lamp/php-7.0.7/php.ini-production /usr/local/php/etc/php.ini vim /usr/local/apache2/etc/httpd.conf AddType application/x-httpd-php .php .phtml AddType application/x-httpd-php-source .phps 重启Apache服务：/usr/local/apache2/bin/apachectl stop /usr/local/apache2/bin/apachectl start vim /usr/local/apache2/htdocs/test.php &lt;?php phpinfo(); ?&gt; 测试 浏览器 192.168.2.43/test.php 123456789101112添加环境变量vim /etc/profileexport PATH=&quot;/usr/local/php/bin:$PATH&quot;export PATH=&quot;/usr/local/mysql/bin:$PATH&quot;export PATH=&quot;/usr/local/apache2/bin:$PATH&quot;source /etc/profilephp -vmysql -u root -papachectl -v 收尾12345678910111213141516安装opensslyum -y install openssl-devel 必须安装cd /lamp/php-7.0.7/ext/opensslmv config0.m4 config.m4 否则报错：找不到config.m4/usr/local/php/bin/phpize ./configure --with-openssl --with-php-config=/usr/local/php/bin/php-config makemake installvim /usr/local/php/etc/php.ini722 extension_dir = &quot;/usr/local/php/lib/php/extensions/no-debug-zts-20151012/&quot;#打开注释，并修改extension=&quot;openssl.so&quot;;apachectl stopapachectl start 1234567891011安装phpMyAdmincp -r /lamp/phpMyAdmin-4.1.4-all-languages /usr/local/apache2/htdocs/phpmyadmincd /usr/local/apache2/htdocs/phpmyadmincp config.sample.inc.php config.inc.phpvim config.inc.php//$cfg[&apos;Servers&apos;][$i][&apos;auth_type&apos;] = &apos;cookie&apos;;$cfg[&apos;Servers&apos;][$i][&apos;auth_type&apos;] = &apos;http&apos;;测试 浏览器 192.168.2.43/phpmyadmin/index.phproot123456 安装memcache服务1234567891011121314151617181920211. Linux下安装操作： 1.1 #安装memcache扩展模块 unzip pecl-memcache-php7.zip cd pecl-memcache-php7 /usr/local/php/bin/phpize ./configure --with-php-config=/usr/local/php/bin/php-config make &amp;&amp; make install 修改/usr/local/php/etc/php.ini extension_dir = &quot;/usr/local/php/lib/php/extensions/no-debug-zts-20151012/&quot; extension=&quot;memcache.so&quot;; #重启apache，通过浏览器 在phpinfo中可以找到这个模块 1.2 #安装缓存服务 memcached-1.4.4-3.el6.i686.rpm mount /dev/sr0 /mnt/cdrom/ 挂载ISO镜像文件 yum -y install memcached useradd memcache 添加memcache用户 memcached -d -m 128 -l 127.0.0.1 -p 11211 -u memcache 启动服务 chkconfig memcached on 设置开机自启动 Apache服务器配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180一 简介 1 www：world wide web http 协议： 超文本传输协议 HTML语言： 超文本标识语言 2 URL：统一资源定位 协议+域名：端口+网页文件名 http://www.sina.com.cn:80/admin/index.html二 安装 1、lamp源码安装 2、二进制包安装 yum安装 httpd mysql mysql-server php php-devel php-mysql三 相关文件 apache配置文件 源码包安装：/usr/lcoal/apache2/etc/httpd.conf /usr/local/apache2/etc/extra/*.conf 二进制包安装：/etc/httpd/conf/httpd.conf 默认网页保存位置： 源码包：/usr/local/apache2/htdocs/ 二进制包安装：/var/www/html/ 日志保存位置 源码包：/usr/local/apache2/logs/ 二进制包： /var/log/httpd/ 二进制包默认使用日志处理程序 /var下都会轮替 源码包才 需要设置日志处理： 1日志切割 apache自带日志里面自带日志切割 2日志轮替 linux自带日志管理logrorate.conf 加入/usr/local/apache2/logs/access_log&#123; daily rotate 30 &#125; logrotate -f /etc/logrotate.conf 所有日志都要进行日i www! he htdocs bu yiyang! 志轮替 四 配置文件vim /root/.bashrc alias sta=’/usr/local/apache2/bin/apachectl start’ alias sto=’/usr/local/apache2/bin/apachectl stop’source /root/.bashrc 注意：apache配置文件严格区分大小写 1 针对主机环境的基本配置 31 ServerRoot apache主目录 52 Listen 监听端口 LoadModule 加载的相关模块 User Group 用户和组 ServerAdmin 管理员邮箱 ServerName 服务器名（没有域名解析时，使用临时解析） ErrorLog &quot;logs/error_log 错误日志 CustomLog &quot;logs/access_log&quot; common 正确访问日志 DirectoryIndex index.html index.php 默认网页文件名,优先级顺序 Include etc/extra/httpd-vhosts.conf 子配置文件中内容也会加载生效 2 主页目录及权限 DocumentRoot &quot;/usr/local/apache2//htdocs&quot; 主页目录 &lt;Directory &quot;/usr/local/apache2//htdocs&quot;&gt; #Directory关键字定义目录权限 Options Indexes FollowSymLinks #options None：没有任何额外权限 All： 所有权限 Indexes：浏览权限（当此目录下没有默认网页文件时，显示目录内容） FollowSymLinks：准许软连接到其他目录 AllowOverride None #定义是否允许目录下.htaccess文件中的权限生效 None：.htaccess中权限不生效 All：文件中所有权限都生效 AuthConfig：文件中，只有网页认证的权限生效。 Require all granted 访问控制列表403错误 404错误 网页找不见 3 目录别名 扩展网站目录，增加服务器 子配置文件名 etc/extra/httpd-autoindex.confAlias /www/ &quot;/usr/local/apache2//www/&quot; &lt;Directory &quot;/usr/local/apache2//www&quot;&gt; Options Indexes MultiViews AllowOverride None Require all granted &lt;/Directory&gt; mkdir /usr/local/apache2/www/浏览器测试 http://192.168.1.253/www/4 虚拟主机 1）分类 基于IP的虚拟主机: 一台服务器，多个IP，搭建多个网站 基于端口的虚拟主机：一台服务器，一个ip，搭建多个网站，每个网络使用不同端口访问 基于名字的虚拟主机： 一台服务器，一个ip，搭建多个网站，每个网站使用不同域名访问 2）步骤： ① 解析试验域名 www.sina.com www.sohu.comC:\\WINDOWS\\system32\\drivers\\etc\\hosts ② 规划网站主目录 /share/sina--------------www.sina.com /share/sohu ------------ www.sohu.com ③ 修改配置文件 vim /usr/local/apache2/etc/httpd.conf Include etc//extra/httpd-vhosts.conf #打开虚拟主机配置文件vim /usr/local/apache2/etc/extra/httpd-vhosts.conf&lt;Directory &quot;/share/sina&quot;&gt; Options Indexes AllowOverride NoneRequire all granted &lt;/Directory&gt;&lt;Directory &quot;/share/sohu&quot;&gt; Options Indexes AllowOverride None Require all granted &lt;/Directory&gt;&lt;VirtualHost 192.168.150.253&gt;#注意，只能写ip ServerAdmin webmaster@sina.com #管理员邮箱 DocumentRoot &quot;/share/sina&quot; #网站主目录 ServerName www.sina.com #完整域名 ErrorLog &quot;logs/sina-error_log&quot; #错误日志 CustomLog &quot;logs/sina-access_log&quot; common #访问日志&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.150.253&gt; ServerAdmin webmaster@sohu.com DocumentRoot &quot;/share/sohu&quot; ServerName www.sohu.com ErrorLog &quot;logs/sohu.com-error_log&quot; CustomLog &quot;logs/sohu.com-access_log&quot; common&lt;/VirtualHost&gt;5 rewrite 重写功能 在URL中输入一个地址，会自动跳转为另一个 1）域名跳转 www.sina.com ------&gt; www.sohu.com 开启虚拟主机，并正常访问 [root@localhost ~]# vim /usr/local/apache2/etc/httpd.confLoadModule rewrite_module modules/mod_rewrite.so#打开重写模块，记得重启apache 修改配置文件，使sina目录的.htaccess文件生效[root@localhost etc]# vim /usr/local/apache2/etc/extra/httpd-vhosts.conf&lt;Directory &quot;/share/sina&quot;&gt; Options Indexes FollowSymLinks AllowOverride All Require all granted &lt;/Directory&gt;vim /share/sina/.htaccessRewriteEngine on #开启rewrite功能RewriteCond %&#123;HTTP_HOST&#125; www.sina.com 把以www.sina.com 开头的内容赋值给HTTP_HOST变量RewriteRule .* http://www.sohu.com .* 输入任何地址，都跳转到http://www.sohu.com2)网页文件跳转 vim /share/sina/.htaccessRewriteEngine onRewriteRule index(\\d+).html index.php?id=$1 #输入index(数值).html时，跳转到index.php文件，同时把数值当成变量传入index.php Apache执行停止改名12345678910111213命令别名 aliasvim /root/.bashrcalias sto=&apos;/usr/local/apache2/bin/apachectl stop&apos;alias sta=&apos;/usr/local/apache2/bin/apachectl start&apos;source /root/.bashrcstosta 目录别名 扩容 增加服务目录12345678910111213141516171819202122232425261）建立扩容目录mkdir /usr/local/apache2/www/2）修改主配置文件 vim /usr/local/apache2/etc/httpd.conf453 Include etc//extra/httpd-autoindex.conf3）修改子配置文件vim /usr/local/apache2/etc/extra/httpd-autoindex.conf 29 Alias /www/ &quot;/usr/local/apache2/www/&quot; 30 31 &lt;Directory &quot;/usr/local/apache2/www/&quot;&gt; 32 Options Indexes 33 AllowOverride None 34 Require all granted 35 &lt;/Directory&gt;4）重启服务 测试stosta测试 192.168.2.251/www/ 虚拟主机1234567891011121314151617181920212223242526272829303132333435363738394041424344454647步骤：1）域名解析 文件解析C:\\Windows\\System32\\drivers\\etc\\hosts 添加下面两个网址192.168.2.251 www.sina.com192.168.2.251 www.sohu.com2）网站目录规划 (想显示内容要在里面创建index.html ，里面写入中文会乱码，英文正常显示)mkdir -p /share/sina/mkdir /share/sohu/3）修改主配置文件vim /usr/local/apache2/etc/httpd.conf465 Include etc//extra/httpd-vhosts.conf4）修改子配置文件vim /usr/local/apache2/etc/extra/httpd-vhosts.conf 23 &lt;Directory &quot;/share/sina/&quot;&gt; 24 Options Indexes 25 AllowOverride None 26 Require all granted 27 &lt;/Directory&gt; 28 29 &lt;Directory &quot;/share/sohu/&quot;&gt; 30 Options Indexes 31 AllowOverride None 32 Require all granted 33 &lt;/Directory&gt; 35 &lt;VirtualHost 192.168.2.251&gt; 36 ServerAdmin webmaster@sina.com 37 DocumentRoot &quot;/share/sina/&quot; 38 ServerName www.sina.com 39 ErrorLog &quot;logs/sina-error_log&quot; 40 CustomLog &quot;logs/sina-access_log&quot; common 41 &lt;/VirtualHost&gt; 42 43 &lt;VirtualHost 192.168.2.251&gt; 44 ServerAdmin webmaster@sohu.com 45 DocumentRoot &quot;/share/sohu/&quot; 46 ServerName www.sohu.com 47 ErrorLog &quot;logs/sohu-error_log&quot; 48 CustomLog &quot;logs/sohu-access_log&quot; common 49 &lt;/VirtualHost&gt;5）重启服务 测试stosta测试 www.sina.com www.sohu.com 重定向12345678910111213141516171819202122232425rewrite 重写/重定向www.sina.com -&gt; www.sohu.com 1）修改主配置文件vim /usr/local/apache2/etc/httpd.conf147 LoadModule rewrite_module modules/mod_rewrite.so2）修改子配置文件vim /usr/local/apache2/etc/extra/httpd-vhosts.conf 23 &lt;Directory &quot;/share/sina/&quot;&gt; 24 Options Indexes FollowSymLinks 25 AllowOverride All 26 Require all granted 27 &lt;/Directory&gt;3）建立权限文件.htaccessvim /share/sina/.htaccess 1 RewriteEngine on 2 RewriteCond %&#123;HTTP_HOST&#125; www.sina.com 3 RewriteRule .* http://www.sohu.com .* 代表任意所有，要从上往下看，这里.*代表sina.com4） 重启服务 测试 sto sta 测试 www.sina.com -&gt; www.sohu.com 网页跳转123456789101112131415161）修改权限文件vim /share/sina/.htaccess 1 RewriteEngine on 2 RewriteRule index(\\d+).html index.php?id=$12）建立index.php文件vim /share/sina/index.php 1 &lt;?php 2 echo &quot;hello rewrite!&quot;; 3 ?&gt;3）重启服务测试stosta测试 www.sina.com/index5.html LNMP环境搭建-Nginx服务LNMP环境搭建123456789101112131415161718192021222324252627282930313233343536准备工作： 恢复初始化安装 设置IP 关闭防火墙 配置光盘yum源安装步骤：1.解压缩 tar -zxvf lnmp1.2-full.tar.gz ls2.进入解压目录 cd lnmp1.2-full3.安装 ./install.sh lnmp环境目录和文件： Nginx 目录: /usr/local/nginx/ MySQL 目录 : /usr/local/mysql/ MySQL数据库所在目录：/usr/local/mysql/var/ PHP目录 : /usr/local/php/ PHPMyAdmin目录 : /home/wwwroot/default/phpmyadmin/ 默认网站目录 : /home/wwwroot/default/ Nginx日志目录：/home/wwwlogs/ Nginx主配置文件：/usr/local/nginx/conf/nginx.conf MySQL配置文件：/etc/my.cnf PHP配置文件：/usr/local/php/etc/php.ini管理命令lnmp start | restart | stop | statuslnmp nginx start | stop | restart | status配置文件 ulimit -a ulimit -n 51200 检查nginx配置文件语句错误 /usr/local/nginx/sbin/nginx -t 平滑重启nginx进程 pkill -HUP nginx 虚拟主机12345678910111213141516171819202122232425262728293031323334353637383940411）域名解析 文件解析C:\\Windows\\System32\\drivers\\etc\\hosts 192.168.2.251 www.sina.com 192.168.2.251 www.sohu.com2）网站目录规划mkdir /home/wwwroot/sina/mkdir /home/wwwroot/sohu/vim /home/wwwroot/sina/index.htmlvim /home/wwwroot/sohu/index.html3）修改配置文件vim /usr/local/nginx/conf/nginx.conf 66 listen 80; 4）建立虚拟主机文件vim /usr/local/nginx/conf/vhost/v.conf 1 server &#123; 2 listen 80; 3 server_name www.sina.com; 4 index index.html index.htm index.php; 5 root /home/wwwroot/sina/; 6 7 include enable-php.conf; 8 &#125; 9 server &#123; 10 listen 80; 11 server_name www.sohu.com; 12 index index.html index.htm index.php; 13 root /home/wwwroot/sohu/; 14 15 include enable-php.conf; 16 &#125;5） 重启服务 测试pkill -HUP nginx 测试 www.sina.com www.sohu.com 列表页显示12345vim /usr/local/nginx/conf/vhost/v.conf 加入 autoindex on; 开启列表页显示功能 (两个里面都加)cd /home/wwwroot/sina mv index.html a.html（需要改名） 状态监控模块添加123456789101112131415vim /usr/local/nginx/conf/vhost/v.conf 9 server &#123; 10 listen 80; 11 server_name www.sohu.com; 12 index index.html index.htm index.php; 13 root /home/wwwroot/sohu/; 14 location /nginx_status&#123; stub_status on; access_log off; &#125; 15 include enable-php.conf; 16 &#125;测试 www.sohu.com/nginx_status rewrite重写、重定向1234567891011121314151617域名跳转 www.sina.com -&gt; www.sohu.comvim /usr/loca/nginx/conf/vhost/v.conf server &#123; listen 80; server_name www.sina.com; index index.html index.htm index.php; root /home/wwwroot/sina; if ($http_host = www.sina.com) &#123; rewrite (.*) http://www.sohu.com permanent; &#125; &#125;重启服务 测试pkill -HUP nginx测试 www.sina.com -&gt; www.sohu.com 网页文件跳转12345678910111213141516171819201）修改配置文件vim /usr/local/nginx/conf/vhost/v.conf 1 server &#123; 2 listen 80; 3 server_name www.sina.com; 4 index index.html index.htm index.php; 5 root /home/wwwroot/sina/; 6 rewrite index(\\d+).html /index.php?id=$1 last; 7 include enable-php.conf; 8 &#125; 2）建立 php文件vim /home/wwwroot/sina/index.php 1 &lt;?php 2 echo &quot;hi Nginx rewrite&quot;; 3 ?&gt;3）重启服务 测试pkill -HUP nginx测试 www.sina.com/index5.html 代理负载均衡（反向代理）1234567891011121314151617181920212223242526272829303132333435363738准备工作： S 192.168.2.251 Nginx 负载均衡 S1 192.168.2.102 Nginx 网站解析 S2 192.168.2.191 Nginx 网站解析实验步骤：1）修改S 192.168.2.251 配置文件vim /usr/local/nginx/conf/nginx.conf 63 upstream myweb1 &#123; 64 server 192.168.2.102:80; 65 server 192.168.2.191:80; 66 &#125; 67 server &#123; 68 listen 80; 69 server_name www.sohu.com; 70 location / &#123; 71 proxy_pass http://myweb1; 72 proxy_next_upstream http_500 http_502 http_503 error timeout invalid_header; 73 proxy_set_header Host $host; 74 proxy_set_header X-Forwarded-For $remote_addr; 75 &#125; 76 &#125; 77 &#125;2）修改S1 192.168.2.102 关闭虚拟主机关闭虚拟主机： cd /usr/local/nginx/conf/ vim nginx.conf # include vhost/*.conf; 检测这个有没有注释或者删了就行 cd /home/wwwroot/default/ vim index.htmlS1111111111113）修改S1 192.168.2.191 关闭虚拟主机cd /home/wwwroot/default/ vim index.htmlS22222222224） 重启S 服务 测试pkill -HUP nginx 测试 www.sohu.com 刷新 S1 S2 Shell 编程shell的作用和历史 12Shell的作用 -- 命令解释器，“翻译官”vim /etc/shells shell文件(里面有好多不同的shell) shell 常用功能1234567891011121314151617181920212223242526272829303132333435363738394041自动补全 Tab命令历史 history history -w 同步历史命令/写入隐藏文件 history -c 清除历史记录 !n：执行历史记录中的第n条命令!str：执行历史记录中以“str”开头的命令vim /etc/profile 48 HISTSIZE=1000 为使用频率较高的复杂命令行设置简短的调用名称存放位置：~/.bashrcvim /root/.bashrc查看命令别名格式：alias [别名]设置命令别名执行：alias 别名=&apos;实际执行的命令&apos;alias ls=&apos;ls -lha&apos; 设置之后需要执行此文件，否则不生效ls 取消已设置的命令别名 格式：unalias 别名unalias ls输入重定向man wcwc &lt; install.log输出重定向ls &gt; bak.listls -l &gt;&gt; bak.list标准错误输出lss 2&gt; bak.listlss 2&gt;&gt; bak.list重定向标准输出和标准错误ls &amp;&gt; /dev/null 黑洞设备文件（空设备文件）lss &gt;&gt; a.txt 2&gt;&amp;1 重定向标准错误2&gt;&amp;1 算是一个判断条件，如果前面正确，则无用，如果错误，就会把错误信息也输入到文件里 12管道符 | netstat -an | grep ESTABLISHED | wc -l 统计与服务器的连接数量 Shell变量的应用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118Shell变量的种类用户自定义变量：由用户自己定义、修改和使用环境变量：由系统维护，用于设置用户的Shell工作环境，只有极少数的变量用户可以修改预定义变量：Bash预定义的特殊变量，不能直接修改位置变量：通过命令行给程序传递执行参数变量的赋值与引用定义新的变量变量名要以英文字母或下划线开头，区分大小写格式：变量名=变量值查看变量的值格式：echo $变量名查看所有变量：set清除变量unset 变量名定义变量 Var=lampecho $&#123;var&#125;3.0&quot;&quot; &apos;&apos; `` 单引号 双引号 反引号 对比 DAY=xingqier echo $DAY 显示xingqier echo &quot;$DAY&quot; 显示xingqier echo &apos;$DAY&apos; 显示$DAY echo `$DAY` 执行 xingqier （必须是命令。否则报错） unset DAY DAY=ls echo `$DAY` 执行ls环境变量赋值设置变量的作用范围格式：export 变量名... export 变量名=变量值 [...变量名n=变量值n]查看环境变量 env 或 export清除用户定义的变量格式：unset 变量名 命令执行时查找顺序 1、以相对/绝对路径执行 2、由alias找到的执行 3、bash内部命令执行 4、按$PATH路径执行 环境变量PS1 echo $PS1 \\d 日期 \\t 时间（24） \\T时间（12） \\H 完整主机名 \\h 简写主机名 \\u 用户名 \\v bash版本 \\w 完整目录 \\W 最后一个目录 \\# 执行了第几个命令 \\$ 提示符 PS1=‘[\\u@\\h \\W \\t #\\#]\\$’ 常见的环境变量： $USER 、$LOGNAME $UID 、 $SHELL 、$HOME $PWD、 $PATH $PS1、$PS2 查看环境变量[root@localhost ~]# echo $PATH/usr/kerberos/sbin:/usr/kerberos/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin 预定义变量 表示形式如下 $#：命令行中位置参数的个数 $*：所有位置参数的内容 $?：上一条命令执行后返回的状态，当返回状态值为0时表示执行正常，非0值表示执行异常或出错 $$：当前所在进程的进程号 $!：后台运行的最后一个进程号 $0：当前执行的进程/程序名 命令执行时查找顺序 1、以相对/绝对路径执行 2、由alias找到的执行 3、bash内部命令执行 4、按$PATH路径执行 [root@localhost ~]# bash [root@localhost ~]# echo $0 $$ bash 5887 [root@localhost ~]# exxit bash: exxit: command not found [root@localhost ~]# echo $? 127 [root@localhost ~]# exit exit [root@localhost ~]# echo $? 0 ； 命令顺序执行。 &amp;&amp; 前后命令的执行存在逻辑与关系，只有&amp;&amp;前面的命令执行成功后，它后面的命令才被执行。 || 前后命令的执行存在逻辑或关系，只有||前面的命令执行失败后，它后面的命令才被执行。 通配符与特殊符号 通配符 * 任意多个 ？ 任意一个 [] 括号内任一个 [^0-9]非数字 rm -rf * rm -rf ?.?? touch 1.txt 2.txt 3.txt rm -rf [1-9].* 特殊符号 \\ 转义符 &amp; 后台 ！ 非 12345678910111213141516171819204.数值变量的运算计算整数表达式的运算结果格式：expr 变量1 运算符 变量2 ...[运算符 变量n]expr的常用运算符加法运算：+减法运算： -乘法运算： \\*除法运算： /求模（取余）运算： % Bash程序并不适合进行强大的数学运算，例如小数或指数运算的，一般只能进行简单的整数运算对Shell变量进行数值运算时，更多的时候是用于脚本程序的过程控制，如控制程序的循环次数在expr命令的使用格式中，变量与运算符间是有空格的，可以同时使用多个运算符、多个变量由于星号“*”作为Bash环境中的通配符使用，因此乘法运算符需要使用“\\*”的特殊形式（转义字符）#!/bin/bashread -p &quot;please input num1:&quot; -t 30 test1read -p &quot;input num2:&quot; -t 30 test2declare -i sum=”$test1+$test2”echo “num1 + num2 = $sum” shell脚本的概念12345678910111213141516171819202122 Shell脚本 1.用途：完成特定的、较复杂的系统管理任务 2.格式：集中保存多条Linux命令，普通文本文件 3.执行方式：按照预设的顺序依次解释执行[root@localhost ~]# vi repboot.sh #!/bin/bash # To show usage of /boot directory and mode of kernel file. echo &quot;Useage of /boot: &quot; du -sh /boot echo &quot;The mode of kernel file:&quot; ls -lh /boot/vmlinuz-* [root@localhost ~]# chmod a+x repboot.sh 运行Shell脚本程序 1.直接执行具有“x”权限的脚本文件 例如：./repboot.sh 2.使用指定的解释器程序执行脚本内容 例如：bash repboot.sh 3.通过source命令（或 . ）读取脚本内容执行 例如：souce repboot.sh 或 . hello.sh shell脚本应用实例1234567891011121314示例1：每周五17:30清理FTP服务器的公共共享目录 检查 /var/ftp/pub/ 目录，将其中所有子目录及文件的详细列表、当时的时间信息追加保存到 /var/log/pubdir.log 日志文件中，然后清空该目录[root@localhost ~]# vi /opt/ftpclean.sh#!/bin/bashdate &gt;&gt; /var/log/pubdir.logls -lhR /var/ftp/pub &gt;&gt; /var/log/pubdir.logrm -rf /var/ftp/pub/*[root@localhost ~]# crontab -e30 17 * * 5 /opt/ftpclean.shchmod +x /opt/ftpclean.sh 12345678910111213141516171819示例2:每隔3天时间3：30对数据库目录做一次完整备份 统计 /usr/local/mysql/var 目录占用的空间大小、查看当前的日期，并记录到临时文件 /tmp/dbinfo.txt 中， 将 /tmp/dbinfo.txt 文件、/usr/local/mysql/var 目录进行压缩归档，备份到/opt/dbbak/目录中， 备份后的包文件名中要包含当天的日期信息， 最后删除临时文件/tmp/dbinfo.txt[root@localhost ~]# vi /opt/dbbak.sh#!/bin/bashDAY=`date +%Y%m%d`SIZE=`du -sh /usr/local/mysql/var`echo &quot;Date: $DAY&quot; &gt;&gt; /tmp/dbinfo.txtecho &quot;Data Size: $SIZE&quot; &gt;&gt; /tmp/dbinfo.txtmkdir /opt/dbbakcd /opt/dbbaktar -zcPf mysqlbak-$&#123;DAY&#125;.tar.gz /usr/local/mysql/var /tmp/dbinfo.txtrm -f /tmp/dbinfo.txt[root@localhost ~]# crontab -e30 3 */3 * * /opt/dbbak.shchmod +x /opt/dbbak.sh shell 显示写法12345678910111213从键盘输入内容为变量赋值格式： read [-p &quot;信息&quot;] 变量名结合不同的引号为变量赋值双引号 “ ” ：允许通过$符号引用其他变量值单引号 ‘ ’ ：禁止引用其他变量值，$视为普通字符反撇号 ` ` ：将命令执行的结果输出给变量下面就是一个简单计算器的运用写法： read -p &quot;input first num: &quot; var1 read -p &quot;input +-*/ : &quot; var read -p &quot;input second num: &quot; var2 v=`echo &quot; $var1 $var $var2 &quot;|bc` echo &quot;$var1 $var $var2 = $v&quot; Shell 正式编程正则表达式123456789101112131415161718192021222324252627282930313233343536371 ^#只匹配行首2 $#只匹配行尾3 *#匹配0个或者多个单字符4 []#只匹配[]内字符，可以是一个单字符，也可以是字符序列，可以使用*表示[]内字符序列范围，如用[1-5]代替[12345]5 \\#只用来屏蔽一个元字符的特殊含义6 .#只匹配任意单字符7 pattern\\&#123;n\\&#125;#匹配n次pattern8 pattern\\&#123;n,\\&#125;#匹配n次以上pattern9 pattern\\&#123;n,m\\&#125;#匹配n到m次pattern11 ^只允许在一行的开始匹配字符或单词^d 筛选出以d开头的文件属性12 ^ $#匹配空行13 ^.$#匹配包含一个字符的行14 kkk$#匹配以kkk结尾的所有字符15 \\*\\.pas#匹配以*.pas结尾的所有字符或文件16 a\\&#123;2\\&#125;b#a出现两次，aab 17 a\\&#123;4,\\&#125;b#a至少出现4次，aaaab,aaaaab ..18 a\\&#123;2,4\\&#125;#a出现次数范围2-4次19 [0-9]\\&#123;3\\&#125;\\.[0-9]\\&#123;3\\&#125;\\.[0-9]\\&#123;3\\&#125;\\.[0-9]\\&#123;3\\&#125;#匹配所有ip地址20 cal 显示日历 shell编程中常用的命令12345678910111213141516行提取命令grep 选项： -v -n -i grep &quot;[^a-z]oo&quot; aa (文件名) oo前不是小写字母的行匹配。 注意：和开头没有关系 grep “\\.$” aa 匹配以.结尾的行 grep &quot;^[^A-Za-z]&quot; aa 匹配不以字母开头的行 注意：所有字母不能这样写 A-z grep “^$” aa 匹配空白行 grep &quot;oo*&quot; aa 匹配最少一个o grep “g.*d” aa 匹配g开头，d结尾，中间任意字符 gd 123456789101112131415161718192021222324252627列提取命令awk &apos;条件 ｛动作｝&apos; last | awk &apos;&#123;printf $1 &quot;\\t&quot; $3 &quot;\\n&quot;&#125;&apos; 提取last显示结果的第一和第三列last | grep &quot;[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;&quot;|awk &apos;&#123;printf $1 &quot;\\t&quot; $3 &quot;\\n&quot;&#125;&apos;在last中提取包含ip的行，在行中提取第一和第三列awk内置变量 FS 指定分隔符more /etc/passwd | awk &apos;BEGIN &#123;FS=&quot;:&quot;&#125; &#123;printf $1 &quot;\\t&quot; $3 &quot;\\n&quot;&#125;&apos;读取passwd文件，以&quot;:&quot;为分隔符，截取第一和第三列BEGIN 在截取前使分隔符生效。如果没有BEGIN，那么第一行自定义的分隔符不生效1 last &gt; file#把last命令结果保存在file文件中2 awk ‘&#123;print $0 “\\n”&#125;&apos; file #查找出file文件中的每1列3 awk &apos;&#123;print $1&quot;\\t&quot;$7 “\\n”&#125;&apos; file#查找出file文件中的第1列和第7列cut cut -d “分隔符” -f 提取列 文件名more /etc/passwd | grep &quot;/bin/bash&quot; | cut -d &quot;:&quot; -f 1,3提取passwd文件中可以登录的用户的用户名和UID 12345678910111213输出命令echo -e “输出内容” -e 识别格式化打印内容 echo -e “1\\t2\\t3” 打印tab键 echo -e &quot;\\e[1;31m this is red text \\e[0m&quot; 输出红色字体 \\e[ 格式 1;31m 指定颜色 0m 恢复颜色（重置）30m=黑色，31m=红色，32m=绿色，33m=黄色，34m=蓝色，35m=洋红，36m=青色，37=白色 shell条件测试操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182条件测试操作test命令用途：测试特定的表达式是否成立，当条件成立时，命令执行后的返回值为0，否则为其他数值格式：test 条件表达式 [ 条件表达式 ]常见的测试类型测试文件状态字符串比较整数值比较逻辑测试测试文件状态格式：[ 操作符 文件或目录 ]常用的测试操作符-d：测试是否为目录（Directory）-e：测试目录或文件是否存在（Exist）-f：测试是否为文件（File）-r：测试当前用户是否有权限读取（Read）-w：测试当前用户是否有权限写入（Write）-x：测试当前用户是否可执行（Excute）该文件-L：测试是否为符号连接（Link）文件[root@localhost ~]# [ -d /etc/vsftpd ][root@localhost ~]# echo $?0[root@localhost ~]# [ -d /etc/hosts ][root@localhost ~]# echo $?1[root@localhost ~]# [ -e /media/cdrom ] &amp;&amp; echo &quot;YES&quot;YES [root@localhost ~]# [ -e /media/cdrom/Server ] &amp;&amp; echo &quot;YES”[root@localhost ~]#整数值比较格式：[ 整数1 操作符 整数2 ]常用的测试操作符-eq：等于（Equal）-ne：不等于（Not Equal）-gt：大于（Greater Than）-lt：小于（Lesser Than）-le：小于或等于（Lesser or Equal）-ge：大于或等于（Greater or Equal）[root@localhost ~]# who | wc -l5[root@localhost ~]# [ `who | wc -l` -le 10 ] &amp;&amp; echo &quot;YES&quot;YES [root@localhost ~]# df -hT | grep &quot;/boot&quot; | awk &apos;&#123;print $6&#125;&apos;18% [root@localhost ~]# BootUsage=`df -hT | grep &quot;/boot&quot; | awk &apos;&#123;print $6&#125;&apos; | cut -d &quot;%&quot; -f 1`[root@localhost ~]# echo $BootUsage18[root@localhost ~]# [ $BootUsage -gt 95 ] &amp;&amp; echo &quot;YES&quot; 字符串比较格式：[ 字符串1 == 字符串2 ] [ 字符串1 != 字符串2 ] [ -z 字符串 ]常用的测试操作符==：字符串内容相同 !! ==两边不能有空格！！！【】两边必须有空格！！！!=：字符串内容不同，! 号表示相反的意思-z：字符串内容为空[root@localhost ~]# read -p &quot;Location：&quot; FilePathLocation：/etc/inittab[root@localhost ~]# [ $FilePath == &quot;/etc/inittab&quot; ] &amp;&amp; echo &quot;YES&quot;YES [root@localhost ~]# [ $LANG != &quot;en.US&quot; ] &amp;&amp; echo $LANGzh_CN.UTF-8 123456789101112131415161718逻辑测试格式：[ 表达式1 ] 操作符 [ 表达式2 ] ... 常用的测试操作符-a或&amp;&amp;：逻辑与，“而且”的意思#前后两个表达式都成立时整个测试结果才为真，否则为假 -o或||：逻辑或，“或者”的意思#操作符两边至少一个为真时，结果为真，否则结果为假!：逻辑否#当指定的条件不成立时，返回结果为真[root@localhost ~]# echo $USERroot[root@localhost ~]# [ $USER != &quot;teacher&quot; ] &amp;&amp; echo &quot;Not teacher&quot;Not teacher[root@localhost ~]# [ $USER = &quot;teacher&quot; ] || echo &quot;Not teacher&quot;Not teacher if 条件语句(流程控制)1234567891011if条件语句 -- 单分支应用示例：如果/boot分区的空间使用超过80%，输出报警信息如果测试 / 目录的话 将 /boot 换成 /$ 就可以了 #!/bin/bashRATE=`df -hT | grep &quot;/boot&quot; | awk &apos;&#123;print $6&#125;&apos; | cut -d &quot;%&quot; -f1 `if [ $RATE -gt 80 ]then echo &quot;Warning,DISK is full!&quot;fi 123456789101112if条件语句 -- 双分支应用示例：判断mysqld是否在运行，若已运行则输出提示信息，否则重新启动mysqld服务#!/bin/bashTEST=`/usr/bin/pgrep mysqld `if [ “$TEST” != “” ] then echo &quot;mysqld service is running.&quot; else /etc/init.d/mysqld restartfi 1234567891011if条件语句 -- 多分支相当于if语句嵌套，针对多个条件执行不同操作if 条件测试命令1 ; then 命令序列1elif 条件测试命令2 ; then 命令序列2elif ...else 命令序列nfi for 循环语句1234567891011121314应用示例1：依次输出3条文字信息，包括一天中的“Morning”、“Noon”、“Evening”字串[root@localhost ~]# vi showday.sh#!/bin/bashfor TM in &quot;Morning&quot; &quot;Noon&quot; &quot;Evening&quot;do echo &quot;The $TM of the day.&quot;done [root@localhost ~]# sh showday.shThe Morning of the day.The Noon of the day.The Evening of the day 1234567891011121314应用示例2：对于使用“/bin/bash”作为登录Shell的系统用户，检查他们在“/opt”目录中拥有的子目录或文件数量，如果超过100个，则列出具体个数及对应的用户帐号 #!/bin/bashDIR=&quot;/opt&quot;LMT=100ValidUsers=`grep &quot;/bin/bash&quot; /etc/passwd | cut -d &quot;:&quot; -f 1`for UserName in $ValidUsersdo Num=`find $DIR -user $UserName | wc -l` if [ $Num -gt $LMT ] ; then echo &quot;$UserName have $Num files.&quot; fidone while 循环语句123456789101112131415161718192021222324252627重复测试指定的条件，只要条件成立则反复执行对应的命令操作应用示例1：批量添加20个系统用户帐号， 用户名依次为“stu1”、“stu2”、……、“stu20”这些用户的初始密码均设置为“123456” --stdin 表示转换成键盘输入expr 是shell计算器（bc）里的加法#!/bin/bashi=1while [ $i -le 20 ]do useradd stu$i echo &quot;123456&quot; | passwd --stdin stu$i &amp;&gt; /dev/null i=`expr $i + 1`done 应用示例2：批量删除上例中添加的20个系统用户帐号#!/bin/bashi=1while [ $i -le 20 ]do userdel -r stu$i i=`expr $i + 1`done case 多重分支语句12345678910111213141516171819202122232425262728293031323334353637根据变量的不同取值，分别执行不同的命令操作应用示例1：编写脚本文件 mydb.sh，用于控制系统服务mysqld当执行 ./mydb.sh start 时，启动mysqld服务当执行 ./mydb.sh stop 时，关闭mysqld服务如果输入其他脚本参数，则显示帮助信息#!/bin/bash case $1 in start) echo &quot;Start MySQL service.&quot; ;; stop) echo &quot;Stop MySQL service.&quot; ;; *) echo &quot;Usage：$0 start|stop&quot; ;;esac应用示例2：提示用户从键盘输入一个字符，判断该字符是否为字母、数字或者其它字符，并输出相应的提示信息 #!/bin/bashread -p &quot;Press some key, then press Return:“ KEYcase &quot;$KEY“ in [a-z]|[A-Z]) echo &quot;It&apos;s a letter.&quot; ;; [0-9]) echo &quot;It&apos;s a digit.&quot; ;; *) echo &quot;It&apos;s function keys、Spacebar or other keys. &quot;esac shell 函数应用1234567891011121314151617181920212223242526272829303132333435Shell函数概述在编写Shell脚本程序时，将一些需要重复使用的命令操作，定义为公共使用的语句块，即可称为函数合理使用Shell函数，可以使脚本内容更加简洁，增强程序的易读性，提高执行效率定义新的函数function 函数名 &#123; 命令序列&#125; 函数名() &#123; 命令序列&#125;调用已定义的函数函数名向函数内传递参数函数名 参数1 参数2 ...应用示例：在脚本中定义一个加法函数，用于计算2个整数的和调用该函数计算（12+34）、（56+789）的和#!/bin/bashadder() &#123; echo `expr $1 + $2`&#125;adder 12 34adder 56 789[root@localhost ~]# bash adderfun.sh46845 额外#传输文件的方法 yum -y install lrzsz rz #下载东西 wget 网址 ##监控工具 dstat和vmstat 编译安装： 工具下载地址：wget http://dstat.sourcearchive.com/downloads/0.7.2-2/dstat_0.7.2.orig.tar.gz yum安装： yum -y install dstat 写的比较详细的博客 http://blog.csdn.net/smooth00/article/details/78623728","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://127.0.0.1/blog/tags/linux/"}]},{"title":"爬虫笔记","slug":"爬虫笔记","date":"2019-05-06T04:36:15.000Z","updated":"2019-05-08T08:21:10.409Z","comments":true,"path":"2019/05/06/爬虫笔记/","link":"","permalink":"https://127.0.0.1/blog/2019/05/06/爬虫笔记/","excerpt":"","text":"e1.HTTP和HTTPSHTTP协议（HyperText Transfer Protocol，超文本传输协议）：是一种发布和接收 HTML页面的方法。 HTTPS（Hypertext Transfer Protocol over Secure Socket Layer）简单讲是HTTP的安全版，在HTTP下加入SSL层。 SSL（Secure Sockets Layer 安全套接层）主要用于Web的安全传输协议，在传输层对网络连接进行加密，保障在Internet上数据传输的安全。 · HTTP的端口号为80， · HTTPS的端口号为443 1.1.1 HTTP工作原理网络爬虫抓取过程可以理解为模拟浏览器操作的过程。 浏览器的主要功能是向服务器发出请求，在浏览器窗口中展示您选择的网络资源，HTTP是一套计算机通过网络进行通信的规则。 1.2 HTTP的请求与响应HTTP通信由两部分组成： 客户端请求消息 与服务器响应消息 1.2.1 浏览器发送HTTP请求的过程：1)当用户在浏览器的地址栏中输入一个URL并按回车键之后，浏览器会向HTTP服务器发送HTTP请求。HTTP请求主要分为“Get”和“Post”两种方法。 2)当我们在浏览器输入URL http://www.baidu.com 的时候，浏览器发送一个Request请求去获取 http://www.baidu.com 的html文件，服务器把Response文件对象发送回给浏览器。 3)浏览器分析Response中的 HTML，发现其中引用了很多其他文件，比如Images文件，CSS文件，JS文件。 浏览器会自动再次发送Request去获取图片，CSS文件，或者JS文件。 4)当所有的文件都下载成功后，网页会根据HTML语法结构，完整的显示出来了。 URL（Uniform / Universal Resource Locator的缩写）：统一资源定位符，是用于完整地描述Internet上网页和其他资源的地址的一种标识方法。 基本格式：scheme://host[:port#]/path/…/[?query-string][#anchor] · scheme：协议(例如：http, https, ftp) · host：服务器的IP地址或者域名 · port#：服务器的端口（如果是走协议默认端口，缺省端口80） · path：访问资源的路径 · query-string：参数，发送给http服务器的数据 · anchor：锚（跳转到网页的指定锚点位置） 例如： · ftp://192.168.0.116:8080/index · http://www.baidu.com · http://item.jd.com/11936238.html#product-detail 1.3 客户端HTTP请求URL只是标识资源的位置，而HTTP是用来提交和获取资源。客户端发送一个HTTP请求到服务器的请求消息，包括以下格式： 请求行、请求头部、空行、请求数据 四个部分组成 1.3.1 一个典型的HTTP请求示例GET https://www.baidu.com/ HTTP/1.1 Host: www.baidu.com Connection: keep-alive Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8 Referer: http://www.baidu.com/ Accept-Encoding: gzip, deflate, sdch, br Accept-Language: zh-CN,zh;q=0.8,en;q=0.6 Cookie: BAIDUID=04E4001F34EA74AD4601512DD3C41A7B:FG=1; BIDUPSID=04E4001F34EA74AD4601512DD3C41A7B; PSTM=1470329258; MCITY=-343%3A340%3A; BDUSS=nF0MVFiMTVLcUh-Q2MxQ0M3STZGQUZ4N2hBa1FFRkIzUDI3QlBCZjg5cFdOd1pZQVFBQUFBJCQAAAAAAAAAAAEAAADpLvgG0KGyvLrcyfrG-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFaq3ldWqt5XN; H_PS_PSSID=1447_18240_21105_21386_21454_21409_21554; BD_UPN=12314753; sug=3; sugstore=0; ORIGIN=0; bdime=0; H_PS_645EC=7e2ad3QHl181NSPbFbd7PRUCE1LlufzxrcFmwYin0E6b%2BW8bbTMKHZbDP0g; BDSVRTM=0 1.3.2 请求方法GET https://www.baidu.com/ HTTP/1.1 根据HTTP标准，HTTP请求可以使用多种请求方法。 HTTP 0.9：只有基本的文本 GET 功能。 HTTP 1.0：完善的请求/响应模型，并将协议补充完整，定义了三种请求方法： GET, POST 和 HEAD方法。 HTTP 1.1：在 1.0 基础上进行更新，新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。 HTTP 2.0（未普及）：请求/响应首部的定义基本没有改变，只是所有首部键必须全部小写，而且请求行要独立为 :method、:scheme、:host、:path这些键值对。 序号 方法 描述 1 GET 请求指定的页面信息，并返回实体主体。 2 HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头 3 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件），数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 4 PUT 从客户端向服务器传送的数据取代指定的文档的内容。 5 DELETE 请求服务器删除指定的页面。 6 CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。 7 OPTIONS 允许客户端查看服务器的性能。 8 TRACE 回显服务器收到的请求，主要用于测试或诊断。 1.3.3 HTTP请求主要分为Get和Post两种方法· GET是从服务器上获取数据，POST是向服务器传送数据 · GET请求参数显示，都显示在浏览器网址上，HTTP服务器根据该请求所包含URL中的参数来产生响应内容，即“Get”请求的参数是URL的一部分。 例如： http://www.baidu.com/s?wd=Chinese · POST请求参数在请求体当中，消息长度没有限制而且以隐式的方式进行发送，通常用来向HTTP服务器提交量比较大的数据（比如请求中包含许多参数或者文件上传操作等），请求的参数包含在“Content-Type”消息头里，指明该消息体的媒体类型和编码， 注意：避免使用Get方式提交表单，因为有可能会导致安全问题。比如说在登陆表单中用Get方式，用户输入的用户名和密码将在地址栏中暴露无遗。 1.3.4 常用的请求报头Host (主机和端口号)Host：对应网址URL中的Web名称和端口号，用于指定被请求资源的Internet主机和端口号，通常属于URL的一部分。 Connection (链接类型)Connection：表示客户端与服务连接类型 1)Client 发起一个包含 Connection:keep-alive 的请求，HTTP/1.1使用 keep-alive 为默认值。 2) Server收到请求后： o 如果 Server 支持 keep-alive，回复一个包含 Connection:keep-alive 的响应，不关闭连接； o 如果 Server 不支持 keep-alive，回复一个包含 Connection:close 的响应，关闭连接。 3)如果client收到包含 Connection:keep-alive 的响应，向同一个连接发送下一个请求，直到一方主动关闭连接。 keep-alive在很多情况下能够重用连接，减少资源消耗，缩短响应时间，比如当浏览器需要多个文件时(比如一个HTML文件和相关的图形文件)，不需要每次都去请求建立连接。 1.3.5 Upgrade-Insecure-Requests (升级为HTTPS请求)Upgrade-Insecure-Requests：升级不安全的请求，意思是会在加载 http 资源时自动替换成 https 请求，让浏览器不再显示https页面中的http请求警报。 HTTPS 是以安全为目标的 HTTP 通道，所以在 HTTPS 承载的页面上不允许出现 HTTP 请求，一旦出现就是提示或报错。 1.3.6 User-Agent (浏览器名称)User-Agent：是客户浏览器的名称，以后会详细讲。 1.3.7 Accept (传输文件类型)Accept：指浏览器或其他客户端可以接受的MIME（Multipurpose Internet Mail Extensions（多用途互联网邮件扩展））文件类型，服务器可以根据它判断并返回适当的文件格式。 举例：Accept: /：表示什么都可以接收。 Accept：image/gif：表明客户端希望接受GIF图像格式的资源； Accept：text/html：表明客户端希望接受html文本。 Accept: text/html, application/xhtml+xml;q=0.9, image/*;q=0.8：表示浏览器支持的 MIME 类型分别是 html文本、xhtml和xml文档、所有的图像格式资源。 q是权重系数，范围 0 =&lt; q &lt;= 1，q 值越大，请求越倾向于获得其“;”之前的类型表示的内容。若没有指定q值，则默认为1，按从左到右排序顺序；若被赋值为0，则用于表示浏览器不接受此内容类型。 Text：用于标准化地表示的文本信息，文本消息可以是多种字符集和或者多种格式的；Application：用于传输应用程序数据或者二进制数据。详细请点击 ###1.3.8 Referer (页面跳转处) Referer：表明产生请求的网页来自于哪个URL，用户是从该 Referer页面访问到当前请求的页面。这个属性可以用来跟踪Web请求来自哪个页面，是从什么网站来的等。 有时候遇到下载某网站图片，需要对应的referer，否则无法下载图片，那是因为人家做了防盗链，原理就是根据referer去判断是否是本网站的地址，如果不是，则拒绝，如果是，就可以下载； 1.3.9 Accept-Encoding（文件编解码格式）Accept-Encoding：指出浏览器可以接受的编码方式。编码方式不同于文件格式，它是为了压缩文件并加速文件传递速度。浏览器在接收到Web响应之后先解码，然后再检查文件格式，许多情形下这可以减少大量的下载时间。 举例：Accept-Encoding:gzip;q=1.0, identity; q=0.5, *;q=0如果有多个Encoding同时匹配, 按照q值顺序排列，本例中按顺序支持 gzip, identity压缩编码，支持gzip的浏览器会返回经过gzip编码的HTML页面。 如果请求消息中没有设置这个域服务器假定客户端对各种内容编码都可以接受。 1.3.10 Accept-Language（语言种类）Accept-Langeuage：指出浏览器可以接受的语言种类，如en或en-us指英语，zh或者zh-cn指中文，当服务器能够提供一种以上的语言版本时要用到。 1.3.11 Accept-Charset（字符编码）Accept-Charset：指出浏览器可以接受的字符编码。 举例：Accept-Charset:iso-8859-1,gb2312,utf-8· ISO8859-1：通常叫做Latin-1。Latin-1包括了书写所有西方欧洲语言不可缺少的附加字符，英文浏览器的默认值是ISO-8859-1. · gb2312：标准简体中文字符集; · utf-8：UNICODE 的一种变长字符编码，可以解决多种语言文本显示问题，从而实现应用国际化和本地化。 如果在请求消息中没有设置这个域，缺省是任何字符集都可以接受。 1.3.12 Cookie （Cookie）Cookie：浏览器用这个属性向服务器发送Cookie。Cookie是在浏览器中寄存的小型数据体，它可以记载和服务器相关的用户信息，也可以用来实现会话功能，以后会详细讲。 1.3.13 Content-Type (POST数据类型)Content-Type：POST请求里用来表示的内容类型。 举例：Content-Type = Text/XML; charset=gb2312：指明该请求的消息体中包含的是纯文本的XML类型的数据，字符编码采用“gb2312”。 1.4 服务端HTTP响应HTTP响应也由四个部分组成，分别是： 状态行、消息报头、空行、响应正文 HTTP/1.1 200 OK Server: Tengine Connection: keep-alive Date: Wed, 30 Nov 2016 07:58:21 GMT Cache-Control: no-cache Content-Type: text/html;charset=UTF-8 Keep-Alive: timeout=20 Vary: Accept-Encoding Pragma: no-cache X-NWS-LOG-UUID: bd27210a-24e5-4740-8f6c-25dbafa9c395 Content-Length: 180945 &lt;!DOCTYPE html PUBLIC “-//W3C//DTD XHTML 1.0 Transitional//EN” …. 1.4.1 常用的响应报头(了解)理论上所有的响应头信息都应该是回应请求头的。但是服务端为了效率，安全，还有其他方面的考虑，会添加相对应的响应头信息： 1.4.2 Cache-Control：must-revalidate, no-cache, private。这个值告诉客户端，服务端不希望客户端缓存资源，在下次请求资源时，必须要从新请求服务器，不能从缓存副本中获取资源。 · Cache-Control是响应头中很重要的信息，当客户端请求头中包含Cache-Control:max-age=0请求，明确表示不会缓存服务器资源时,Cache-Control作为作为回应信息，通常会返回no-cache，意思就是说，”那就不缓存呗”。 · 当客户端在请求头中没有包含Cache-Control时，服务端往往会定,不同的资源不同的缓存策略，比如说oschina在缓存图片资源的策略就是Cache-Control：max-age=86400,这个意思是，从当前时间开始，在86400秒的时间内，客户端可以直接从缓存副本中读取资源，而不需要向服务器请求。 1.4.3 Connection：keep-alive这个字段作为回应客户端的Connection：keep-alive，告诉客户端服务器的tcp连接也是一个长连接，客户端可以继续使用这个tcp连接发送http请求。 1.4.4 Content-Encoding:gzip告诉客户端，服务端发送的资源是采用gzip编码的，客户端看到这个信息后，应该采用gzip对资源进行解码。 1.4.5 Content-Type：text/html;charset=UTF-8告诉客户端，资源文件的类型，还有字符编码，客户端通过utf-8对资源进行解码，然后对资源进行html解析。通常我们会看到有些网站是乱码的，往往就是服务器端没有返回正确的编码。 1.4.6 Date：Sun, 21 Sep 2016 06:18:21 GMT这个是服务端发送资源时的服务器时间，GMT是格林尼治所在地的标准时间。http协议中发送的时间都是GMT的，这主要是解决在互联网上，不同时区在相互请求资源的时候，时间混乱问题。 1.4.7 Expires:Sun, 1 Jan 2000 01:00:00 GMT这个响应头也是跟缓存有关的，告诉客户端在这个时间前，可以直接访问缓存副本，很显然这个值会存在问题，因为客户端和服务器的时间不一定会都是相同的，如果时间不同就会导致问题。所以这个响应头是没有Cache-Control：max-age=*这个响应头准确的，因为max-age=date中的date是个相对时间，不仅更好理解，也更准确。 1.4.8 Pragma:no-cache这个含义与Cache-Control等同。 1.4.9 Server：Tengine/1.4.6这个是服务器和相对应的版本，只是告诉客户端服务器的信息。 1.4.10 Transfer-Encoding：chunked这个响应头告诉客户端，服务器发送的资源的方式是分块发送的。一般分块发送的资源都是服务器动态生成的，在发送时还不知道发送资源的大小，所以采用分块发送，每一块都是独立的，独立的块都能标示自己的长度，最后一块是0长度的，当客户端读到这个0长度的块时，就可以确定资源已经传输完了。 1.4.11 Vary: Accept-Encoding告诉缓存服务器，缓存压缩文件和非压缩文件两个版本，现在这个字段用处并不大，因为现在的浏览器都是支持压缩的。 1.5 响应状态码响应状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值。 1.5.1 常见状态码：· 100~199：表示服务器成功接收部分请求，要求客户端继续提交其余请求才能完成整个处理过程。 · 200~299：表示服务器成功接收请求并已完成整个处理过程。常用200（OK 请求成功）。 · 300~399：为完成请求，客户需进一步细化请求。例如：请求的资源已经移动一个新地址、常用302（所请求的页面已经临时转移至新的url）、307和304（使用缓存资源）。 · 400~499：客户端的请求有错误，常用404（服务器无法找到被请求的页面）、403（服务器拒绝访问，权限不够）。 · 500~599：服务器端出现错误，常用500（请求未完成。服务器遇到不可预知的情况）。 1.5.2 Cookie 和 Session：服务器和客户端的交互仅限于请求/响应过程，结束之后便断开，在下一次请求时，服务器会认为新的客户端。 为了维护他们之间的链接，让服务器知道这是前一个用户发送的请求，必须在一个地方保存客户端的信息。 Cookie：通过在 客户端 记录的信息确定用户的身份。 Session：通过在 服务器端 记录的信息确定用户的身份。 1.6 HTTP代理神器FiddlerFiddler是一款强大Web调试工具，它能记录所有客户端和服务器的HTTP请求。 Fiddler启动的时候，默认IE的代理设为了127.0.0.1:8888，而其他浏览器是需要手动设置。 1.6.1 工作原理Fiddler 是以代理web服务器的形式工作的，它使用代理地址：127.0.0.1，端口：8888 1.6.2 Fiddler抓取HTTPS设置1)启动Fiddler，打开菜单栏中的 Tools &gt; Telerik Fiddler Options，打开“Fiddler Options”对话框。 2)对Fiddler进行设置： o 打开工具栏-&gt;Tools-&gt;Fiddler Options-&gt;HTTPS， o 选中Capture HTTPS CONNECTs (捕捉HTTPS连接)， o 选中Decrypt HTTPS traffic（解密HTTPS通信） o 另外我们要用Fiddler获取本机所有进程的HTTPS请求，所以中间的下拉菜单中选中…from all processes （从所有进程） o 选中下方Ignore server certificate errors（忽略服务器证书错误） 3)为 Fiddler 配置Windows信任这个根证书解决安全警告：Trust Root Certificate（受信任的根证书）。 4) Fiddler 主菜单 Tools -&gt; Fiddler Options…-&gt; Connections o 选中Allow remote computers to connect（允许远程连接） o Act as system proxy on startup（作为系统启动代理） 5) 重启Fiddler，使配置生效（这一步很重要，必须做）。 1.6.3 Fiddler 如何捕获Chrome的会话1) 安装SwitchyOmega 代理管理 Chrome 浏览器插件 2)设置代理服务器为127.0.0.1:8888 3)通过浏览器插件切换为设置好的代理。 1.6.4 Fiddler界面设置好后，本机HTTP通信都会经过127.0.0.1:8888代理，也就会被Fiddler拦截到。 1)请求 (Request) 部分详解 1) Headers —— 显示客户端发送到服务器的 HTTP 请求的 header，显示为一个分级视图，包含了 Web 客户端信息、Cookie、传输状态等。 2)Textview —— 显示 POST 请求的 body 部分为文本。 3)WebForms —— 显示请求的 GET 参数 和 POST body 内容。 4) HexView —— 用十六进制数据显示请求。 5)Auth —— 显示响应 header 中的 Proxy-Authorization(代理身份验证) 和 Authorization(授权) 信息. 6)Raw —— 将整个请求显示为纯文本。 7)JSON - 显示JSON格式文件。 8)XML —— 如果请求的 body 是 XML 格式，就是用分级的 XML 树来显示它。 2) 响应 (Response) 部分详解 Transformer —— 显示响应的编码信息。 Headers —— 用分级视图显示响应的 header。 TextView —— 使用文本显示相应的 body。 ImageVies —— 如果请求是图片资源，显示响应的图片。 HexView —— 用十六进制数据显示响应。 WebView —— 响应在 Web 浏览器中的预览效果。 Auth —— 显示响应 header 中的 Proxy-Authorization(代理身份验证) 和 Authorization(授权) 信息。 Caching —— 显示此请求的缓存信息。 Privacy —— 显示此请求的私密 (P3P) 信息。 Raw —— 将整个响应显示为纯文本。 JSON - 显示JSON格式文件。 XML —— 如果响应的 body 是 XML 格式，就是用分级的 XML 树来显示它 。 2. urllib2库的基本使用所谓网页抓取，就是把URL地址中指定的网络资源从网络流中读取出来，保存到本地。 在Python中有很多库可以用来抓取网页，我们先学习urllib2。 urllib2 是 Python2.7 自带的模块(不需要下载，导入即可使用) urllib2 官方文档：https://docs.python.org/2/library/urllib2.html urllib2 源码：https://hg.python.org/cpython/file/2.7/Lib/urllib2.py urllib2 在 python3.x 中被改为urllib.request 2.1 urlopen我们先来段代码： # urllib2_urlopen.py # 导入urllib2 库 import urllib2 # 向指定的url发送请求，并返回服务器响应的类文件对象 response = urllib2.urlopen(“http://www.baidu.com&quot;) # 类文件对象支持 文件对象的操作方法，如read()方法读取文件全部内容，返回字符串 html = response.read() # 打印字符串 print html 执行写的python代码，将打印结果 Power@PowerMac ~$: python urllib2_urlopen.py 实际上，如果我们在浏览器上打开百度主页， 右键选择“查看源代码”，你会发现，跟我们刚才打印出来的是一模一样。也就是说，上面的4行代码就已经帮我们把百度的首页的全部代码爬了下来。 一个基本的url请求对应的python代码真的非常简单。 2.2 Request在我们第一个例子里，urlopen()的参数就是一个url地址； 但是如果需要执行更复杂的操作，比如增加HTTP报头，必须创建一个 Request 实例来作为urlopen()的参数；而需要访问的url地址则作为 Request 实例的参数。 我们编辑urllib2_request.py # urllib2_request.py import urllib2 # url 作为Request()方法的参数，构造并返回一个Request对象 request = urllib2.Request(“http://www.baidu.com&quot;) # Request对象作为urlopen()方法的参数，发送给服务器并接收响应 response = urllib2.urlopen(request) html = response.read() print html 2.2.1 运行结果是完全一样的：新建Request实例，除了必须要有 url 参数之外，还可以设置另外两个参数： data（默认空）：是伴随 url 提交的数据（比如要post的数据），同时 HTTP 请求将从 “GET”方式 改为 “POST”方式。 headers（默认空）：是一个字典，包含了需要发送的HTTP报头的键值对。 这两个参数下面会说到。 2.2.2 User-Agent但是这样直接用urllib2给一个网站发送请求的话，确实略有些唐突了，就好比，人家每家都有门，你以一个路人的身份直接闯进去显然不是很礼貌。而且有一些站点不喜欢被程序（非人为访问）访问，有可能会拒绝你的访问请求。 但是如果我们用一个合法的身份去请求别人网站，显然人家就是欢迎的，所以我们就应该给我们的这个代码加上一个身份，就是所谓的User-Agent头。 · 浏览器 就是互联网世界上公认被允许的身份，如果我们希望我们的爬虫程序更像一个真实用户，那我们第一步，就是需要伪装成一个被公认的浏览器。用不同的浏览器在发送请求的时候，会有不同的User-Agent头。 urllib2默认的User-Agent头为：Python-urllib/x.y（x和y是Python主版本和次版本号,例如 Python-urllib/2.7） #urllib2_useragent.py import urllib2 url = “http://www.itxdl.cn&quot; #IE 9.0 的 User-Agent，包含在 ua_header里 ua_header = {“User-Agent” : “Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;”} # url 连同 headers，一起构造Request请求，这个请求将附带 IE9.0 浏览器的User-Agent request = urllib2.Request(url, headers = ua_header) # 向服务器发送这个请求 response = urllib2.urlopen(request) html = response.read() print html 2.2.3 添加更多的Header信息在 HTTP Request 中加入特定的 Header，来构造一个完整的HTTP请求消息。 可以通过调用Request.add_header() 添加/修改一个特定的header 也可以通过调用Request.get_header()来查看已有的header。 · 添加一个特定的header # urllib2_headers.py import urllib2 url = “http://www.itxdl.cn&quot; #IE 9.0 的 User-Agent header = {“User-Agent” : “Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;”} request = urllib2.Request(url, headers = header) #也可以通过调用Request.add_header() 添加/修改一个特定的header request.add_header(“Connection”, “keep-alive”) # 也可以通过调用Request.get_header()来查看header信息 # request.get_header(header_name=”Connection”) response = urllib2.urlopen(req) print response.code #可以查看响应状态码 html = response.read() print html · 随机添加/修改User-Agent # urllib2_add_headers.py import urllib2 import random url = “http://www.itxdl.cn&quot; ua_list = [ ​ “Mozilla/5.0 (Windows NT 6.1; ) Apple…. “, ​ “Mozilla/5.0 (X11; CrOS i686 2268.111.0)… “, ​ “Mozilla/5.0 (Macintosh; U; PPC Mac OS X…. “, ​ “Mozilla/5.0 (Macintosh; Intel Mac OS… “ ] user_agent = random.choice(ua_list) request = urllib2.Request(url) #也可以通过调用Request.add_header() 添加/修改一个特定的header request.add_header(“User-Agent”, user_agent) # 第一个字母大写，后面的全部小写 request.get_header(“User-agent”) response = urllib2.urlopen(req) html = response.read() print html 2.3 urllib2默认只支持HTTP/HTTPS的GET和POST方法2.3.1 urllib.urlencode()1)urllib 和 urllib2 都是接受URL请求的相关模块，但是提供了不同的功能。两个最显著的不同如下： · urllib 仅可以接受URL，不能创建 设置了headers 的Request 类实例； · 但是 urllib 提供 urlencode 方法用来GET查询字符串的产生，而 urllib2 则没有。（这是 urllib 和 urllib2 经常一起使用的主要原因） · 编码工作使用urllib的urlencode()函数，帮我们将key:value这样的键值对转换成”key=value”这样的字符串，解码工作可以使用urllib的unquote()函数。（注意，不是urllib2.urlencode() ) # IPython2 中的测试结果 In [1]: import urllib In [2]: word = {“wd” : “兄弟连”} # 通过urllib.urlencode()方法，将字典键值对按URL编码转换，从而能被web服务器接受。 In [3]: urllib.urlencode(word) Out[3]: “wd=%e5%85%84%e5%bc%9f%e8%bf%9e” # 通过urllib.unquote()方法，把 URL编码字符串，转换回原先字符串。 In [4]: print urllib.unquote(“wd=%e5%85%84%e5%bc%9f%e8%bf%9e”) wd=兄弟连 2)一般HTTP请求提交数据，需要编码成 URL编码格式，然后做为url的一部分，或者作为参数传到Request对象中。 2.4 Get方式GET请求一般用于我们向服务器获取数据，比如说，我们用百度搜索兄弟连：https://www.baidu.com/s?wd=兄弟连 浏览器的url会跳转成如下所示: https://www.baidu.com/s?wd=%e5%85%84%e5%bc%9f%e8%bf%9e 在其中我们可以看到在请求部分里，http://www.baidu.com/s? 之后出现一个长长的字符串，其中就包含我们要查询的关键词兄弟连，于是我们可以尝试用默认的Get方式来发送请求。 # urllib2_get.py import urllib #负责url编码处理 import urllib2 url = “http://www.baidu.com/s&quot; word = {“wd”:”兄弟连”} word = urllib.urlencode(word) #转换成url编码格式（字符串） newurl = url + “?” + word # url首个分隔符就是 ? headers={ “User-Agent”: “Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36”} request = urllib2.Request(newurl, headers=headers) response = urllib2.urlopen(request) print response.read() 2.5 批量爬取贴吧页面数据首先我们创建一个python文件, tiebaSpider.py，我们要完成的是，输入一个百度贴吧的地址，比如： 百度贴吧LOL吧第一页：http://tieba.baidu.com/f?kw=lol&amp;ie=utf-8&amp;pn=0 第二页： http://tieba.baidu.com/f?kw=lol&amp;ie=utf-8&amp;pn=50 第三页： http://tieba.baidu.com/f?kw=lol&amp;ie=utf-8&amp;pn=100 发现规律了吧，贴吧中每个页面不同之处，就是url最后的pn的值，其余的都是一样的，我们可以抓住这个规律。 简单写一个小爬虫程序，来爬取百度LOL吧的所有网页。 · 先写一个main，提示用户输入要爬取的贴吧名，并用urllib.urlencode()进行转码，然后组合url，假设是lol吧，那么组合后的url就是：http://tieba.baidu.com/f?kw=lol # 模拟 main 函数 if name == “main“: ​ kw = raw_input(“请输入需要爬取的贴吧:”) ​ # 输入起始页和终止页，str转成int类型 ​ beginPage = int(raw_input(“请输入起始页：”)) ​ endPage = int(raw_input(“请输入终止页：”)) ​ url = “http://tieba.baidu.com/f?&quot; ​ key = urllib.urlencode({“kw” : kw}) ​ # 组合后的url示例：http://tieba.baidu.com/f?kw=lol ​ url = url + key ​ tiebaSpider(url, beginPage, endPage) · 接下来，我们写一个百度贴吧爬虫接口，我们需要传递3个参数给这个接口， 一个是main里组合的url地址，以及起始页码和终止页码，表示要爬取页码的范围。 def tiebaSpider(url, beginPage, endPage): ​ “”” ​ 作用：负责处理url，分配每个url去发送请求 ​ url：需要处理的第一个url ​ beginPage: 爬虫执行的起始页面 ​ endPage: 爬虫执行的截止页面 ​ “”” ​ for page in range(beginPage, endPage + 1): ​ pn = (page - 1) * 50 ​ filename = “第” + str(page) + “页.html” ​ # 组合为完整的 url，并且pn值每次增加50 ​ fullurl = url + “&amp;pn=” + str(pn) ​ #print fullurl ​ # 调用loadPage()发送请求获取HTML页面 ​ html = loadPage(fullurl, filename) ​ # 将获取到的HTML页面写入本地磁盘文件 ​ writeFile(html, filename) · 我们已经之前写出一个爬取一个网页的代码。现在，我们可以将它封装成一个小函数loadPage，供我们使用。 def loadPage(url, filename): ​ ‘’’ ​ 作用：根据url发送请求，获取服务器响应文件 ​ url：需要爬取的url地址 ​ filename: 文件名 ​ ‘’’ ​ print “正在下载” + filename ​ headers = {“User-Agent”: “Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;”} ​ request = urllib2.Request(url, headers = headers) ​ response = urllib2.urlopen(request) ​ return response.read() · 最后如果我们希望将爬取到了每页的信息存储在本地磁盘上，我们可以简单写一个存储文件的接口。 def writeFile(html, filename): ​ “”” ​ 作用：保存服务器响应文件到本地磁盘文件里 ​ html: 服务器响应文件 ​ filename: 本地磁盘文件名 ​ “”” ​ print “正在存储” + filename ​ with open(filename, ‘w’) as f: ​ f.write(html) ​ print “-“ * 20 其实很多网站都是这样的，同类网站下的html页面编号，分别对应网址后的网页序号，只要发现规律就可以批量爬取页面了。 2.6 POST方式：上面我们说了Request请求对象的里有data参数，它就是用在POST里的，我们要传送的数据就是这个参数data，data是一个字典，里面要匹配键值对。 2.6.1 有道词典翻译网站：输入测试数据，再通过使用Fiddler观察，其中有一条是POST请求，而向服务器发送的请求数据并不是在url里，那么我们可以试着模拟这个POST请求。 于是，我们可以尝试用POST方式发送请求。 import urllib import urllib2 # POST请求的目标URL url = “http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule&amp;smartresult=ugc&amp;sessionFrom=null&quot; headers={“User-Agent”: “Mozilla….”} formdata = { ​ “type”:”AUTO”, ​ “i”:”i love python”, ​ “doctype”:”json”, ​ “xmlVersion”:”1.8”, ​ “keyfrom”:”fanyi.web”, ​ “ue”:”UTF-8”, ​ “action”:”FY_BY_ENTER”, ​ “typoResult”:”true” } data = urllib.urlencode(formdata) request = urllib2.Request(url, data = data, headers = headers) response = urllib2.urlopen(request) print response.read() 发送POST请求时，需要特别注意headers的一些属性：Content-Length: 144： 是指发送的表单数据长度为144，也就是字符个数是144个。 X-Requested-With: XMLHttpRequest ：表示Ajax异步请求。 Content-Type: application/x-www-form-urlencoded ： 表示浏览器提交 Web 表单时使用，表单数据会按照 name1=value1&amp;name2=value2 键值对形式进行编码。 2.7 获取AJAX加载的内容有些网页内容使用AJAX加载，只要记得，AJAX一般返回的是JSON,直接对AJAX地址进行post或get，就返回JSON数据了。 “作为一名爬虫工程师，你最需要关注的，是数据的来源” import urllib import urllib2 # demo1 url = “https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action&quot; headers={“User-Agent”: “Mozilla….”} # 变动的是这两个参数，从start开始往后显示limit个 formdata = { ​ ‘start’:’0’, ​ ‘limit’:’10’ } data = urllib.urlencode(formdata) request = urllib2.Request(url, data = data, headers = headers) response = urllib2.urlopen(request) print response.read() # demo2 url = “https://movie.douban.com/j/chart/top_list?&quot; headers={“User-Agent”: “Mozilla….”} # 处理所有参数 formdata = { ​ ‘type’:’11’, ​ ‘interval_id’:’100:90’, ​ ‘action’:’’, ​ ‘start’:’0’, ​ ‘limit’:’10’ } data = urllib.urlencode(formdata) request = urllib2.Request(url, data = data, headers = headers) response = urllib2.urlopen(request) print response.read() 2.7.1 问题：为什么有时候POST也能在URL内看到数据？· GET方式是直接以链接形式访问，链接中包含了所有的参数，服务器端用Request.QueryString获取变量的值。如果包含了密码的话是一种不安全的选择，不过你可以直观地看到自己提交了什么内容。 · POST则不会在网址上显示所有的参数，服务器端用Request.Form获取提交的数据，在Form提交的时候。但是HTML代码里如果不指定 method 属性，则默认为GET请求，Form中提交的数据将会附加在url之后，以?分开与url分开。 · 表单数据可以作为 URL 字段（method=”get”）或者 HTTP POST （method=”post”）的方式来发送。比如在下面的HTML代码中，表单数据将因为 （method=”get”） 而附加到 URL 上： ​ First name: ​ Last name: ​ 2.8 处理HTTPS请求 SSL证书验证现在随处可见 https 开头的网站，urllib2可以为 HTTPS 请求验证SSL证书，就像web浏览器一样，如果网站的SSL证书是经过CA认证的，则能够正常访问，如：https://www.baidu.com/等... 如果SSL证书验证不通过，或者操作系统不信任服务器的安全证书，比如浏览器在访问12306网站如：https://www.12306.cn/mormhweb/的时候，会警告用户证书不受信任。（据说 12306 网站证书是自己做的，没有通过CA认证） urllib2在访问的时候则会报出SSLError： import urllib2 url = “https://www.12306.cn/mormhweb/&quot; headers = {“User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36”} request = urllib2.Request(url, headers = headers) response = urllib2.urlopen(request) print response.read() 运行结果： urllib2.URLError: 所以，如果以后遇到这种网站，我们需要单独处理SSL证书，让程序忽略SSL证书验证错误，即可正常访问。 import urllib import urllib2 # 1. 导入Python SSL处理模块 import ssl # 2. 表示忽略未经核实的SSL证书认证 context = ssl._create_unverified_context() url = “https://www.12306.cn/mormhweb/&quot; headers = {“User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36”} request = urllib2.Request(url, headers = headers) # 3. 在urlopen()方法里 指明添加 context 参数 response = urllib2.urlopen(request, context = context) print response.read() 2.9 关于CACA(Certificate Authority)是数字证书认证中心的简称，是指发放、管理、废除数字证书的受信任的第三方机构，如北京数字认证股份有限公司、上海市数字证书认证中心有限公司等… CA的作用是检查证书持有者身份的合法性，并签发证书，以防证书被伪造或篡改，以及对证书和密钥进行管理。 现实生活中可以用身份证来证明身份， 那么在网络世界里，数字证书就是身份证。和现实生活不同的是，并不是每个上网的用户都有数字证书的，往往只有当一个人需要证明自己的身份的时候才需要用到数字证书。 普通用户一般是不需要，因为网站并不关心是谁访问了网站，现在的网站只关心流量。但是反过来，网站就需要证明自己的身份了。 比如说现在钓鱼网站很多的，比如你想访问的是www.baidu.com，但其实你访问的是www.daibu.com”，所以在提交自己的隐私信息之前需要验证一下网站的身份，要求网站出示数字证书。 一般正常的网站都会主动出示自己的数字证书，来确保客户端和网站服务器之间的通信数据是加密安全的。 2.正则2.1 为什么要学正则表达式实际上爬虫一共就四个主要步骤： 明确目标 (要知道你准备在哪个范围或者网站去搜索) 爬 (将所有的网站的内容全部爬下来) 取 (去掉对我们没用处的数据) 处理数据（按照我们想要的方式存储和使用） 那么对于文本的过滤或者规则的匹配，最强大的就是正则表达式，是Python爬虫世界里必不可少的神兵利器。 2.1.1 什么是正则表达式正则表达式，又称规则表达式，通常被用来检索、替换那些符合某个模式(规则)的文本。 正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。 给定一个正则表达式和另一个字符串，我们可以达到如下的目的： · 给定的字符串是否符合正则表达式的过滤逻辑（“匹配”）； · 通过正则表达式，从文本字符串中获取我们想要的特定部分（“过滤”）。 2.2 正则表达式匹配规则 2.2.1 Python 的re 模块在 Python 中，我们可以使用内置的 re 模块来使用正则表达式。 有一点需要特别注意的是，正则表达式使用 对特殊字符进行转义，所以如果我们要使用原始字符串，只需加一个 r 前缀，示例： r’chuanzhiboke\\t.\\tpython’ 2.2.2 re 模块的一般使用步骤如下： 使用 compile() 函数将正则表达式的字符串形式编译为一个 Pattern 对象 通过 Pattern 对象提供的一系列方法对文本进行匹配查找，获得匹配结果，一个 Match 对象。 最后使用 Match 对象提供的属性和方法获得信息，根据需要进行其他的操作 2.2.3 compile 函数compile 函数用于编译正则表达式，生成一个 Pattern 对象，它的一般使用形式如下： import re 1) 将正则表达式编译成 Pattern 对象 pattern = re.compile(r’\\d+’) 在上面，我们已将一个正则表达式编译成 Pattern 对象，接下来，我们就可以利用 pattern 的一系列方法对文本进行匹配查找了。 Pattern 对象的一些常用方法主要有： · match 方法：从起始位置开始查找，一次匹配 · search 方法：从任何位置开始查找，一次匹配 · findall 方法：全部匹配，返回列表 · finditer 方法：全部匹配，返回迭代器 · split 方法：分割字符串，返回列表 · sub 方法：替换 2.2.4 match 方法match 方法用于查找字符串的头部（也可以指定起始位置），它是一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果。它的一般使用形式如下： match(string[, pos[, endpos]]) 其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。因此，当你不指定 pos 和 endpos 时，match 方法默认匹配字符串的头部。 当匹配成功时，返回一个 Match 对象，如果没有匹配上，则返回 None。 >&gt;&gt; import re >&gt;&gt; pattern = re.compile(r’\\d+’) # 用于匹配至少一个数字 >&gt;&gt; m = pattern.match(‘one12twothree34four’) # 查找头部，没有匹配 >&gt;&gt; print m None >&gt;&gt; m = pattern.match(‘one12twothree34four’, 2, 10) # 从’e’的位置开始匹配，没有匹配 >&gt;&gt; print m None >&gt;&gt; m = pattern.match(‘one12twothree34four’, 3, 10) # 从’1’的位置开始匹配，正好匹配 >&gt;&gt; print m # 返回一个 Match 对象 &lt;_sre.SRE_Match object at 0x10a42aac0&gt; >&gt;&gt; m.group(0) # 可省略 0 ‘12’ >&gt;&gt; m.start(0) # 可省略 0 3 >&gt;&gt; m.end(0) # 可省略 0 5 >&gt;&gt; m.span(0) # 可省略 0 (3, 5) 在上面，当匹配成功时返回一个 Match 对象，其中： · group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)； · start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0； · end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0； · span([group]) 方法返回 (start(group), end(group))。 再看看一个例子： >&gt;&gt; import re >&gt;&gt; pattern = re.compile(r’([a-z]+) ([a-z]+)’, re.I) # re.I 表示忽略大小写 >&gt;&gt; m = pattern.match(‘Hello World Wide Web’) >&gt;&gt; print m # 匹配成功，返回一个 Match 对象 &lt;_sre.SRE_Match object at 0x10bea83e8&gt; >&gt;&gt; m.group(0) # 返回匹配成功的整个子串 ‘Hello World’ >&gt;&gt; m.span(0) # 返回匹配成功的整个子串的索引 (0, 11) >&gt;&gt; m.group(1) # 返回第一个分组匹配成功的子串 ‘Hello’ >&gt;&gt; m.span(1) # 返回第一个分组匹配成功的子串的索引 (0, 5) >&gt;&gt; m.group(2) # 返回第二个分组匹配成功的子串 ‘World’ >&gt;&gt; m.span(2) # 返回第二个分组匹配成功的子串 (6, 11) >&gt;&gt; m.groups() # 等价于 (m.group(1), m.group(2), …) (‘Hello’, ‘World’) >&gt;&gt; m.group(3) # 不存在第三个分组 Traceback (most recent call last): File ““, line 1, in IndexError: no such group 2.2.5 search 方法search 方法用于查找字符串的任何位置，它也是一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果，它的一般使用形式如下： search(string[, pos[, endpos]]) 其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。 当匹配成功时，返回一个 Match 对象，如果没有匹配上，则返回 None。 让我们看看例子： >&gt;&gt; import re >&gt;&gt; pattern = re.compile(‘\\d+’) >&gt;&gt; m = pattern.search(‘one12twothree34four’) # 这里如果使用 match 方法则不匹配 >&gt;&gt; m &lt;_sre.SRE_Match object at 0x10cc03ac0&gt; >&gt;&gt; m.group() ‘12’ >&gt;&gt; m = pattern.search(‘one12twothree34four’, 10, 30) # 指定字符串区间 >&gt;&gt; m &lt;_sre.SRE_Match object at 0x10cc03b28&gt; >&gt;&gt; m.group() ‘34’ >&gt;&gt; m.span() (13, 15) 再来看一个例子： # -- coding: utf-8 -- import re # 将正则表达式编译成 Pattern 对象 pattern = re.compile(r’\\d+’) # 使用 search() 查找匹配的子串，不存在匹配的子串时将返回 None # 这里使用 match() 无法成功匹配 m = pattern.search(‘hello 123456 789’) if m: ​ # 使用 Match 获得分组信息 ​ print ‘matching string:’,m.group() ​ # 起始位置和结束位置 ​ print ‘position:’,m.span() 执行结果： matching string: 123456 position: (6, 12) 2.2.6 findall方法上面的 match 和 search 方法都是一次匹配，只要找到了一个匹配的结果就返回。然而，在大多数时候，我们需要搜索整个字符串，获得所有匹配的结果。 findall 方法的使用形式如下： findall(string[, pos[, endpos]]) 其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。 findall 以列表形式返回全部能匹配的子串，如果没有匹配，则返回一个空列表。 看看例子： import re pattern = re.compile(r’\\d+’) # 查找数字 result1 = pattern.findall(‘hello 123456 789’) result2 = pattern.findall(‘one1two2three3four4’, 0, 10) print result1 print result2 执行结果： [‘123456’, ‘789’] [‘1’, ‘2’] 再先看一个栗子： # re_test.py import re #re模块提供一个方法叫compile模块，提供我们输入一个匹配的规则 #然后返回一个pattern实例，我们根据这个规则去匹配字符串 pattern = re.compile(r’\\d+.\\d*’) #通过partten.findall()方法就能够全部匹配到我们得到的字符串 result = pattern.findall(“123.141593, ‘bigcat’, 232312, 3.15”) #findall 以 列表形式 返回全部能匹配的子串给result for item in result: ​ print item 运行结果： 123.141593 3.15 —————————————————————————————————— 2.2.7 finditer方法finditer 方法的行为跟 findall 的行为类似，也是搜索整个字符串，获得所有匹配的结果。但它返回一个顺序访问每一个匹配结果（Match 对象）的迭代器。 看看例子： # -- coding: utf-8 -- import re pattern = re.compile(r’\\d+’) result_iter1 = pattern.finditer(‘hello 123456 789’) result_iter2 = pattern.finditer(‘one1two2three3four4’, 0, 10) print type(result_iter1) print type(result_iter2) print ‘result1…’ for m1 in result_iter1: # m1 是 Match 对象 ​ print ‘matching string: {}, position: {}’.format(m1.group(), m1.span()) print ‘result2…’ for m2 in result_iter2: ​ print ‘matching string: {}, position: {}’.format(m2.group(), m2.span()) 执行结果： result1… matching string: 123456, position: (6, 12) matching string: 789, position: (13, 16) result2… matching string: 1, position: (3, 4) matching string: 2, position: (7, 8) —————————————————————————————————— 2.2.8 split 方法split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下： split(string[, maxsplit]) 其中，maxsplit 用于指定最大分割次数，不指定将全部分割。 看看例子： import re p = re.compile(r’[\\s\\,\\;]+’) print p.split(‘a,b;; c d’) 执行结果： [‘a’, ‘b’, ‘c’, ‘d’] —————————————————————————————————— 2.2.9 sub 方法sub 方法用于替换。它的使用形式如下： sub(repl, string[, count]) 其中，repl 可以是字符串也可以是一个函数： · 如果 repl 是字符串，则会使用 repl 去替换字符串每一个匹配的子串，并返回替换后的字符串，另外，repl 还可以使用 id 的形式来引用分组，但不能使用编号 0； · 如果 repl 是函数，这个方法应当只接受一个参数（Match 对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。 · count 用于指定最多替换次数，不指定时全部替换。 看看例子： import re p = re.compile(r’(\\w+) (\\w+)’) # \\w = [A-Za-z0-9] s = ‘hello 123, hello 456’ print p.sub(r’hello world’, s) # 使用 ‘hello world’ 替换 ‘hello 123’ 和 ‘hello 456’ print p.sub(r’\\2 \\1’, s) # 引用分组 def func(m): ​ return ‘hi’ + ‘ ‘ + m.group(2) print p.sub(func, s) print p.sub(func, s, 1) # 最多替换一次 执行结果： hello world, hello world 123 hello, 456 hello hi 123, hi 456 hi 123, hello 456 —————————————————————————————————— 2.2.10 匹配中文在某些情况下，我们想匹配文本中的汉字，有一点需要注意的是，中文的 unicode 编码范围 主要在 [u4e00-u9fa5]，这里说主要是因为这个范围并不完整，比如没有包括全角（中文）标点，不过，在大部分情况下，应该是够用的。 假设现在想把字符串 title = u’你好，hello，世界’ 中的中文提取出来，可以这么做： import re title = u’你好，hello，世界’ pattern = re.compile(ur’[\\u4e00-\\u9fa5]+’) result = pattern.findall(title) print result 注意到，我们在正则表达式前面加上了两个前缀 ur，其中 r 表示使用原始字符串，u 表示是 unicode 字符串。 执行结果: [u’\\u4f60\\u597d’, u’\\u4e16\\u754c’] 注意：贪婪模式与非贪婪模式 贪婪模式：在整个表达式匹配成功的前提下，尽可能多的匹配 ( * )； 非贪婪模式：在整个表达式匹配成功的前提下，尽可能少的匹配 ( ? )； Python里数量词默认是贪婪的。 示例一：源字符串：abbbc · 使用贪婪的数量词的正则表达式 ab* ，匹配结果： abbb。 决定了尽可能多匹配 b，所以a后面所有的 b 都出现了。 · 使用非贪婪的数量词的正则表达式ab*?，匹配结果： a。 即使前面有 *，但是 ? 决定了尽可能少匹配 b，所以没有 b。 示例二 ：源字符串：aatest1bbtest2cc · 使用贪婪的数量词的正则表达式：.* · 匹配结果：test1bbtest2 这里采用的是贪婪模式。在匹配到第一个“”时已经可以使整个表达式匹配成功，但是由于采用的是贪婪模式，所以仍然要向右尝试匹配，查看是否还有更长的可以成功匹配的子串。匹配到第二个“”后，向右再没有可以成功匹配的子串，匹配结束，匹配结果为“test1bbtest2” · 使用非贪婪的数量词的正则表达式：.*? · 匹配结果：test1 正则表达式二采用的是非贪婪模式，在匹配到第一个“”时使整个表达式匹配成功，由于采用的是非贪婪模式，所以结束匹配，不再向右尝试，匹配结果为“test1”。 3. CSS 选择器：BeautifulSoup4和 lxml 一样，Beautiful Soup 也是一个 HTML/XML的解析器，主要的功能也是如何解析和提取 HTML/XML 数据。 lxml 只会局部遍历，而Beautiful Soup 是基于HTML DOM的，会载入整个文档，解析整个DOM树，因此时间和内存开销都会大很多，所以性能要低于lxml。 BeautifulSoup 用来解析 HTML 比较简单，API非常人性化，支持CSS选择器、Python标准库中的HTML解析器，也支持 lxml 的 XML解析器。 Beautiful Soup 3 目前已经停止开发，推荐现在的项目使用Beautiful Soup 4。使用 pip 安装即可：pip install beautifulsoup4 官方文档：http://beautifulsoup.readthedocs.io/zh_CN/v4.4.0 抓取工具 速度 使用难度 安装难度 正则 最快 困难 无（内置） BeautifulSoup 慢 最简单 简单 lxml 快 简单 一般 示例： 首先必须要导入 bs4 库 123456789101112131415161718192021222324# beautifulsoup4_test.pyfrom bs4 import BeautifulSouphtml = &quot;&quot;&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&quot;&quot;&quot;#创建 Beautiful Soup 对象soup = BeautifulSoup(html)#打开本地 HTML 文件的方式来创建对象#soup = BeautifulSoup(open(&apos;index.html&apos;))#格式化输出 soup 对象的内容print soup.prettify() 运行结果： 123456789101112131415161718192021222324252627282930313233&lt;html&gt; &lt;head&gt; &lt;title&gt; The Dormouse&apos;s story &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt; &lt;b&gt; The Dormouse&apos;s story &lt;/b&gt; &lt;/p&gt; &lt;p class=&quot;story&quot;&gt; Once upon a time there were three little sisters; and their names were &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; &lt;!-- Elsie --&gt; &lt;/a&gt; , &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt; Lacie &lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt; Tillie &lt;/a&gt; ;and they lived at the bottom of a well. &lt;/p&gt; &lt;p class=&quot;story&quot;&gt; ... &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; · 如果我们在 Terminal下执行，会看到这样一段警告： · 意思是，如果我们没有显式地指定解析器，所以默认使用这个系统的最佳可用HTML解析器(“lxml”)。如果你在另一个系统中运行这段代码，或者在不同的虚拟环境中，使用不同的解析器造成行为不同。 · 但是我们可以通过soup = BeautifulSoup(html,“lxml”)方式指定lxml解析器。 3.1 四大对象种类Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种: · Tag · NavigableString · BeautifulSoup · Comment 3.1.1 TagTag 通俗点讲就是 HTML 中的一个个标签，例如： 123&lt;head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;&lt;/head&gt;&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt; 上面的 title head a p等等 HTML 标签加上里面包括的内容就是 Tag，那么试着使用 Beautiful Soup 来获取 Tags: 1234567891011121314151617181920212223242526272829303132from bs4 import BeautifulSouphtml = &quot;&quot;&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&quot;&quot;&quot;#创建 Beautiful Soup 对象soup = BeautifulSoup(html)print soup.title# &lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;print soup.head# &lt;head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;&lt;/head&gt;print soup.a# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;print soup.p# &lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;print type(soup.p)# &lt;class &apos;bs4.element.Tag&apos;&gt; 我们可以利用 soup 加标签名轻松地获取这些标签的内容，这些对象的类型是bs4.element.Tag。但是注意，它查找的是在所有内容中的第一个符合要求的标签。如果要查询所有的标签，后面会进行介绍。 对于 Tag，它有两个重要的属性，是 name 和 attrs 1234567891011121314151617181920print soup.name# [document] #soup 对象本身比较特殊，它的 name 即为 [document]print soup.head.name# head #对于其他内部标签，输出的值便为标签本身的名称print soup.p.attrs# &#123;&apos;class&apos;: [&apos;title&apos;], &apos;name&apos;: &apos;dromouse&apos;&#125;# 在这里，我们把 p 标签的所有属性打印输出了出来，得到的类型是一个字典。print soup.p[&apos;class&apos;] # soup.p.get(&apos;class&apos;)# [&apos;title&apos;] #还可以利用get方法，传入属性的名称，二者是等价的soup.p[&apos;class&apos;] = &quot;newClass&quot;print soup.p # 可以对这些属性和内容等等进行修改# &lt;p class=&quot;newClass&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;del soup.p[&apos;class&apos;] # 还可以对这个属性进行删除print soup.p# &lt;p name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt; 3.1.2 NavigableString既然我们已经得到了标签的内容，那么问题来了，我们要想获取标签内部的文字怎么办呢？很简单，用 .string 即可，例如 12345print soup.p.string# The Dormouse&apos;s storyprint type(soup.p.string)# In [13]: &lt;class &apos;bs4.element.NavigableString&apos;&gt; 3.1.3 BeautifulSoupBeautifulSoup 对象表示的是一个文档的内容。大部分时候,可以把它当作 Tag 对象，是一个特殊的 Tag，我们可以分别获取它的类型，名称，以及属性来感受一下 12345678print type(soup.name)# &lt;type &apos;unicode&apos;&gt;print soup.name # [document]print soup.attrs # 文档本身的属性为空# &#123;&#125; 3.1.4 CommentComment 对象是一个特殊类型的 NavigableString 对象，其输出的内容不包括注释符号。 12345678print soup.a# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;print soup.a.string# Elsie print type(soup.a.string)# &lt;class &apos;bs4.element.Comment&apos;&gt; a 标签里的内容实际上是注释，但是如果我们利用 .string 来输出它的内容时，注释符号已经去掉了。 3.2 遍历文档树3.2.1 直接子节点：.contents .children属性.content tag 的 .content 属性可以将tag的子节点以列表的方式输出 12print soup.head.contents #[&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;] 输出方式为列表，我们可以用列表索引来获取它的某一个元素 12print soup.head.contents[0]#&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt; .children 它返回的不是一个 list，不过我们可以通过遍历获取所有子节点。 我们打印输出 .children 看一下，可以发现它是一个 list 生成器对象 12345print soup.head.children#&lt;listiterator object at 0x7f71457f5710&gt;for child in soup.body.children: print child 结果: 123456789&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt; 3.2.2 所有子孙节点: .descendants属性.contents 和 .children 属性仅包含tag的直接子节点，.descendants 属性可以对所有tag的子孙节点进行递归循环，和 children类似，我们也需要遍历获取其中的内容。 12for child in soup.descendants: print child 运行结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;&lt;/head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;The Dormouse&apos;s story&lt;body&gt;&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&lt;/body&gt;&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;The Dormouse&apos;s story&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;Once upon a time there were three little sisters; and their names were&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt; Elsie ,&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;Lacie and&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;Tillie;and they lived at the bottom of a well.&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;... ###3.2.3 节点内容 : .stringb 属 性 如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点。如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同。 通俗点说就是：如果一个标签里面没有标签了，那么 .string 就会返回标签里面的内容。如果标签里面只有唯一的一个标签了，那么 .strin`g 也会返回最里面的内容。例如： print soup.head.string #The Dormouse’s story print soup.title.string #The Dormouse’s story 3.3 搜索文档 树3.3.1 find_all(name, attrs, recursive, text, kwargs) 1 ） name 参 数 name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉 A. 传字符 串 最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的标签: 12345soup.find_all(&apos;b&apos;)# [&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;]print soup.find_all(&apos;a&apos;)#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;] B. 传正则表达 式 如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示和标签都应该被找到 12345import refor tag in soup.find_all(re.compile(&quot;^b&quot;)): print(tag.name)# body# b C. 传列 表 如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有标签和标签: 12345soup.find_all([&quot;a&quot;, &quot;b&quot;])# [&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;] 2）keyword参数 12soup.find_all(id=&apos;link2&apos;)# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;] 3 ） text参数 通过 text 参数可以搜搜文档中的字符串内容，与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表 12345678soup.find_all(text=&quot;Elsie&quot;)# [u&apos;Elsie&apos;]soup.find_all(text=[&quot;Tillie&quot;, &quot;Elsie&quot;, &quot;Lacie&quot;])# [u&apos;Elsie&apos;, u&apos;Lacie&apos;, u&apos;Tillie&apos;]soup.find_all(text=re.compile(&quot;Dormouse&quot;))[u&quot;The Dormouse&apos;s story&quot;, u&quot;The Dormouse&apos;s story&quot;] 3.4 CSS选择器这就是另一种与 find_all 方法有异曲同工之妙的查找方法. · 写 CSS 时，标签名不加任何修饰，类名前加.，id名前加# · 在这里我们也可以利用类似的方法来筛选元素，用到的方法是 soup.select()，返回类型是 list 3.4.1 通过标签名查找12345678print soup.select(&apos;title&apos;) #[&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;]print soup.select(&apos;a&apos;)#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]print soup.select(&apos;b&apos;)#[&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;] 3.4.2 通过类名查找12print soup.select(&apos;.sister&apos;)#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;] 3.4.3 通过 id名查找 12print soup.select(&apos;#link1&apos;)#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;] 3.4.4 组合查找组合查找即和写 class 文件时，标签名与类名、id名进行的组合原理是一样的，例如查找 p 标签中，id 等于 link1的内容，二者需要用空格分开 12print soup.select(&apos;p #link1&apos;)#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;] 直接子标签查找，则使用 &gt; 分隔 12print soup.select(&quot;head &gt; title&quot;)#[&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;] 3.4.5 属性查找查找时还可以加入属性元素，属性需要用中括号括起来，注意属性和标签属于同一节点，所以中间不能加空格，否则会无法匹配到。 12345print soup.select(&apos;a[class=&quot;sister&quot;]&apos;)#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]print soup.select(&apos;a[href=&quot;http://example.com/elsie&quot;]&apos;)#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;] 同样，属性仍然可以与上述查找方式组合，不在同一节点的空格隔开，同一节点的不加空格 12print soup.select(&apos;p a[href=&quot;http://example.com/elsie&quot;]&apos;)#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;] 3.4.6 获取内容以上的 select 方法返回的结果都是列表形式，可以遍历形式输出，然后用 get_text() 方法来获取它的内容。 123456soup = BeautifulSoup(html, &apos;lxml&apos;)print type(soup.select(&apos;title&apos;))print soup.select(&apos;title&apos;)[0].get_text()for title in soup.select(&apos;title&apos;): print title.get_text() 4. 数据提取之JSON与JsonPATHJSON(JavaScript Object Notation) 是一种轻量级的数据交换格式，它使得人们很容易的进行阅读和编写。同时也方便了机器进行解析和生成。适用于进行数据交互的场景，比如网站前台与后台之间的数据交互。 JSON和XML的比较可谓不相上下。 Python 2.7中自带了JSON模块，直接import json就可以使用了。 官方文档：http://docs.python.org/library/json.html Json在线解析网站：http://www.json.cn/# 4.1 JSONjson简单说就是javascript中的对象和数组，所以这两种结构就是对象和数组两种结构，通过这两种结构可以表示各种复杂的结构 对象：对象在js中表示为{ }括起来的内容，数据结构为 { key：value, key：value, … }的键值对的结构，在面向对象的语言中，key为对象的属性，value为对应的属性值，所以很容易理解，取值方法为 对象.key 获取属性值，这个属性值的类型可以是数字、字符串、数组、对象这几种。 数组：数组在js中是中括号[ ]括起来的内容，数据结构为 [“Python”, “javascript”, “C++”, …]，取值方式和所有语言中一样，使用索引获取，字段值的类型可以是 数字、字符串、数组、对象几种。 4.2 import jsonjson模块提供了四个功能：dumps、dump、loads、load，用于字符串 和 python数据类型间进行转换。 4.2.1 json.loads()把Json格式字符串解码转换成Python对象 从json到python的类型转化对照如下： 12345678910111213# json_loads.pyimport jsonstrList = &apos;[1, 2, 3, 4]&apos;strDict = &apos;&#123;&quot;city&quot;: &quot;北京&quot;, &quot;name&quot;: &quot;大猫&quot;&#125;&apos;json.loads(strList) # [1, 2, 3, 4]json.loads(strDict) # json数据自动按Unicode存储# &#123;u&apos;city&apos;: u&apos;\\u5317\\u4eac&apos;, u&apos;name&apos;: u&apos;\\u5927\\u732b&apos;&#125; 4.2.2. json.dumps()实现python类型转化为json字符串，返回一个str对象 把一个Python对象编码转换成Json字符串 从python原始类型向json类型的转化对照如下： 1234567891011121314151617181920212223242526272829# json_dumps.pyimport jsonimport chardetlistStr = [1, 2, 3, 4]tupleStr = (1, 2, 3, 4)dictStr = &#123;&quot;city&quot;: &quot;北京&quot;, &quot;name&quot;: &quot;大猫&quot;&#125;json.dumps(listStr)# &apos;[1, 2, 3, 4]&apos;json.dumps(tupleStr)# &apos;[1, 2, 3, 4]&apos;# 注意：json.dumps() 序列化时默认使用的ascii编码# 添加参数 ensure_ascii=False 禁用ascii编码，按utf-8编码# chardet.detect()返回字典, 其中confidence是检测精确度json.dumps(dictStr) # &apos;&#123;&quot;city&quot;: &quot;\\\\u5317\\\\u4eac&quot;, &quot;name&quot;: &quot;\\\\u5927\\\\u5218&quot;&#125;&apos;chardet.detect(json.dumps(dictStr))# &#123;&apos;confidence&apos;: 1.0, &apos;encoding&apos;: &apos;ascii&apos;&#125;print json.dumps(dictStr, ensure_ascii=False) # &#123;&quot;city&quot;: &quot;北京&quot;, &quot;name&quot;: &quot;大刘&quot;&#125;chardet.detect(json.dumps(dictStr, ensure_ascii=False))# &#123;&apos;confidence&apos;: 0.99, &apos;encoding&apos;: &apos;utf-8&apos;&#125; chardet是一个非常优秀的编码识别模块，可通过pip安装 4.2.3 json.dump()将Python内置类型序列化为json对象后写入文件 123456789# json_dump.pyimport jsonlistStr = [&#123;&quot;city&quot;: &quot;北京&quot;&#125;, &#123;&quot;name&quot;: &quot;大刘&quot;&#125;]json.dump(listStr, open(&quot;listStr.json&quot;,&quot;w&quot;), ensure_ascii=False)dictStr = &#123;&quot;city&quot;: &quot;北京&quot;, &quot;name&quot;: &quot;大刘&quot;&#125;json.dump(dictStr, open(&quot;dictStr.json&quot;,&quot;w&quot;), ensure_ascii=False) 4.2.4. json.load()读取文件中json形式的字符串元素 转化成python类型 123456789101112# json_load.pyimport jsonstrList = json.load(open(&quot;listStr.json&quot;))print strList# [&#123;u&apos;city&apos;: u&apos;\\u5317\\u4eac&apos;&#125;, &#123;u&apos;name&apos;: u&apos;\\u5927\\u5218&apos;&#125;]strDict = json.load(open(&quot;dictStr.json&quot;))print strDict# &#123;u&apos;city&apos;: u&apos;\\u5317\\u4eac&apos;, u&apos;name&apos;: u&apos;\\u5927\\u5218&apos;&#125; 4.3 JsonPahJsonPath 是一种信息抽取类库，是从JSON文档中抽取指定信息的工具，提供多种语言实现版本，包括：Javascript, Python， PHP 和 Java。 JsonPath 对于 JSON 来说，相当于 XPATH 对于 XML。 下载地址：https://pypi.python.org/pypi/jsonpath 安装方法：点击Download URL链接下载jsonpath，解压之后执行python setup.py install 官方文档：http://goessner.net/articles/JsonPath 4.4 JsonPath与XPath语法对比:Json结构清晰，可读性高，复杂度低，非常容易匹配，下表中对应了XPath的用法。 XPath JSONPath 描述 / $ 根节点 . @ 现行节点 / .or[] 取子节点 .. n/a 取父节点，Jsonpath未支持 // .. 就是不管位置，选择所有符合条件的条件 * * 匹配所有元素节点 @ n/a 根据属性访问，Json不支持，因为Json是个Key-value递归结构，不需要。 [] [] 迭代器标示（可以在里边做简单的迭代操作，如数组下标，根据内容选值等） \\ [,] 支持迭代器中做多选。 [] ?() 支持过滤操作. n/a () 支持表达式计算 () n/a 分组，JsonPath不支持 示例： 我们以拉勾网城市JSON文件 http://www.lagou.com/lbs/getAllCitySearchLabels.json 为例，获取所有城市。 123456789101112131415161718192021222324252627# jsonpath_lagou.pyimport urllib2import jsonpathimport jsonimport chardeturl = &apos;http://www.lagou.com/lbs/getAllCitySearchLabels.json&apos;request =urllib2.Request(url)response = urllib2.urlopen(request)html = response.read()# 把json格式字符串转换成python对象jsonobj = json.loads(html)# 从根节点开始，匹配name节点citylist = jsonpath.jsonpath(jsonobj,&apos;$..name&apos;)print citylistprint type(citylist)fp = open(&apos;city.json&apos;,&apos;w&apos;)content = json.dumps(citylist, ensure_ascii=False)print contentfp.write(content.encode(&apos;utf-8&apos;))fp.close() 5.xpath有同学说，我正则用的不好，处理HTML文档很累，有没有其他的方法？ 有！那就是XPath，我们可以先将 HTML文件 转换成 XML文档，然后用 XPath 查找 HTML 节点或元素。 5.1 什么是XML· XML 指可扩展标记语言（EXtensible Markup Language） · XML 是一种标记语言，很类似 HTML · XML 的设计宗旨是传输数据，而非显示数据 · XML 的标签需要我们自行定义。 · XML 被设计为具有自我描述性。 · XML 是 W3C 的推荐标准 W3School官方文档：http://www.w3school.com.cn/xml/index.asp 5.1.1 XML和HTML 的区别 数据格式 描述 设计目标 XML Extensible Markup Language （可扩展标记语言） 被设计为传输和存储数据，其焦点是数据的内容。 HTML HyperText Markup Language （超文本标记语言） 显示数据以及如何更好显示数据。 HTML DOM Document Object Model for HTML (文档对象模型) 通过 HTML DOM，可以访问所有的 HTML 元素，连同它们所包含的文本和属性。可以对其中的内容进行修改和删除，同时也可以创建新的元素。 5.1.2 XML文档示例12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;bookstore&gt; &lt;book category=&quot;cooking&quot;&gt; &lt;title lang=&quot;en&quot;&gt;Everyday Italian&lt;/title&gt; &lt;author&gt;Giada De Laurentiis&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;30.00&lt;/price&gt; &lt;/book&gt; &lt;book category=&quot;children&quot;&gt; &lt;title lang=&quot;en&quot;&gt;Harry Potter&lt;/title&gt; &lt;author&gt;J K. Rowling&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;29.99&lt;/price&gt; &lt;/book&gt; &lt;book category=&quot;web&quot;&gt; &lt;title lang=&quot;en&quot;&gt;XQuery Kick Start&lt;/title&gt; &lt;author&gt;James McGovern&lt;/author&gt; &lt;author&gt;Per Bothner&lt;/author&gt; &lt;author&gt;Kurt Cagle&lt;/author&gt; &lt;author&gt;James Linn&lt;/author&gt; &lt;author&gt;Vaidyanathan Nagarajan&lt;/author&gt; &lt;year&gt;2003&lt;/year&gt; &lt;price&gt;49.99&lt;/price&gt; &lt;/book&gt; &lt;book category=&quot;web&quot; cover=&quot;paperback&quot;&gt; &lt;title lang=&quot;en&quot;&gt;Learning XML&lt;/title&gt; &lt;author&gt;Erik T. Ray&lt;/author&gt; &lt;year&gt;2003&lt;/year&gt; &lt;price&gt;39.95&lt;/price&gt; &lt;/book&gt; &lt;/bookstore&gt; 5.1.3 HTML DOM模型示例HTML DOM 定义了访问和操作 HTML 文档的标准方法，以树结构方式表达 HTML 文档。 5.1.4 XML的节点关系 1)父（Parent） 每个元素以及属性都有一个父。 下面是一个简单的XML例子中，book 元素是 title、author、year 以及 price 元素的父： 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;book&gt; &lt;title&gt;Harry Potter&lt;/title&gt; &lt;author&gt;J K. Rowling&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;29.99&lt;/price&gt;&lt;/book&gt; 2)子（Children） 元素节点可有零个、一个或多个子。 在下面的例子中，title、author、year 以及 price 元素都是 book 元素的子： 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;book&gt; &lt;title&gt;Harry Potter&lt;/title&gt; &lt;author&gt;J K. Rowling&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;29.99&lt;/price&gt;&lt;/book&gt; 3)同胞（Sibling） 拥有相同的父的节点 在下面的例子中，title、author、year 以及 price 元素都是同胞： 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;book&gt; &lt;title&gt;Harry Potter&lt;/title&gt; &lt;author&gt;J K. Rowling&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;29.99&lt;/price&gt;&lt;/book&gt; 4)先辈（Ancestor） 某节点的父、父的父，等等。 在下面的例子中，title 元素的先辈是 book 元素和 bookstore 元素： 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;bookstore&gt;&lt;book&gt; &lt;title&gt;Harry Potter&lt;/title&gt; &lt;author&gt;J K. Rowling&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;29.99&lt;/price&gt;&lt;/book&gt;&lt;/bookstore&gt; 5)后代（Descendant） 某个节点的子，子的子，等等。 在下面的例子中，bookstore 的后代是 book、title、author、year 以及 price 元素： 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;bookstore&gt;&lt;book&gt; &lt;title&gt;Harry Potter&lt;/title&gt; &lt;author&gt;J K. Rowling&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;29.99&lt;/price&gt;&lt;/book&gt;&lt;/bookstore&gt; 5.2 什么是XPath？XPath (XML Path Language) 是一门在 XML 文档中查找信息的语言，可用来在 XML 文档中对元素和属性进行遍历。 W3School官方文档：http://www.w3school.com.cn/xpath/index.asp 5.2.1 XPath 开发工具 开源的XPath表达式编辑工具:XMLQuire(XML格式文件可用) Chrome插件 XPath Helper Firefox插件 XPath Checker 5.2.2 选取节点XPath 使用路径表达式来选取 XML 文档中的节点或者节点集。这些路径表达式和我们在常规的电脑文件系统中看到的表达式非常相似。 下面列出了最常用的路径表达式： 表达式 描述 Nodename 选取此节点的所有子节点。 / 从根节点选取。 // 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。 . 选取当前节点。 .. 选取当前节点的父节点。 @ 选取属性。 在下面的表格中，我们已列出了一些路径表达式以及表达式的结果： 路径表达式 结果 bookstore 选取 bookstore 元素的所有子节点。 /bookstore 选取根元素 bookstore。注释：假如路径起始于正斜杠( / )，则此路径始终代表到某元素的绝对路径！ bookstore/book 选取属于 bookstore 的子元素的所有 book 元素。 //book 选取所有 book 子元素，而不管它们在文档中的位置。 bookstore//book 选择属于 bookstore 元素的后代的所有 book 元素，而不管它们位于 bookstore 之下的什么位置。 //@lang 选取名为 lang 的所有属性。 5.2.3 谓语（Predicates）谓语用来查找某个特定的节点或者包含某个指定的值的节点，被嵌在方括号中。 在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果： 路径表达式 结果 /bookstore/book[1] 选取属于 bookstore 子元素的第一个 book 元素。 /bookstore/book[last()] 选取属于 bookstore 子元素的最后一个 book 元素。 /bookstore/book[last()-1] 选取属于 bookstore 子元素的倒数第二个 book 元素。 /bookstore/book[position()&lt;3] 选取最前面的两个属于 bookstore 元素的子元素的 book 元素。 //title[@lang] 选取所有拥有名为 lang 的属性的 title 元素。 //title[@lang=’eng’] 选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。 /bookstore/book[price&gt;35.00] 选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。 /bookstore/book[price&gt;35.00]/title 选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。 5.2.4 选取未知节点XPath 通配符可用来选取未知的 XML 元素。 通配符 描述 * 匹配任何元素节点。 @* 匹配任何属性节点。 node() 匹配任何类型的节点。 在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果： 路径表达式 结果 /bookstore/* 选取 bookstore 元素的所有子元素。 //* 选取文档中的所有元素。 //title[@*] 选取所有带有属性的 title 元素。 5.2.5 选取若干路径通过在路径表达式中使用“|”运算符，您可以选取若干个路径。 实例 在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果： 路径表达式 结果 //book/title \\ //book/price 选取 book 元素的所有 title 和 price 元素。 //title \\ //price 选取文档中的所有 title 和 price 元素。 /bookstore/book/title \\ //price 选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。 5.2.6 XPath的运算符下面列出了可用在 XPath 表达式中的运算符： 这些就是XPath的语法内容，在运用到Python抓取时要先转换为xml。 1)lxml库** lxml 是 一个HTML/XML的解析器，主要的功能是如何解析和提取 HTML/XML 数据。 lxml和正则一样，也是用 C 实现的，是一款高性能的 Python HTML/XML 解析器，我们可以利用之前学习的XPath语法，来快速的定位特定元素以及节点信息。 lxml python 官方文档：http://lxml.de/index.html 需要安装C语言库，可使用 pip 安装：pip install lxml （或通过wheel方式安装） 2)初步使用 我们利用它来解析 HTML 代码，简单示例： 123456789101112131415161718192021222324252627282930313233343536# lxml_test.py# 使用 lxml 的 etree 库from lxml import etree text = &apos;&apos;&apos;&lt;div&gt; &lt;ul&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link1.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-inactive&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;third item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt; # 注意，此处缺少一个 &lt;/li&gt; 闭合标签 &lt;/ul&gt; &lt;/div&gt;&apos;&apos;&apos;#利用etree.HTML，将字符串解析为HTML文档html = etree.HTML(text) # 按字符串序列化HTML文档result = etree.tostring(html) print(result)输出结果：&lt;html&gt;&lt;body&gt;&lt;div&gt; &lt;ul&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link1.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-inactive&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;third item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; lxml 可以自动修正 html 代码，例子里不仅补全了 li 标签，还添加了 body，html 标签。 3)文件读取： 除了直接读取字符串，lxml还支持从文件里读取内容。我们新建一个hello.html文件： 1234567891011&lt;!-- hello.html --&gt;&lt;div&gt; &lt;ul&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link1.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-inactive&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; 再利用 etree.parse() 方法来读取文件。 123456789# lxml_parse.pyfrom lxml import etree# 读取外部文件 hello.htmlhtml = etree.parse(&apos;./hello.html&apos;)result = etree.tostring(html, pretty_print=True)print(result) 输出结果与之前相同： 1234567891011&lt;html&gt;&lt;body&gt;&lt;div&gt; &lt;ul&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link1.html&quot;&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-inactive&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;third item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 5.2.7 XPath实例测试1. 获取所有的 标签 12345678910111213# xpath_li.pyfrom lxml import etreehtml = etree.parse(&apos;hello.html&apos;)print type(html) # 显示etree.parse() 返回类型result = html.xpath(&apos;//li&apos;)print result # 打印&lt;li&gt;标签的元素集合print len(result)print type(result)print type(result[0]) 输出结果： 12345&lt;type &apos;lxml.etree._ElementTree&apos;&gt;[&lt;Element li at 0x1014e0e18&gt;, &lt;Element li at 0x1014e0ef0&gt;, &lt;Element li at 0x1014e0f38&gt;, &lt;Element li at 0x1014e0f80&gt;, &lt;Element li at 0x1014e0fc8&gt;]5&lt;type &apos;list&apos;&gt;&lt;type &apos;lxml.etree._Element&apos;&gt; 2. 继续获取 标签的所有 class属性 12345678# xpath_li.pyfrom lxml import etreehtml = etree.parse(&apos;hello.html&apos;)result = html.xpath(&apos;//li/@class&apos;)print result 运行结果 [‘item-0’, ‘item-1’, ‘item-inactive’, ‘item-1’, ‘item-0’] 继续获取标签下hre为link1.html的标签 12345678# xpath_li.pyfrom lxml import etreehtml = etree.parse(&apos;hello.html&apos;)result = html.xpath(&apos;//li/a[@href=&quot;link1.html&quot;]&apos;)print result 运行结果 [] **4. 获取标签下的所有标签 12345678910111213# xpath_li.pyfrom lxml import etreehtml = etree.parse(&apos;hello.html&apos;)#result = html.xpath(&apos;//li/span&apos;)#注意这么写是不对的：#因为 / 是用来获取子元素的，而 &lt;span&gt; 并不是 &lt;li&gt; 的子元素，所以，要用双斜杠result = html.xpath(&apos;//li//span&apos;)print result 运行结果 [] **5. 获取标签下的标签里的所有 class 12345678# xpath_li.pyfrom lxml import etreehtml = etree.parse(&apos;hello.html&apos;)result = html.xpath(&apos;//li/a//@class&apos;)print result 运行结果 [‘blod’] 6. 获取最后一个的的href 12345678910# xpath_li.pyfrom lxml import etreehtml = etree.parse(&apos;hello.html&apos;)result = html.xpath(&apos;//li[last()]/a/@href&apos;)# 谓语 [last()] 可以找到最后一个元素print result 运行结果 [‘link5.html’] 7. 获取倒数第二个元素的内容 123456789# xpath_li.pyfrom lxml import etreehtml = etree.parse(&apos;hello.html&apos;)result = html.xpath(&apos;//li[last()-1]/a&apos;)# text 方法可以获取元素内容print result[0].text 运行结果 fourth item 8. 获取class值为bold的标签名 12345678910# xpath_li.pyfrom lxml import etreehtml = etree.parse(&apos;hello.html&apos;)result = html.xpath(&apos;//*[@class=&quot;bold&quot;]&apos;)# tag方法可以获取标签名print result[0].tag 运行结果 span 6.多线程6.1多线程糗事百科案例案例要求参考上一个糗事百科单进程案例 Queue（队列对象） Queue是python中的标准库，可以直接import Queue引用;队列是线程间最常用的交换数据的形式 python下多线程的思考 对于资源，加锁是个重要的环节。因为python原生的list,dict等，都是not thread safe的。而Queue，是线程安全的，因此在满足使用条件下，建议使用队列 初始化： class Queue.Queue(maxsize) FIFO 先进先出 包中的常用方法: o Queue.qsize() 返回队列的大小 o Queue.empty() 如果队列为空，返回True,反之False o Queue.full() 如果队列满了，返回True,反之False o Queue.full 与 maxsize 大小对应 o Queue.get([block[, timeout]])获取队列，timeout等待时间 创建一个“队列”对象 o import Queue o myqueue = Queue.Queue(maxsize = 10) 将一个值放入队列中 o myqueue.put(10) 将一个值从队列中取出 o myqueue.get() 6.2 多线程示意图 7. phantomjs 爬虫(Spider)，反爬虫(Anti-Spider)，反反爬虫(Anti-Anti-Spider) 之间恢宏壮阔的斗争… 7.1 Day 1· 小莫想要某站上所有的电影，写了标准的爬虫(基于HttpClient库)，不断地遍历某站的电影列表页面，根据 Html 分析电影名字存进自己的数据库。 · 这个站点的运维小黎发现某个时间段请求量陡增，分析日志发现都是 IP(xxx.xxx.xxx.xxx)这个用户，并且 user-agent 还是 Python-urllib/2.7 ，基于这两点判断非人类后直接在服务器上封杀。 7.2 Day 2· 小莫电影只爬了一半，于是也针对性的变换了下策略：1. user-agent 模仿百度(“Baiduspider…”)，2. IP每爬半个小时就换一个IP代理。 · 小黎也发现了对应的变化，于是在服务器上设置了一个频率限制，每分钟超过120次请求的再屏蔽IP。 同时考虑到百度家的爬虫有可能会被误伤，想想市场部门每月几十万的投放，于是写了个脚本，通过 hostname 检查下这个 ip 是不是真的百度家的，对这些 ip 设置一个白名单。 7.3 Day 3· 小莫发现了新的限制后，想着我也不急着要这些数据，留给服务器慢慢爬吧，于是修改了代码，随机1-3秒爬一次，爬10次休息10秒，每天只在8-12，18-20点爬，隔几天还休息一下。 · 小黎看着新的日志头都大了，再设定规则不小心会误伤真实用户，于是准备换了一个思路，当3个小时的总请求超过50次的时候弹出一个验证码弹框，没有准确正确输入的话就把 IP 记录进黑名单。 7.4 Day 4· 小莫看到验证码有些傻脸了，不过也不是没有办法，先去学习了图像识别（关键词 PIL，tesseract），再对验证码进行了二值化，分词，模式训练之后，总之最后识别了小黎的验证码（关于验证码，验证码的识别，验证码的反识别也是一个恢弘壮丽的斗争史…），之后爬虫又跑了起来。 · 小黎是个不折不挠的好同学，看到验证码被攻破后，和开发同学商量了变化下开发模式，数据并不再直接渲染，而是由前端同学异步获取，并且通过 JavaScript 的加密库生成动态的 token，同时加密库再进行混淆（比较重要的步骤的确有网站这样做，参见淘宝和微博的登陆流程）。 7.5 Day 5· 混淆过的加密库就没有办法了么？当然不是，可以慢慢调试，找到加密原理，不过小莫不准备用这么耗时耗力的方法，他放弃了基于 HttpClient的爬虫，选择了内置浏览器引擎的爬虫(关键词：PhantomJS，Selenium)，在浏览器引擎运行页面，直接获取了正确的结果，又一次拿到了对方的数据。 · 小黎：….. 7.6 爬虫与发爬虫的斗争还在继续…通常情况下，在爬虫与反爬虫的对弈中，爬虫一定会胜利。 换言之，只要人类能够正常访问的网页，爬虫在具备同等资源的情况下就一定可以抓取到。 ###7.6.1 关于爬虫部分一些建议： 尽量减少请求次数，能抓列表页就不抓详情页，减轻服务器压力，程序员都是混口饭吃不容易。 不要只看 Web 网站，还有手机 App 和 H5，这样的反爬虫措施一般比较少。 实际应用时候，一般防守方做到根据 IP 限制频次就结束了，除非很核心的数据，不会再进行更多的验证，毕竟成本的问题会考虑到。 如果真的对性能要求很高，可以考虑多线程(一些成熟的框架如 Scrapy都已支持)，甚至分布式… 7.7 SeleniumSelenium是一个Web的自动化测试工具，最初是为网站自动化测试而开发的，类型像我们玩游戏用的按键精灵，可以按指定的命令自动操作，不同是Selenium 可以直接运行在浏览器上，它支持所有主流的浏览器（包括PhantomJS这些无界面的浏览器）。 Selenium 可以根据我们的指令，让浏览器自动加载页面，获取需要的数据，甚至页面截屏，或者判断网站上某些动作是否发生。 Selenium 自己不带浏览器，不支持浏览器的功能，它需要与第三方浏览器结合在一起才能使用。但是我们有时候需要让它内嵌在代码中运行，所以我们可以用一个叫 PhantomJS 的工具代替真实的浏览器。 可以从 PyPI 网站下载 Selenium库https://pypi.python.org/simple/selenium ，也可以用 第三方管理器 pip用命令安装：pip install selenium Selenium 官方参考文档：http://selenium-python.readthedocs.io/index.html 7.8 PhantomJSPhantomJS 是一个基于Webkit的“无界面”(headless)浏览器，它会把网站加载到内存并执行页面上的 JavaScript，因为不会展示图形界面，所以运行起来比完整的浏览器要高效。 如果我们把 Selenium 和 PhantomJS 结合在一起，就可以运行一个非常强大的网络爬虫了，这个爬虫可以处理 JavaScrip、Cookie、headers，以及任何我们真实用户需要做的事情。 注意：PhantomJS 只能从它的官方网站http://phantomjs.org/download.html) 下载。 因为 PhantomJS 是一个功能完善(虽然无界面)的浏览器而非一个 Python 库，所以它不需要像 Python 的其他库一样安装，但我们可以通过Selenium调用PhantomJS来直接使用。 PhantomJS 官方参考文档：http://phantomjs.org/documentation 7.8.1 快速入门Selenium 库里有个叫 WebDriver 的 API。WebDriver 有点儿像可以加载网站的浏览器，但是它也可以像 BeautifulSoup 或者其他 Selector 对象一样用来查找页面元素，与页面上的元素进行交互 (发送文本、点击等)，以及执行其他动作来运行网络爬虫。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# IPython2 测试代码# 导入 webdriverfrom selenium import webdriver# 要想调用键盘按键操作需要引入keys包from selenium.webdriver.common.keys import Keys# 调用环境变量指定的PhantomJS浏览器创建浏览器对象driver = webdriver.PhantomJS()# 如果没有在环境变量指定PhantomJS位置# driver = webdriver.PhantomJS(executable_path=&quot;./phantomjs&quot;))# get方法会一直等到页面被完全加载，然后才会继续程序，通常测试会在这里选择 time.sleep(2)driver.get(&quot;http://www.baidu.com/&quot;)# 获取页面名为 wrapper的id标签的文本内容data = driver.find_element_by_id(&quot;wrapper&quot;).text# 打印数据内容print data# 打印页面标题 &quot;百度一下，你就知道&quot;print driver.title# 生成当前页面快照并保存driver.save_screenshot(&quot;baidu.png&quot;)# id=&quot;kw&quot;是百度搜索输入框，输入字符串&quot;长城&quot;driver.find_element_by_id(&quot;kw&quot;).send_keys(u&quot;缝纫机乐队&quot;)# id=&quot;su&quot;是百度搜索按钮，click() 是模拟点击driver.find_element_by_id(&quot;su&quot;).click()# 获取新的页面快照driver.save_screenshot(&quot;缝纫机乐队.png&quot;)# 打印网页渲染后的源代码print driver.page_source# 获取当前页面Cookieprint driver.get_cookies()# ctrl+a 全选输入框内容driver.find_element_by_id(&quot;kw&quot;).send_keys(Keys.CONTROL,&apos;a&apos;)# ctrl+x 剪切输入框内容driver.find_element_by_id(&quot;kw&quot;).send_keys(Keys.CONTROL,&apos;x&apos;)# 输入框重新输入内容driver.find_element_by_id(&quot;kw&quot;).send_keys(&quot;itxdl&quot;)# 模拟Enter回车键driver.find_element_by_id(&quot;su&quot;).send_keys(Keys.RETURN)# 清除输入框内容driver.find_element_by_id(&quot;kw&quot;).clear()# 生成新的页面快照driver.save_screenshot(&quot;itxdl.png&quot;)# 获取当前urlprint driver.current_url# 关闭当前页面，如果只有一个页面，会关闭浏览器# driver.close()# 关闭浏览器driver.quit() 7.8.2 页面操作Selenium 的 WebDriver提供了各种方法来寻找元素，假设下面有一个表单输入框：","categories":[],"tags":[{"name":"Python爬虫","slug":"Python爬虫","permalink":"https://127.0.0.1/blog/tags/Python爬虫/"}]}]}